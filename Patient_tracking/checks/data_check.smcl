{smcl}
{com}{sf}{ul off}{txt}
{com}. 
. 
. * ----------------------------
. * load/install packages
. * ----------------------------
. 
. /* 
> If needed, install necessary packages to compile notebook document (e.g., html, docx, pdf)
> these packages include: markdoc, kethcup, weaver, synlight, and statax
> note: if get any error messages, follow on-screen instructions in Stata console to 
> complete correct installation
> 
> * once install following packages once, do not need to re-install; 
> * here, commented out
> */
. *packages for MarkDoc
. *ssc install Markdoc
. *ssc install weaver
. *ssc install synlight
. *ssc install statax
. *markdocpandoc // installs pandoc
. *packages for analysis and presentation of results
. *ssc install estout, replace
. *ssc install outreg
. *ssc install pandoc
. *ssc install coefplot 
. 
. *-----------------------
. *-----------------------
. 
. 
. /* Template: 
> MI 20170122: 
> comments from Stata do-file will not appear in final markdoc.
> The text included in this do-file will only appear if it
> is blocked between a forward slash '/' and 3 asterisks '***', as done below
> immediately before start of latex syntax.
> */
.         
. 
. /***
> 
> \documentclass{c -(}article{c )-}
> 
> \usepackage{c -(}graphicx{c )-}  % this is a package for inserting graphics
> \usepackage{c -(}hyperref{c )-}
> \hypersetup{c -(}
>     colorlinks=true,
>     linkcolor=blue,
>     filecolor=blue,      
>     urlcolor=blue
>         {c )-}
>         
> \usepackage{c -(}geometry{c )-}   % useful package for formatting document
> \geometry{c -(}
>         letterpaper,
>         total={c -(}6.5in, 9in{c )-},
>         left=1in,
>         right=1in,
>         top=1in,
>         bottom=1in
>         {c )-}
> 
> \begin{c -(}document{c )-}
> 
> \title{c -(}Data Validation Exercise before Entry into UCSR{c )-}
> \author{c -(}
>   Lily Alexander
>   {c )-}
> 
>  \date{c -(}
>   \bigskip
>   \today
>   {c )-}
> 
> \maketitle
>         
> \begin{c -(}abstract{c )-}
> \textbf{c -(}Summary{c )-}. This is a document to validate and check variables before they are integrated into the UCSR.
> \end{c -(}abstract{c )-}
> 
> \section{c -(}High-level codebook for all variables{c )-}
> 
> \begin{c -(}verbatim{c )-}
> ***/
. 
. /* ------------------------
> load dataset
> ---------------------------
> */
. 
. /**/ use pat_tracking_clean_wide_file_Mar2018.dta, clear 
{txt}
{com}. 
. 
. /* ------------------------
> codebook generation
> ---------------------------
> */
. /**/ codebook 

{txt}{hline}
{res}disease{right:Disease}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"HIV"

{txt}{hline}
{res}collapsed{right:Collapsed}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str2

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"No"

{txt}{hline}
{res}lead_author{right:Lead Author}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Rosen, S"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}ref_year{right:Reference Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}2010{txt},{res}2010{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2010

{txt}{hline}
{res}output_unit2{right:Output unit}
{txt}{hline}

{col 19}type:  string ({res}str23{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Cost Per Patient Traced"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}title{right:Title}
{txt}{hline}

{col 19}type:  string ({res}str159{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Cost of using a patient tracer to
{col 33}reduce loss to follow-up and ascertain
{col 33}patient status in a large antiretroviral
{col 33}therapy program in Johannesburg, South
{col 33}Africa"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}journal_etc{right:Journal}
{txt}{hline}

{col 19}type:  string ({res}str47{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Trop Med Int Health. 2010 Jun; 15(s1):
{col 33}98–104"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}url{right:URL}
{txt}{hline}

{col 19}type:  string ({res}str56{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"<https://www.ncbi.nlm.nih.gov/pmc/artic
{col 33}les/PMC3059411/>."

{txt}{hline}
{res}iso_name{right:Country}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"South Africa "

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}location{right:Location}
{txt}{hline}

{col 19}type:  string ({res}str12{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Johannesburg"

{txt}{hline}
{res}no_sites{right:Sites}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}1{txt},{res}1{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}1

{txt}{hline}
{res}pop_density{right:Urbanicity}
{txt}{hline}

{col 19}type:  string ({res}str5{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Urban"

{txt}{hline}
{res}ownership{right:Ownership}
{txt}{hline}

{col 19}type:  string ({res}str6{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Public"

{txt}{hline}
{res}platform{right:Platform}
{txt}{hline}

{col 19}type:  string ({res}str15{txt}), but longest is str14

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Fixed Facility"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}facility_cat{right:Platform specificity}
{txt}{hline}

{col 19}type:  string ({res}str68{txt}), but longest is str29

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Hospital - Primary (District)"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_class{right:Intervention Category}
{txt}{hline}

{col 19}type:  string ({res}str13{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Health System"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_int{right:Intervention}
{txt}{hline}

{col 19}type:  string ({res}str16{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"PATIENT TRACKING"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}int_description_long{right:Intervention Description (Long)}
{txt}{hline}

{col 19}type:  string ({res}str1224{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"In the role of patient tracer, the
{col 33}researcher was instructed to use all
{col 33}available contact information to locate
{col 33}patients; discuss the patient's
{col 33}situation by phone or in person; and,
{col 33}following pre-established guidelines,
{col 33}assist the patient to return to care.
{col 33}Assistance allowed by the intervention's
{col 33}guidelines included making an
{col 33}appointment at the clinic on the
{col 33}patient's behalf; meeting the patient
{col 33}for the appointment and assisting in the
{col 33}consultation if requested; helping to
{col 33}obtain documentation required to
{col 33}continue treatment; finding and
{col 33}referring the patient to another
{col 33}treatment facility closer to the
{col 33}patient's home or open at different
{col 33}times; helping the patient to disclose
{col 33}his/her HIV or treatment status to
{col 33}family members; providing other
{col 33}information or referrals as requested;
{col 33}and/or providing up to R100
{col 33}(approximately $11) per patient for
{col 33}transport fares to and from the clinic.
{col 33}The intention of providing transport
{col 33}funds was to allow the patient to make
{col 33}one additional roundtrip visit to the
{col 33}clinic, in the hope that the clinic
{col 33}staff could assist the patient in
{col 33}devising a longer-term solution to the
{col 33}lack of transport funds, such as
{col 33}transferring to a closer facility or
{col 33}applying for a social support grant."

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}clinical_monitoring{right:Clinical monitoring}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}demand_generation{right:Demand generation}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}counseling_content{right:Counseling content}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}staff_type{right:Staff type & number}
{txt}{hline}

{col 19}type:  string ({res}str19{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Patient Tracker (1)"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}supportive_care{right:Supportive care}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}visits{right:Visit type & number}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}referrals{right:Referrals}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}method{right:Method}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}id_tech{right:Technology}
{txt}{hline}

{col 19}type:  string ({res}str27{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Phone-Based Tracking System"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}treatment_phase{right:Treatment phase}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}arv_regimen{right:ARV Regimen}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}treatment{right:Treatment}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}screening_diagnoses{right:Screening and diagnosis}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}community_awareness{right:Community awareness}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}health_system{right:health_system}
{txt}{hline}

{col 19}type:  string ({res}str27{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"phone-based tracking system"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_activities{right:Costed activities}
{txt}{hline}

{col 19}type:  string ({res}str13{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Health System"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}start_month{right:Start Month}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}2{txt},{res}2{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2

{txt}{hline}
{res}start_year{right:Start Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}2009{txt},{res}2009{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2009

{txt}{hline}
{res}end_month{right:End Month}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}6{txt},{res}6{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}6

{txt}{hline}
{res}end_year{right:End Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}2009{txt},{res}2009{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2009

{txt}{hline}
{res}period_portrayed{right:Total Months}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}4{txt},{res}4{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}4

{txt}{hline}
{res}year_intro{right:Year introduced at study site}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}2009{txt},{res}2009{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2009

{txt}{hline}
{res}coverage{right:Coverage}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}id_pop_dem_std{right:Target group (demographic)}
{txt}{hline}

{col 19}type:  string ({res}str19{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"General Populations"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_pop_clin_std{right:Target group (clinical)}
{txt}{hline}

{col 19}type:  string ({res}str12{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"HIV positive"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}pop_age{right:Average Age}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}pop_sex{right:Gender}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}pop_ses{right:SES}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}pop_education{right:Education}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}hiv_prev{right:HIV Prevalence}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}tb_prev{right:TB Prevalence}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}tb_rx_resistance{right:TB Drug Resistance}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}costing_purpose{right:Costing Purpose}
{txt}{hline}

{col 19}type:  string ({res}str127{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"To conduct a cost-effectivess analysis
{col 33}of a pilot 'patient tracer' intervention
{col 33}that the site implemented over a 4-month
{col 33}period"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}timing{right:Timing}
{txt}{hline}

{col 19}type:  string ({res}str15{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Cross-Sectional"

{txt}{hline}
{res}country_sampling{right:Country Sampling}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}geo_sampling_incountry{right:Geographic Area In Country Sampling}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}site_sampling{right:Site Sampling}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Entire Program"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}px_sampling{right:Patient Sampling}
{txt}{hline}

{col 19}type:  string ({res}str6{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Random"

{txt}{hline}
{res}sample_size_derived{right:Sample size formally derived}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"No"

{txt}{hline}
{res}controls{right:Controls}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"No"

{txt}{hline}
{res}econ_perspective_actual{right:Perspective}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Provider"

{txt}{hline}
{res}econ_costing{right:Economic / Financial}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Financial Only"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}real_world{right:Real World / Per Protocol}
{txt}{hline}

{col 19}type:  string ({res}str10{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Real World"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}asd_costs{right:Above Service Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}list_asd_costs{right:Above Service Cost List}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"None"

{txt}{hline}
{res}omitted_costs{right:Omitted Costs}
{txt}{hline}

{col 19}type:  string ({res}str33{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Vehicles/transport, Patient costs"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}sensitivity_analysis{right:Sensitivity Analysis}
{txt}{hline}

{col 19}type:  string ({res}str7{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Limited"

{txt}{hline}
{res}scale{right:Economies of scale}
{txt}{hline}

{col 19}type:  string ({res}str9{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Discussed"

{txt}{hline}
{res}research_costs{right:Research Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Excluded"

{txt}{hline}
{res}unrelated_costs{right:Unrelated Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"No"

{txt}{hline}
{res}overhead{right:Overhead Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Yes"

{txt}{hline}
{res}overhead_costs{right:Overhead Costs List}
{txt}{hline}

{col 19}type:  string ({res}str55{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Office Expenses And Service,
{col 33}Communication And Supplies"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}pot_distortions{right:Potential distortions}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}volunteer_time{right:Valuing Volunteer Time}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}family_time{right:Valuing Family Time}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}px_costs_measured{right:Patient-Incurred Costs Measured}
{txt}{hline}

{col 19}type:  string ({res}str12{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Not Included"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}cat_cost{right:Catastrophic Cost Calculated}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"None"

{txt}{hline}
{res}currency_yr{right:Reported Currency Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}2009{txt},{res}2009{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}2009

{txt}{hline}
{res}iso_code{right:Reported Currency}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"USD"

{txt}{hline}
{res}currency_iso{right:Currency of Data Collection}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"ZAR"

{txt}{hline}
{res}currency_x{right:Currency Exchange Method}
{txt}{hline}

{col 19}type:  string ({res}str11{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"Market Only"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}current_x_rate{right:Currency Exchange Rate}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}9.36{txt},{res}9.36{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}9.36

{txt}{hline}
{res}discount_rate{right:Discount Rate}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}inflation{right:Inflation rate}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"."

{txt}{hline}
{res}mean_cost{right:Mean Unit Cost}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}77.322704{txt},{res}120.27357{txt}]{col 55}units:  {res}1.000e-06
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}77.322704
{col 21}         1{col 33}120.27357

{txt}{hline}
{res}si_personnel{right:Personnel (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}58.82765{txt},{res}101.77852{txt}]{col 55}units:  {res}.00001
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}58.827648
{col 21}         1{col 33}101.77852

{txt}{hline}
{res}si_per_service_delivery{right:Personnel: Direct Service Delivery (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}58.82765{txt},{res}101.77852{txt}]{col 55}units:  {res}.00001
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}58.827648
{col 21}         1{col 33}101.77852

{txt}{hline}
{res}si_per_support{right:Personnel: Support (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_per_mixed_unspec{right:Personnel: Mixed Unspecified (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_recurrent{right:Recurrent Goods (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}18.495056{txt},{res}18.495056{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}18.495056

{txt}{hline}
{res}si_rec_key_drugs{right:Recurring: Supplies (key drugs) (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{p 0 39}{res}si_rec_med_int_supplies{space 16}Recurring: Medical Supplies (excluding drugs) (SI){p_end}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_rec_nonmed_int_supplies{right:Recurring: Non-medical Supplies (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}18.160808{txt},{res}18.160808{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}18.160808

{txt}{hline}
{res}si_rec_building_space{right:Recurring: Building Space (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_rec_mixed{right:Recurring: Mixed (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_rec_other{right:Recurring: Other (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.33424801{txt},{res}.33424801{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.33424801

{txt}{hline}
{res}si_capital{right:Capital (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_med_equip{right:Capital: Equipment (medical) (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_nonmed_equip{right:Capital: Equipment (non-medical) (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_building_space{right:Capital: Building Space (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_vehicles{right:Capital: Vehicles (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_mixed{right:Capital: Mixed (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_cap_other{right:Capital: Other (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_mixed{right:Mixed (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}si_unspecified{right:Unspecified (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_primary_sd{right:Primary Service Delivery (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}58.82765{txt},{res}101.77852{txt}]{col 55}units:  {res}.00001
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}58.827648
{col 21}         1{col 33}101.77852

{txt}{hline}
{res}a_prisd_unspecified{right:Primary SD: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}58.82765{txt},{res}101.77852{txt}]{col 55}units:  {res}.00001
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}58.827648
{col 21}         1{col 33}101.77852

{txt}{hline}
{res}a_prisd_unspec_counseling{right:Primary SD: Counseling unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_prisd_post_test_counseling{right:Primary SD: Post-test counseling (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_prisd_lab_services{right:Primary SD: Lab services (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_prisd_htc_service_delivery{right:Primary SD: HTC service delivery (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_prisd_hiv_rapid_test{right:Primary SD: HIV rapid testing (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_prisd_arv_delivery{right:Primary SD: ARV delivery}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_secondary_sd{right:Secondary Service Delivery (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ancillary{right:Ancillary (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_anc_demand_generation{right:Ancillary: Demand generation (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_anc_lab_services{right:Ancillary: Lab Services (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_anc_adhreten{right:Ancillary: Adherence/Retention (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_anc_bldg_equip{right:Ancillary: Building equipment (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_anc_unspecified{right:Ancillary: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_operational{right:Operational (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}18.495056{txt},{res}18.495056{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}18.495056

{txt}{hline}
{res}a_ope_bldg_equip{right:Operational: Buildings and Equipment (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_logistics{right:Operational: Logistics (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_program_mgmt{right:Operational: Program Management (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_supervision{right:Operational: Supervision (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_training{right:Operational: Training (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_transportation{right:Operational: Transportation (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.33424801{txt},{res}.33424801{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.33424801

{txt}{hline}
{res}a_ope_massed{right:Operational: Mass Education (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_hmis{right:Operational: HMIS and Record-Keeping (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_ope_unspecified{right:Operational: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}18.160808{txt},{res}18.160808{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}18.160808

{txt}{hline}
{res}a_mixed{right:Mixed (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_mix_bldg_equip{right:Mixed: Building Equipment (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.

{txt}{hline}
{res}a_unspecified{right:Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}2{txt}/{res}2

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}.
{txt}
{com}. /*
> 
> \end{c -(}verbatim{c )-}
> 
> 
> 
> \begin{c -(}verbatim{c )-}
> ***/
. 
. * can generate clean tables
. 
. /***
> \end{c -(}verbatim{c )-}
> 
> Here we import the table of summary statistics.\\
> 
> \input{c -(}./checks/sumstats{c )-} 
> 
> Now lets generate and add a figure that visualizing one of these variables.\\
> 
> ----------------------
> export final tex document
> -----------------------------
> */
. 
. /* Exporting in several formats */
. *markdoc example1, replace              /* exporting a markdown file */
. *markdoc example1, replace export(html) 
. *markdoc example1, replace export(odt) 
. *markdoc example1, replace export(txt) 
. *markdoc example1, replace export(epub) 
. *markdoc mytemplatelatex, replace author() affiliation() export(docx) 
. /* could add date option (no parentheses) */
. *markdoc mytemplatelatex, replace author() affiliation() export(pdf)
. 
. * markdoc mytemplatelatex, replace author() affiliation() export(docx) markup()
. * markdoc mytemplatelatex, replace author() affiliation() export(html) markup()
. markdoc data_check, replace author() affiliation() export(tex) markup()
{txt}
{p}(MarkDoc created {bf:{browse "data_check.tex"}})


{com}. 
. /*
> can also produce pdf slides:
> markdoc example1, replace author(Matthew C. Ingram) affiliation(University at Albany, SUNY) date export(slide)
> NOTE: this will replace any existing pdf file with same name, so be cautious
> */
. 
. * end
. 
. 
{txt}end of do-file

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. **************************************************************************
. **************************************************************************
. **************************************************************************
. ** Do file for export of VMMC studies to the UCSR, using select variables
. ** Lily Alexander
. ** University of Washington
. ** February 2018 
. ** lilyalexander18@gmail.com
. **************************************************************************
. **************************************************************************
. **************************************************************************
. 
. ** Data requirements
. **
. **  Must use data already formatted into wide file for GHCC analysis
. **              - These are available upon request
. **              - Procedure to be replicated for other intervention areas (ART, etc)
. **              - As well as other diseases (TB)
. **************************************************************************
. 
. set more off 
{txt}
{com}.         clear
{txt}
{com}.         *Drew's Path:
.         //cd "/Users/dcameron03/Documents/GitHub/Post-Extraction-Processing/VMMC/"
.         //use VMMC_wide_file.dta, replace       
.         *Lily's Path:
.         * cd "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/VMMC"
.         *       use VMMC_wide_file_Feb2018.dta
.         *Lily's temporary path: 
.         cd "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files
{txt}
{com}.         use pat_tracking_wide_file_Apr2018.dta, replace
{txt}
{com}. 
. 
. **********************************              
. ** Cross-validation of costs **
. **********************************
.         
.         * 1. Check that broad standard input categories sum to mean cost 
.         ****************************************************************
.         egen check = rowtotal(si_recurrent si_personnel)
{txt}
{com}.         replace check = si_combined if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1
  {res}0
{txt}
{com}.         di in red `r(N)'
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}. 
.         
.         * 2. Check that narrow standard input categories sum to broad categories
.         ************************************************************************
.         
.         local prefix "rec per" 
{txt}
{com}.                 
.         preserve 
{txt}
{com}.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(si_`var'_*)
{txt}  3{com}.                 drop si_`var'_*
{txt}  4{com}.                 gen diff_`var' = sum_`var' - si_`var'
{txt}  5{com}.                 gen flag_`var' = 1 if diff_`var' > 0.05 & diff_`var' !=. 
{txt}  6{com}.         
.         {c )-}
{txt}(2 missing values generated)
(2 missing values generated)

{com}.         restore
{txt}
{com}.         
.         * 3. Check that broad activity categories sum to mean cost 
.         **********************************************************
.         
.         egen check = rowtotal(a_primary_sd a_operational)
{txt}
{com}.         replace check = a_combo if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1 
  {res}0
{txt}
{com}.         di in red `r(N)' 
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}.         
.         * 4. Check that narrow activity categories sum to broad categories
.         ******************************************************************
.         
.         local prefix "prisd ope com" 
{txt}
{com}.         
.         //preserve 
.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(a_`var'_*) 
{txt}  3{com}.                 
.         {c )-}
{txt}
{com}.         
.         gen diff_prisd = sum_prisd - a_primary_sd 
{txt}
{com}.         gen flag_prisd = 1 if diff_prisd > 0.05 & diff_prisd != . 
{txt}(2 missing values generated)

{com}. 
.         gen diff_ope = sum_ope - a_operational 
{txt}
{com}.         gen flag_ope = 1 if diff_ope > 0.05 & diff_ope != . 
{txt}(2 missing values generated)

{com}.         
.         gen diff_com = sum_com - a_combo
{txt}
{com}.         gen flag_com = 1 if diff_com > 0.05 & diff_com != . 
{txt}(2 missing values generated)

{com}. 
. 
. 
.         
. 
. **************************************************************************              
. ** First, export of whole raw data before compression / aggregation
. **************************************************************************
. ** Begin by selecting key variables for export
.                 
.                 label var disease "Disease" 
{txt}
{com}.                 label var output_unit2 "Output unit"
{txt}
{com}.                 
.                 * Identifiers
.                 **************
.                 label var id "ID Variable"
{txt}
{com}.                 label var unit_cost "Unit Cost ID"
{txt}
{com}.                 
.                 *Bibliographic variables
.                 ************************
.                 label var lead_author "Lead Author"
{txt}
{com}.                 label var ref_year "Reference Year"
{txt}
{com}.                 label var title "Title"
{txt}
{com}.                 label var journal_etc "Journal"
{txt}
{com}.                 label var url "URL"
{txt}
{com}. 
.                 * Geography
.                 ************
.                 label var iso_name "Country"
{txt}
{com}.                 label var pop_density "Urbanicity"
{txt}
{com}.                 label var location "Location"   
{txt}
{com}.                 label var no_sites "Sites"
{txt}
{com}.                 
.                 *Intervention variables
.                 ***********************
.                 label var ownership "Ownership"
{txt}
{com}.                 
.                 * Generate a higher-level platform variable
.                         gen platform=.
{txt}(2 missing values generated)

{com}.                                 replace platform=1 if id_facility=="HC01" | id_facility=="HC02" | id_facility=="HC03" | id_facility=="HC04" | id_facility=="HC05" |  id_facility=="HC06" |  id_facility=="HC07" | id_facility=="HC08" | id_facility=="HC09" | id_facility=="HC10" | id_facility=="HC11"
{txt}(2 real changes made)

{com}.                                 replace platform=2 if id_facility=="OR01" | id_facility=="OR02" |  id_facility=="OR03" |  id_facility=="OR04" |  id_facility=="OR05"
{txt}(0 real changes made)

{com}.                                 replace platform=3 if id_facility=="CB01" | id_facility=="CB02" | id_facility=="CB03" | id_facility=="CB04"
{txt}(0 real changes made)

{com}.                                 replace platform=4 if id_facility=="PW01"
{txt}(0 real changes made)

{com}.                                 replace platform=5 if id_facility=="OT01" |id_facility=="OT02"
{txt}(0 real changes made)

{com}.                         
.                         label variable platform "Platform"
{txt}
{com}.                         label define platform 1 "Fixed facility" 2 "Outreach" 3 "Community based" 4 "Population wide" 5 "Other"
{txt}
{com}.                         label values platform platform
{txt}
{com}.                         
.                 label var facility_cat "Platform specificity" 
{txt}
{com}.                 label var id_class "Intervention Category"
{txt}
{com}.                 label var id_int "Intervention"         
{txt}
{com}.                 label var int_description_long "Intervention Description (Long)"
{txt}
{com}.                 label var clinical_monitoring "Clinical monitoring" 
{txt}
{com}.                 label var demand_generation "Demand generation" 
{txt}
{com}.                 label var counseling_content "Counseling content"
{txt}
{com}.                 label var staff_type "Staff type & number"
{txt}
{com}.                 label var supportive_care "Supportive care"
{txt}
{com}.                 label var visits "Visit type & number"
{txt}
{com}.                 label var referrals "Referrals"
{txt}
{com}.                 label var method "Method"
{txt}
{com}.                 label var id_tech "Technology"
{txt}
{com}.                 label var treatment_phase "Treatment phase"
{txt}
{com}.                 label var arv_regimen "ARV Regimen" 
{txt}
{com}.                 label var treatment "Treatment" 
{txt}
{com}.                 label var screening_diagnoses "Screening and diagnosis"
{txt}
{com}.                 label var community_awareness "Community awareness"
{txt}
{com}.                 label var id_activities "Costed activities"
{txt}
{com}.                 
.                 label var start_month "Start Month"
{txt}
{com}.                 label var start_year "Start Year"
{txt}
{com}.                 label var end_month "End Month"
{txt}
{com}.                 label var end_year "End Year"
{txt}
{com}.                 label var period_portrayed "Total Months"
{txt}
{com}.                 label var year_intro "Year introduced at study site"
{txt}
{com}.                 label var coverage "Coverage"
{txt}
{com}.                 
. 
.                 *Population
.                 ************
.                 label var id_pop_dem_std "Target group (demographic)"
{txt}
{com}.                 label var id_pop_clin_std "Target group (clinical)"
{txt}
{com}.                 label var pop_age "Average Age"
{txt}
{com}.                 label var pop_sex "Gender"
{txt}
{com}.                 label var pop_ses "SES"
{txt}
{com}.                 label var pop_education "Education"
{txt}
{com}.                 label var hiv_prev "HIV Prevalence"
{txt}
{com}.                 label var tb_prev "TB Prevalence"
{txt}
{com}.                 label var tb_rx_resistance "TB Drug Resistance"
{txt}
{com}.                  
.                 replace pop_age = subinstr(pop_age, "years", "", .)
{txt}(0 real changes made)

{com}.                 
.                 * Study Design
.                 ***************
.                 label var costing_purpose "Costing Purpose"
{txt}
{com}.                 label var timing "Timing"
{txt}
{com}.                 label var country_sampling "Country Sampling"
{txt}
{com}.                 label var geo_sampling_incountry "Geographic Area In Country Sampling"
{txt}
{com}.                 label var site_sampling "Site Sampling"
{txt}
{com}.                 label var px_sampling "Patient Sampling"
{txt}
{com}.                 label var sample_size_derived "Sample size formally derived"
{txt}
{com}.                 label var controls "Controls"
{txt}
{com}.         
.         /*
>         *Need to replace all missing values in categoricals with 999 so we can label them "."
>         foreach i of varlist ownership platform id_class id_type id_modality disease id_tech id_phase int_services country region pop_density pop_sex costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_report econ_perspective_actual econ_costing real_world asd_costs research_costs unrelated_costs overhead volunteer_time family_time iso_code currency_x {c -(}
>                         replace `i'=999 if `i'==.
>                         label define `i' 999 ".", add
>                         {c )-}
>         
>         *Need to do same with string variables
>         foreach i of varlist id unit_cost lead_author ref_author title journal_etc url id_facility id_details int_description_long location ss_unique_trait id_pop_std pop_age pop_ses pop_education hiv_prev cd4_range tb_prev list_asd_costs overhead_costs uncertainty_rmk {c -(}
>                 replace `i'="." if `i'==""
>                 {c )-}
>         */
.         
.                 * Costing methods
.                 *******************
.                 label var econ_perspective_actual "Perspective"
{txt}
{com}.                 label var econ_costing "Economic / Financial"
{txt}
{com}.                 label var real_world "Real World / Per Protocol"
{txt}
{com}.                 label var asd_costs "Above Service Costs Included"
{txt}
{com}.                 label var list_asd_costs "Above Service Cost List"
{txt}
{com}.                 label var omitted_costs "Omitted Costs"
{txt}
{com}.                 label var sensitivity_analysis "Sensitivity Analysis"
{txt}
{com}.                 label var scale "Economies of scale"
{txt}
{com}.                 
.                 label var research_costs "Research Costs Included"
{txt}
{com}.                 label var unrelated_costs "Unrelated Costs Included"
{txt}
{com}.                 label var overhead "Overhead Costs Included"
{txt}
{com}.                 label var overhead_costs "Overhead Costs List"
{txt}
{com}.                 label var pot_distortions "Potential distortions"
{txt}
{com}.                 
.                 label var volunteer_time "Valuing Volunteer Time"
{txt}
{com}.                 label var family_time "Valuing Family Time"
{txt}
{com}.                 label var px_costs_measured "Patient-Incurred Costs Measured"
{txt}
{com}.                 label var cat_cost "Catastrophic Cost Calculated"
{txt}
{com}.                 
.                 label var currency_yr "Reported Currency Year"
{txt}
{com}.                 label var iso_code "Reported Currency"
{txt}
{com}.                 label var currency_iso "Currency of Data Collection"
{txt}
{com}.                 label var currency_x "Currency Exchange Method"
{txt}
{com}.                 label var current_x_rate "Currency Exchange Rate"
{txt}
{com}.                 label var discount_rate "Discount Rate"
{txt}
{com}.                 label var inflation "Inflation rate"
{txt}
{com}.                 
.                         
.                 * Finally, relabel the cost categories
.                 ***************************************
.                 
.                 * Label remaining confusing variables
.                 label var mean_cost     "Mean Unit Cost"
{txt}
{com}.                 
.                 // Personnel
.                 label var si_personnel "Personnel (SI)"
{txt}
{com}.                 label var si_per_service_delivery "Personnel: Direct Service Delivery (SI)"
{txt}
{com}. 
.                 // Recurrent
.                 label var si_recurrent "Recurrent Goods (SI)"
{txt}
{com}.                 label var si_rec_other "Recurring: Other (SI)"
{txt}
{com}.                 label var si_rec_nonmed_int_supplies "Recurring: Non-medical Supplies (SI)"
{txt}
{com}.         
.                 // Activities 
.                 label var a_primary_sd "Primary Service Delivery (A)"
{txt}
{com}.                 label var a_prisd_unspecified "Primary SD: Unspecified (A)"
{txt}
{com}. 
.                 label var a_operational "Operational (A)"
{txt}
{com}.                 label var a_ope_unspecified "Operational: Unspecified (A)"
{txt}
{com}.                 label var a_ope_transportation "Operational: Transportation (A)"
{txt}
{com}.                 
. 
.                 * Create the missing columns 
.                 ******************************
.         
.                 gen si_rec_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_mixed "Recurring: Mixed (SI)" 
{txt}
{com}.                 
.                 gen si_rec_med_int_supplies = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_med_int_supplies "Recurring: Medical Supplies (excluding drugs) (SI)"
{txt}
{com}.                 
.                 gen si_rec_key_drugs = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_key_drugs "Recurring: Supplies (key drugs) (SI)" 
{txt}
{com}.                 
.                 gen si_rec_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_building_space "Recurring: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_per_support = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_support "Personnel: Support (SI)" 
{txt}
{com}.                 
.                 gen si_per_mixed_unspec = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_mixed_unspec "Personnel: Mixed Unspecified (SI)"
{txt}
{com}. 
.                 gen si_capital = . 
{txt}(2 missing values generated)

{com}.                 label var si_capital "Capital (SI)"
{txt}
{com}.                 
.                 gen si_cap_other = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_other "Capital: Other (SI)"
{txt}
{com}.                 
.                 gen si_cap_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_mixed "Capital: Mixed (SI)"
{txt}
{com}.                 
.                 gen si_cap_med_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_med_equip "Capital: Equipment (medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_nonmed_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_nonmed_equip "Capital: Equipment (non-medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_building_space "Capital: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_cap_vehicles = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_vehicles "Capital: Vehicles (SI)"
{txt}
{com}.                 
.                 gen si_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_mixed "Mixed (SI)"
{txt}
{com}.                 
.                 gen si_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var si_unspecified "Unspecified (SI)"
{txt}
{com}.                 
.                 gen a_prisd_unspec_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_unspec_counseling "Primary SD: Counseling unspecified (A)"
{txt}
{com}.                 
.                 gen a_prisd_post_test_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_post_test_counseling "Primary SD: Post-test counseling (A)"
{txt}
{com}.                 
.                 gen a_prisd_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_lab_services "Primary SD: Lab services (A)"
{txt}
{com}.                 
.                 gen a_prisd_htc_service_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_htc_service_delivery "Primary SD: HTC service delivery (A)"
{txt}
{com}.                 
.                 gen a_prisd_hiv_rapid_test = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_hiv_rapid_test "Primary SD: HIV rapid testing (A)"
{txt}
{com}.                 
.                 gen a_prisd_arv_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_arv_delivery "Primary SD: ARV delivery"
{txt}
{com}.                 
.                 gen a_anc_adhreten = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_adhreten "Ancillary: Adherence/Retention (A)" 
{txt}
{com}.                 
.                 gen a_anc_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_lab_services "Ancillary: Lab Services (A)"
{txt}
{com}.                 
.                 gen a_ancillary = . 
{txt}(2 missing values generated)

{com}.                 label var a_ancillary "Ancillary (A)"
{txt}
{com}.                 
.                 gen a_anc_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_unspecified "Ancillary: Unspecified (A)"
{txt}
{com}.                 
.                 gen a_anc_demand_generation = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_demand_generation "Ancillary: Demand generation (A)"
{txt}
{com}.                 
.                 gen a_anc_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_bldg_equip "Ancillary: Building equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_training = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_training "Operational: Training (A)"
{txt}
{com}.                 
.                 gen a_ope_program_mgmt = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_program_mgmt "Operational: Program Management (A)"
{txt}
{com}.                 
.                 gen a_ope_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_bldg_equip "Operational: Buildings and Equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_logistics = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_logistics "Operational: Logistics (A)"
{txt}
{com}.                 
.                 gen a_ope_supervision = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_supervision "Operational: Supervision (A)"
{txt}
{com}.                 
.                 gen a_ope_massed = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_massed "Operational: Mass Education (A)" 
{txt}
{com}.                 
.                 gen a_ope_hmis = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_hmis "Operational: HMIS and Record-Keeping (A)"
{txt}
{com}.                 
.                 gen a_secondary_sd = . 
{txt}(2 missing values generated)

{com}.                 label var a_secondary_sd "Secondary Service Delivery (A)"
{txt}
{com}.                         
.                 gen a_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var a_mixed "Mixed (A)"
{txt}
{com}.                 
.                 gen a_mix_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_mix_bldg_equip "Mixed: Building Equipment (A)"
{txt}
{com}.                 
.                 gen a_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_unspecified "Unspecified (A)" 
{txt}
{com}. 
. 
.                 
.         * And for the collapse: 
.                 *Generate a variable to tell collapsed costs from full costs
.                 gen collapsed=0
{txt}
{com}.                 * Need to create an id without (a) for grouping collapse
.                 gen study=substr(id, 1, length(id)-1)
{txt}
{com}.                 
.                                 label variable study "Study"
{txt}
{com}.                                 label variable collapsed "Collapsed"
{txt}
{com}.                                 
.                                 label define collapsed 0 "No" 1 "Yes"
{txt}
{com}.                                 label values collapsed collapsed
{txt}
{com}.                 
.                 *Create a caveats variable 
.                                         //gen flags="." 
.                                         
. 
. **************************************************************************              
. ** Replace N/A, NR and none with missing
. **************************************************************************      
. 
. local to_decode "disease collapsed output_unit2 pop_density ownership platform facility_cat id_class id_int method id_tech pop_sex tb_rx_resistance timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_actual econ_costing real_world asd_costs sensitivity_analysis scale research_costs unrelated_costs overhead volunteer_time family_time px_costs_measured cat_cost iso_code currency_iso currency_x inflation" 
{txt}
{com}. 
. foreach var of local to_decode {c -(} 
{txt}  2{com}.         decode `var', gen(`var'_new) 
{txt}  3{com}.         drop `var'
{txt}  4{com}.         rename `var'_new `var' 
{txt}  5{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  6{com}.         
.         replace `var' = strproper(`var')
{txt}  7{com}. {c )-}
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)

{com}. 
. foreach var of varlist clinical_monitoring demand_generation counseling_content staff_type supportive_care visits referrals id_activities list_asd_cost overhead_costs {c -(} 
{txt}  2{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  3{com}.         
.         replace `var' = strproper(`var')
{txt}  4{com}. 
. {c )-}
{txt}(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)

{com}. 
.   
. replace disease = strupper(disease) 
{txt}(2 real changes made)

{com}. replace id_int = strupper(id_int) 
{txt}(2 real changes made)

{com}. replace iso_code = strupper(iso_code)
{txt}(2 real changes made)

{com}. replace currency_iso = strupper(currency_iso)
{txt}(2 real changes made)

{com}. replace pot_distortions = strupper(pot_distortions)
{txt}(0 real changes made)

{com}. 
. 
. 
. ****************************************************************************            
. ** Cross-validation of costed activities and intervention details columns **
. ****************************************************************************
. 
.         gen flag = 1 if regexm(id_activities, "HTC") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_1 = 1 if regexm(id_activities, "ARV") & arv_regimen == "."
{txt}(2 missing values generated)

{com}.         gen flag_2 = 1 if regexm(id_activities, "ARV") & treatment == "."
{txt}(2 missing values generated)

{com}.         gen flag_3 = 1 if regexm(id_activities, "counsel") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_4 = 1 if regexm(id_activities, "VCT") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_5 = 1 if regexm(id_activities, "CD4") & clinical_monitoring == "." 
{txt}(2 missing values generated)

{com}.         gen flag_6 = 1 if regexm(id_activities, "iagnosis") & clinical_monitoring == "."
{txt}(2 missing values generated)

{com}.         
.         
.         local varlist cost_activities "clinical_monitoring demand_generation counseling_content supportive_care referrals arv_regimen screening_diagnoses treatment community_awareness health_system id_tech" 
{txt}
{com}.         
.         gen supportive_care_flag = 1 if regexm(id_activities, "Supportive") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(2 missing values generated)

{com}.         replace supportive_care_flag = 1 if regexm(id_activities, "support") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(0 real changes made)

{com}.         replace supportive_care_flag = 1 if supportive_care != "." & !(strmatch(id_activities, "*upport*"))
{txt}(0 real changes made)

{com}.         
.         gen clinical_mo_flag = 1 if regexm(id_activities, "CD4|iagnosis") & (clinical_monitoring == "." | clinical_monitoring == "N/A" | clinical_monitoring == "NR")
{txt}(2 missing values generated)

{com}.         replace clinical_mo_flag = 1 if clinical_monitoring != "." & (!(strmatch(id_activities, "*CD4*")) & !(strmatch(id_activities, "*iagnosis*")))
{txt}(0 real changes made)

{com}.         
.         gen counsel_flag = 1 if regexm(id_activities, "ounsel|VCT") & (counseling_content == "." | counseling_content == "N/A" | counseling_content == "NR")
{txt}(2 missing values generated)

{com}.         replace counsel_flag = 1 if counseling_content != "." & !(strmatch(id_activities, "*ounsel*"))
{txt}(0 real changes made)

{com}.         
.         gen demand_gen_flag = 1 if regexm(id_activities, "emand|generation") & (demand_generation == "." | demand_generation == "N/A" | demand_generation == "NR")
{txt}(2 missing values generated)

{com}.         replace demand_gen_flag = 1 if demand_generation != "." & demand_generation != "None" & !(strmatch(id_activities, "*eneration*"))
{txt}(0 real changes made)

{com}.         
.         gen referrals_flag = 1 if regexm(id_activities, "eferrals") & (referrals == "." | referrals == "N/A" | referrals == "NR")
{txt}(2 missing values generated)

{com}.         replace referrals_flag = 1 if referrals != "." & !(strmatch(id_activities, "*eferrals*"))
{txt}(0 real changes made)

{com}.         
.         gen arv_regimen_flag = 1 if regexm(id_activities, "ARV") & (arv_regimen == "." | arv_regimen == "N/A" | arv_regimen == "NR")
{txt}(2 missing values generated)

{com}.         replace arv_regimen_flag = 1 if arv_regimen != "." & arv_regimen != "N/A" & arv_regimen != "NR" & (!(strmatch(id_activities, "*ARV*")) & !(strmatch(id_activities, "*Arv*")))
{txt}(0 real changes made)

{com}.         
.         gen screen_diag_flag = 1 if regexm(id_activities, "iagnoses") & (screening_diagnoses == "." | screening_diagnoses == "N/A" | screening_diagnoses == "NR")
{txt}(2 missing values generated)

{com}.         
.         replace screen_diag_flag = 1 if screening_diagnoses != "." & screening_diagnoses != "NA" & screening_diagnoses != "NR" & !(strmatch(id_activities, "*iagno*"))
{txt}(0 real changes made)

{com}.         
.         gen treatment_flag = 1 if regexm(id_activities, "reatment") & (treatment == "." | treatment == "N/A" | treatment == "NR") 
{txt}(2 missing values generated)

{com}.         replace treatment_flag = 1 if treatment != "." & treatment != "N/A" & treatment != "NR" & !(strmatch(id_activities, "*reatment*"))
{txt}(0 real changes made)

{com}.         
.         gen comm_awareness_flag = 1 if regexm(id_activities, "wareness") & (community_awareness == "." | community_awareness == "N/A" | community_awareness == "NR") 
{txt}(2 missing values generated)

{com}.         replace comm_awareness_flag = 1 if community_awareness != "." & community_awareness != "N/A" & community_awareness != "NR" & community_awareness != "None" & !(strmatch(id_activities, "*wareness*"))
{txt}(0 real changes made)

{com}.         
.         gen health_system_flag = 1 if regexm(id_activities, "system") & (health_system == "." | health_system == "N/A" | health_system == "NR") 
{txt}(2 missing values generated)

{com}.         replace health_system_flag = 1 if health_system != "." & health_system != "N/A" & health_system != "NR" & !(strmatch(id_activities, "*ystem*"))
{txt}(0 real changes made)

{com}.         
.         gen tech_flag = 1 if regexm(id_activities, "echnology") & (technology == "." | technology == "N/A" | technology == "NR") 
{err}technology not found
{txt}{search r(111), local:r(111);}

end of do-file

{search r(111), local:r(111);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. **************************************************************************
. **************************************************************************
. **************************************************************************
. ** Do file for export of VMMC studies to the UCSR, using select variables
. ** Lily Alexander
. ** University of Washington
. ** February 2018 
. ** lilyalexander18@gmail.com
. **************************************************************************
. **************************************************************************
. **************************************************************************
. 
. ** Data requirements
. **
. **  Must use data already formatted into wide file for GHCC analysis
. **              - These are available upon request
. **              - Procedure to be replicated for other intervention areas (ART, etc)
. **              - As well as other diseases (TB)
. **************************************************************************
. 
. set more off 
{txt}
{com}.         clear
{txt}
{com}.         *Drew's Path:
.         //cd "/Users/dcameron03/Documents/GitHub/Post-Extraction-Processing/VMMC/"
.         //use VMMC_wide_file.dta, replace       
.         *Lily's Path:
.         * cd "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/VMMC"
.         *       use VMMC_wide_file_Feb2018.dta
.         *Lily's temporary path: 
.         cd "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files
{txt}
{com}.         use pat_tracking_wide_file_Apr2018.dta, replace
{txt}
{com}. 
. 
. **********************************              
. ** Cross-validation of costs **
. **********************************
.         
.         * 1. Check that broad standard input categories sum to mean cost 
.         ****************************************************************
.         egen check = rowtotal(si_recurrent si_personnel)
{txt}
{com}.         replace check = si_combined if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1
  {res}0
{txt}
{com}.         di in red `r(N)'
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}. 
.         
.         * 2. Check that narrow standard input categories sum to broad categories
.         ************************************************************************
.         
.         local prefix "rec per" 
{txt}
{com}.                 
.         preserve 
{txt}
{com}.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(si_`var'_*)
{txt}  3{com}.                 drop si_`var'_*
{txt}  4{com}.                 gen diff_`var' = sum_`var' - si_`var'
{txt}  5{com}.                 gen flag_`var' = 1 if diff_`var' > 0.05 & diff_`var' !=. 
{txt}  6{com}.         
.         {c )-}
{txt}(2 missing values generated)
(2 missing values generated)

{com}.         restore
{txt}
{com}.         
.         * 3. Check that broad activity categories sum to mean cost 
.         **********************************************************
.         
.         egen check = rowtotal(a_primary_sd a_operational)
{txt}
{com}.         replace check = a_combo if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1 
  {res}0
{txt}
{com}.         di in red `r(N)' 
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}.         
.         * 4. Check that narrow activity categories sum to broad categories
.         ******************************************************************
.         
.         local prefix "prisd ope com" 
{txt}
{com}.         
.         //preserve 
.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(a_`var'_*) 
{txt}  3{com}.                 
.         {c )-}
{txt}
{com}.         
.         gen diff_prisd = sum_prisd - a_primary_sd 
{txt}
{com}.         gen flag_prisd = 1 if diff_prisd > 0.05 & diff_prisd != . 
{txt}(2 missing values generated)

{com}. 
.         gen diff_ope = sum_ope - a_operational 
{txt}
{com}.         gen flag_ope = 1 if diff_ope > 0.05 & diff_ope != . 
{txt}(2 missing values generated)

{com}.         
.         gen diff_com = sum_com - a_combo
{txt}
{com}.         gen flag_com = 1 if diff_com > 0.05 & diff_com != . 
{txt}(2 missing values generated)

{com}. 
. 
. 
.         
. 
. **************************************************************************              
. ** First, export of whole raw data before compression / aggregation
. **************************************************************************
. ** Begin by selecting key variables for export
.                 
.                 label var disease "Disease" 
{txt}
{com}.                 label var output_unit2 "Output unit"
{txt}
{com}.                 
.                 * Identifiers
.                 **************
.                 label var id "ID Variable"
{txt}
{com}.                 label var unit_cost "Unit Cost ID"
{txt}
{com}.                 
.                 *Bibliographic variables
.                 ************************
.                 label var lead_author "Lead Author"
{txt}
{com}.                 label var ref_year "Reference Year"
{txt}
{com}.                 label var title "Title"
{txt}
{com}.                 label var journal_etc "Journal"
{txt}
{com}.                 label var url "URL"
{txt}
{com}. 
.                 * Geography
.                 ************
.                 label var iso_name "Country"
{txt}
{com}.                 label var pop_density "Urbanicity"
{txt}
{com}.                 label var location "Location"   
{txt}
{com}.                 label var no_sites "Sites"
{txt}
{com}.                 
.                 *Intervention variables
.                 ***********************
.                 label var ownership "Ownership"
{txt}
{com}.                 
.                 * Generate a higher-level platform variable
.                         gen platform=.
{txt}(2 missing values generated)

{com}.                                 replace platform=1 if id_facility=="HC01" | id_facility=="HC02" | id_facility=="HC03" | id_facility=="HC04" | id_facility=="HC05" |  id_facility=="HC06" |  id_facility=="HC07" | id_facility=="HC08" | id_facility=="HC09" | id_facility=="HC10" | id_facility=="HC11"
{txt}(2 real changes made)

{com}.                                 replace platform=2 if id_facility=="OR01" | id_facility=="OR02" |  id_facility=="OR03" |  id_facility=="OR04" |  id_facility=="OR05"
{txt}(0 real changes made)

{com}.                                 replace platform=3 if id_facility=="CB01" | id_facility=="CB02" | id_facility=="CB03" | id_facility=="CB04"
{txt}(0 real changes made)

{com}.                                 replace platform=4 if id_facility=="PW01"
{txt}(0 real changes made)

{com}.                                 replace platform=5 if id_facility=="OT01" |id_facility=="OT02"
{txt}(0 real changes made)

{com}.                         
.                         label variable platform "Platform"
{txt}
{com}.                         label define platform 1 "Fixed facility" 2 "Outreach" 3 "Community based" 4 "Population wide" 5 "Other"
{txt}
{com}.                         label values platform platform
{txt}
{com}.                         
.                 label var facility_cat "Platform specificity" 
{txt}
{com}.                 label var id_class "Intervention Category"
{txt}
{com}.                 label var id_int "Intervention"         
{txt}
{com}.                 label var int_description_long "Intervention Description (Long)"
{txt}
{com}.                 label var clinical_monitoring "Clinical monitoring" 
{txt}
{com}.                 label var demand_generation "Demand generation" 
{txt}
{com}.                 label var counseling_content "Counseling content"
{txt}
{com}.                 label var staff_type "Staff type & number"
{txt}
{com}.                 label var supportive_care "Supportive care"
{txt}
{com}.                 label var visits "Visit type & number"
{txt}
{com}.                 label var referrals "Referrals"
{txt}
{com}.                 label var method "Method"
{txt}
{com}.                 label var id_tech "Technology"
{txt}
{com}.                 label var treatment_phase "Treatment phase"
{txt}
{com}.                 label var arv_regimen "ARV Regimen" 
{txt}
{com}.                 label var treatment "Treatment" 
{txt}
{com}.                 label var screening_diagnoses "Screening and diagnosis"
{txt}
{com}.                 label var community_awareness "Community awareness"
{txt}
{com}.                 label var id_activities "Costed activities"
{txt}
{com}.                 
.                 label var start_month "Start Month"
{txt}
{com}.                 label var start_year "Start Year"
{txt}
{com}.                 label var end_month "End Month"
{txt}
{com}.                 label var end_year "End Year"
{txt}
{com}.                 label var period_portrayed "Total Months"
{txt}
{com}.                 label var year_intro "Year introduced at study site"
{txt}
{com}.                 label var coverage "Coverage"
{txt}
{com}.                 
. 
.                 *Population
.                 ************
.                 label var id_pop_dem_std "Target group (demographic)"
{txt}
{com}.                 label var id_pop_clin_std "Target group (clinical)"
{txt}
{com}.                 label var pop_age "Average Age"
{txt}
{com}.                 label var pop_sex "Gender"
{txt}
{com}.                 label var pop_ses "SES"
{txt}
{com}.                 label var pop_education "Education"
{txt}
{com}.                 label var hiv_prev "HIV Prevalence"
{txt}
{com}.                 label var tb_prev "TB Prevalence"
{txt}
{com}.                 label var tb_rx_resistance "TB Drug Resistance"
{txt}
{com}.                  
.                 replace pop_age = subinstr(pop_age, "years", "", .)
{txt}(0 real changes made)

{com}.                 
.                 * Study Design
.                 ***************
.                 label var costing_purpose "Costing Purpose"
{txt}
{com}.                 label var timing "Timing"
{txt}
{com}.                 label var country_sampling "Country Sampling"
{txt}
{com}.                 label var geo_sampling_incountry "Geographic Area In Country Sampling"
{txt}
{com}.                 label var site_sampling "Site Sampling"
{txt}
{com}.                 label var px_sampling "Patient Sampling"
{txt}
{com}.                 label var sample_size_derived "Sample size formally derived"
{txt}
{com}.                 label var controls "Controls"
{txt}
{com}.         
.         /*
>         *Need to replace all missing values in categoricals with 999 so we can label them "."
>         foreach i of varlist ownership platform id_class id_type id_modality disease id_tech id_phase int_services country region pop_density pop_sex costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_report econ_perspective_actual econ_costing real_world asd_costs research_costs unrelated_costs overhead volunteer_time family_time iso_code currency_x {c -(}
>                         replace `i'=999 if `i'==.
>                         label define `i' 999 ".", add
>                         {c )-}
>         
>         *Need to do same with string variables
>         foreach i of varlist id unit_cost lead_author ref_author title journal_etc url id_facility id_details int_description_long location ss_unique_trait id_pop_std pop_age pop_ses pop_education hiv_prev cd4_range tb_prev list_asd_costs overhead_costs uncertainty_rmk {c -(}
>                 replace `i'="." if `i'==""
>                 {c )-}
>         */
.         
.                 * Costing methods
.                 *******************
.                 label var econ_perspective_actual "Perspective"
{txt}
{com}.                 label var econ_costing "Economic / Financial"
{txt}
{com}.                 label var real_world "Real World / Per Protocol"
{txt}
{com}.                 label var asd_costs "Above Service Costs Included"
{txt}
{com}.                 label var list_asd_costs "Above Service Cost List"
{txt}
{com}.                 label var omitted_costs "Omitted Costs"
{txt}
{com}.                 label var sensitivity_analysis "Sensitivity Analysis"
{txt}
{com}.                 label var scale "Economies of scale"
{txt}
{com}.                 
.                 label var research_costs "Research Costs Included"
{txt}
{com}.                 label var unrelated_costs "Unrelated Costs Included"
{txt}
{com}.                 label var overhead "Overhead Costs Included"
{txt}
{com}.                 label var overhead_costs "Overhead Costs List"
{txt}
{com}.                 label var pot_distortions "Potential distortions"
{txt}
{com}.                 
.                 label var volunteer_time "Valuing Volunteer Time"
{txt}
{com}.                 label var family_time "Valuing Family Time"
{txt}
{com}.                 label var px_costs_measured "Patient-Incurred Costs Measured"
{txt}
{com}.                 label var cat_cost "Catastrophic Cost Calculated"
{txt}
{com}.                 
.                 label var currency_yr "Reported Currency Year"
{txt}
{com}.                 label var iso_code "Reported Currency"
{txt}
{com}.                 label var currency_iso "Currency of Data Collection"
{txt}
{com}.                 label var currency_x "Currency Exchange Method"
{txt}
{com}.                 label var current_x_rate "Currency Exchange Rate"
{txt}
{com}.                 label var discount_rate "Discount Rate"
{txt}
{com}.                 label var inflation "Inflation rate"
{txt}
{com}.                 
.                         
.                 * Finally, relabel the cost categories
.                 ***************************************
.                 
.                 * Label remaining confusing variables
.                 label var mean_cost     "Mean Unit Cost"
{txt}
{com}.                 
.                 // Personnel
.                 label var si_personnel "Personnel (SI)"
{txt}
{com}.                 label var si_per_service_delivery "Personnel: Direct Service Delivery (SI)"
{txt}
{com}. 
.                 // Recurrent
.                 label var si_recurrent "Recurrent Goods (SI)"
{txt}
{com}.                 label var si_rec_other "Recurring: Other (SI)"
{txt}
{com}.                 label var si_rec_nonmed_int_supplies "Recurring: Non-medical Supplies (SI)"
{txt}
{com}.         
.                 // Activities 
.                 label var a_primary_sd "Primary Service Delivery (A)"
{txt}
{com}.                 label var a_prisd_unspecified "Primary SD: Unspecified (A)"
{txt}
{com}. 
.                 label var a_operational "Operational (A)"
{txt}
{com}.                 label var a_ope_unspecified "Operational: Unspecified (A)"
{txt}
{com}.                 label var a_ope_transportation "Operational: Transportation (A)"
{txt}
{com}.                 
. 
.                 * Create the missing columns 
.                 ******************************
.         
.                 gen si_rec_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_mixed "Recurring: Mixed (SI)" 
{txt}
{com}.                 
.                 gen si_rec_med_int_supplies = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_med_int_supplies "Recurring: Medical Supplies (excluding drugs) (SI)"
{txt}
{com}.                 
.                 gen si_rec_key_drugs = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_key_drugs "Recurring: Supplies (key drugs) (SI)" 
{txt}
{com}.                 
.                 gen si_rec_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_building_space "Recurring: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_per_support = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_support "Personnel: Support (SI)" 
{txt}
{com}.                 
.                 gen si_per_mixed_unspec = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_mixed_unspec "Personnel: Mixed Unspecified (SI)"
{txt}
{com}. 
.                 gen si_capital = . 
{txt}(2 missing values generated)

{com}.                 label var si_capital "Capital (SI)"
{txt}
{com}.                 
.                 gen si_cap_other = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_other "Capital: Other (SI)"
{txt}
{com}.                 
.                 gen si_cap_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_mixed "Capital: Mixed (SI)"
{txt}
{com}.                 
.                 gen si_cap_med_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_med_equip "Capital: Equipment (medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_nonmed_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_nonmed_equip "Capital: Equipment (non-medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_building_space "Capital: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_cap_vehicles = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_vehicles "Capital: Vehicles (SI)"
{txt}
{com}.                 
.                 gen si_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_mixed "Mixed (SI)"
{txt}
{com}.                 
.                 gen si_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var si_unspecified "Unspecified (SI)"
{txt}
{com}.                 
.                 gen a_prisd_unspec_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_unspec_counseling "Primary SD: Counseling unspecified (A)"
{txt}
{com}.                 
.                 gen a_prisd_post_test_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_post_test_counseling "Primary SD: Post-test counseling (A)"
{txt}
{com}.                 
.                 gen a_prisd_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_lab_services "Primary SD: Lab services (A)"
{txt}
{com}.                 
.                 gen a_prisd_htc_service_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_htc_service_delivery "Primary SD: HTC service delivery (A)"
{txt}
{com}.                 
.                 gen a_prisd_hiv_rapid_test = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_hiv_rapid_test "Primary SD: HIV rapid testing (A)"
{txt}
{com}.                 
.                 gen a_prisd_arv_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_arv_delivery "Primary SD: ARV delivery"
{txt}
{com}.                 
.                 gen a_anc_adhreten = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_adhreten "Ancillary: Adherence/Retention (A)" 
{txt}
{com}.                 
.                 gen a_anc_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_lab_services "Ancillary: Lab Services (A)"
{txt}
{com}.                 
.                 gen a_ancillary = . 
{txt}(2 missing values generated)

{com}.                 label var a_ancillary "Ancillary (A)"
{txt}
{com}.                 
.                 gen a_anc_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_unspecified "Ancillary: Unspecified (A)"
{txt}
{com}.                 
.                 gen a_anc_demand_generation = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_demand_generation "Ancillary: Demand generation (A)"
{txt}
{com}.                 
.                 gen a_anc_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_bldg_equip "Ancillary: Building equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_training = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_training "Operational: Training (A)"
{txt}
{com}.                 
.                 gen a_ope_program_mgmt = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_program_mgmt "Operational: Program Management (A)"
{txt}
{com}.                 
.                 gen a_ope_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_bldg_equip "Operational: Buildings and Equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_logistics = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_logistics "Operational: Logistics (A)"
{txt}
{com}.                 
.                 gen a_ope_supervision = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_supervision "Operational: Supervision (A)"
{txt}
{com}.                 
.                 gen a_ope_massed = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_massed "Operational: Mass Education (A)" 
{txt}
{com}.                 
.                 gen a_ope_hmis = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_hmis "Operational: HMIS and Record-Keeping (A)"
{txt}
{com}.                 
.                 gen a_secondary_sd = . 
{txt}(2 missing values generated)

{com}.                 label var a_secondary_sd "Secondary Service Delivery (A)"
{txt}
{com}.                         
.                 gen a_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var a_mixed "Mixed (A)"
{txt}
{com}.                 
.                 gen a_mix_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_mix_bldg_equip "Mixed: Building Equipment (A)"
{txt}
{com}.                 
.                 gen a_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_unspecified "Unspecified (A)" 
{txt}
{com}. 
. 
.                 
.         * And for the collapse: 
.                 *Generate a variable to tell collapsed costs from full costs
.                 gen collapsed=0
{txt}
{com}.                 * Need to create an id without (a) for grouping collapse
.                 gen study=substr(id, 1, length(id)-1)
{txt}
{com}.                 
.                                 label variable study "Study"
{txt}
{com}.                                 label variable collapsed "Collapsed"
{txt}
{com}.                                 
.                                 label define collapsed 0 "No" 1 "Yes"
{txt}
{com}.                                 label values collapsed collapsed
{txt}
{com}.                 
.                 *Create a caveats variable 
.                                         //gen flags="." 
.                                         
. 
. **************************************************************************              
. ** Replace N/A, NR and none with missing
. **************************************************************************      
. 
. local to_decode "disease collapsed output_unit2 pop_density ownership platform facility_cat id_class id_int method id_tech pop_sex tb_rx_resistance timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_actual econ_costing real_world asd_costs sensitivity_analysis scale research_costs unrelated_costs overhead volunteer_time family_time px_costs_measured cat_cost iso_code currency_iso currency_x inflation" 
{txt}
{com}. 
. foreach var of local to_decode {c -(} 
{txt}  2{com}.         decode `var', gen(`var'_new) 
{txt}  3{com}.         drop `var'
{txt}  4{com}.         rename `var'_new `var' 
{txt}  5{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  6{com}.         
.         replace `var' = strproper(`var')
{txt}  7{com}. {c )-}
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)

{com}. 
. foreach var of varlist clinical_monitoring demand_generation counseling_content staff_type supportive_care visits referrals id_activities list_asd_cost overhead_costs {c -(} 
{txt}  2{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  3{com}.         
.         replace `var' = strproper(`var')
{txt}  4{com}. 
. {c )-}
{txt}(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)

{com}. 
.   
. replace disease = strupper(disease) 
{txt}(2 real changes made)

{com}. replace id_int = strupper(id_int) 
{txt}(2 real changes made)

{com}. replace iso_code = strupper(iso_code)
{txt}(2 real changes made)

{com}. replace currency_iso = strupper(currency_iso)
{txt}(2 real changes made)

{com}. replace pot_distortions = strupper(pot_distortions)
{txt}(0 real changes made)

{com}. 
. 
. 
. ****************************************************************************            
. ** Cross-validation of costed activities and intervention details columns **
. ****************************************************************************
. 
.         gen flag = 1 if regexm(id_activities, "HTC") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_1 = 1 if regexm(id_activities, "ARV") & arv_regimen == "."
{txt}(2 missing values generated)

{com}.         gen flag_2 = 1 if regexm(id_activities, "ARV") & treatment == "."
{txt}(2 missing values generated)

{com}.         gen flag_3 = 1 if regexm(id_activities, "counsel") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_4 = 1 if regexm(id_activities, "VCT") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_5 = 1 if regexm(id_activities, "CD4") & clinical_monitoring == "." 
{txt}(2 missing values generated)

{com}.         gen flag_6 = 1 if regexm(id_activities, "iagnosis") & clinical_monitoring == "."
{txt}(2 missing values generated)

{com}.         
.         
.         local varlist cost_activities "clinical_monitoring demand_generation counseling_content supportive_care referrals arv_regimen screening_diagnoses treatment community_awareness health_system id_tech" 
{txt}
{com}.         
.         gen supportive_care_flag = 1 if regexm(id_activities, "Supportive") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(2 missing values generated)

{com}.         replace supportive_care_flag = 1 if regexm(id_activities, "support") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(0 real changes made)

{com}.         replace supportive_care_flag = 1 if supportive_care != "." & !(strmatch(id_activities, "*upport*"))
{txt}(0 real changes made)

{com}.         
.         gen clinical_mo_flag = 1 if regexm(id_activities, "CD4|iagnosis") & (clinical_monitoring == "." | clinical_monitoring == "N/A" | clinical_monitoring == "NR")
{txt}(2 missing values generated)

{com}.         replace clinical_mo_flag = 1 if clinical_monitoring != "." & (!(strmatch(id_activities, "*CD4*")) & !(strmatch(id_activities, "*iagnosis*")))
{txt}(0 real changes made)

{com}.         
.         gen counsel_flag = 1 if regexm(id_activities, "ounsel|VCT") & (counseling_content == "." | counseling_content == "N/A" | counseling_content == "NR")
{txt}(2 missing values generated)

{com}.         replace counsel_flag = 1 if counseling_content != "." & !(strmatch(id_activities, "*ounsel*"))
{txt}(0 real changes made)

{com}.         
.         gen demand_gen_flag = 1 if regexm(id_activities, "emand|generation") & (demand_generation == "." | demand_generation == "N/A" | demand_generation == "NR")
{txt}(2 missing values generated)

{com}.         replace demand_gen_flag = 1 if demand_generation != "." & demand_generation != "None" & !(strmatch(id_activities, "*eneration*"))
{txt}(0 real changes made)

{com}.         
.         gen referrals_flag = 1 if regexm(id_activities, "eferrals") & (referrals == "." | referrals == "N/A" | referrals == "NR")
{txt}(2 missing values generated)

{com}.         replace referrals_flag = 1 if referrals != "." & !(strmatch(id_activities, "*eferrals*"))
{txt}(0 real changes made)

{com}.         
.         gen arv_regimen_flag = 1 if regexm(id_activities, "ARV") & (arv_regimen == "." | arv_regimen == "N/A" | arv_regimen == "NR")
{txt}(2 missing values generated)

{com}.         replace arv_regimen_flag = 1 if arv_regimen != "." & arv_regimen != "N/A" & arv_regimen != "NR" & (!(strmatch(id_activities, "*ARV*")) & !(strmatch(id_activities, "*Arv*")))
{txt}(0 real changes made)

{com}.         
.         gen screen_diag_flag = 1 if regexm(id_activities, "iagnoses") & (screening_diagnoses == "." | screening_diagnoses == "N/A" | screening_diagnoses == "NR")
{txt}(2 missing values generated)

{com}.         
.         replace screen_diag_flag = 1 if screening_diagnoses != "." & screening_diagnoses != "NA" & screening_diagnoses != "NR" & !(strmatch(id_activities, "*iagno*"))
{txt}(0 real changes made)

{com}.         
.         gen treatment_flag = 1 if regexm(id_activities, "reatment") & (treatment == "." | treatment == "N/A" | treatment == "NR") 
{txt}(2 missing values generated)

{com}.         replace treatment_flag = 1 if treatment != "." & treatment != "N/A" & treatment != "NR" & !(strmatch(id_activities, "*reatment*"))
{txt}(0 real changes made)

{com}.         
.         gen comm_awareness_flag = 1 if regexm(id_activities, "wareness") & (community_awareness == "." | community_awareness == "N/A" | community_awareness == "NR") 
{txt}(2 missing values generated)

{com}.         replace comm_awareness_flag = 1 if community_awareness != "." & community_awareness != "N/A" & community_awareness != "NR" & community_awareness != "None" & !(strmatch(id_activities, "*wareness*"))
{txt}(0 real changes made)

{com}.         
.         gen health_system_flag = 1 if regexm(id_activities, "system") & (health_system == "." | health_system == "N/A" | health_system == "NR") 
{txt}(2 missing values generated)

{com}.         replace health_system_flag = 1 if health_system != "." & health_system != "N/A" & health_system != "NR" & !(strmatch(id_activities, "*ystem*"))
{txt}(0 real changes made)

{com}.         
.         gen tech_flag = 1 if regexm(id_activities, "echnology") & (id_tech == "." | id_tech == "N/A" | id_tech == "NR") 
{txt}(2 missing values generated)

{com}.         replace tech_flag = 1 if id_tech != "." & id_tech != "N/A" & id_tech != "NR" & !(strmatch(id_tech, "*ecnology*"))
{txt}(2 real changes made)

{com}. 
. /*
> **************************************************************************              
> ** Order variables 
> **************************************************************************              
> 
> order disease collapsed lead_author ref_year output_unit2 ref_year title journal_etc url /// 
> iso_name location no_sites pop_density ownership platform facility_cat id_class id_int int_description_long /// 
> clinical_monitoring demand_generation counseling_content staff_type supportive_care visits referrals method id_tech /// 
> treatment_phase arv_regimen treatment screening_diagnoses community_awareness health_system id_activities /// 
> start_month start_year end_month end_year period_portrayed year_intro coverage /// 
> id_pop_dem_std id_pop_clin_std pop_age pop_sex pop_ses pop_education hiv_prev tb_prev tb_rx_resistance /// 
> costing_purpose timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls /// 
> econ_perspective_actual econ_costing real_world asd_costs list_asd_costs omitted_costs sensitivity_analysis scale /// 
> research_costs unrelated_costs overhead overhead_costs pot_distortions /// 
> volunteer_time family_time px_costs_measured cat_cost currency_yr iso_code currency_iso currency_x current_x_rate discount_rate inflation /// 
> mean_cost si_personnel si_per_service_delivery si_per_support si_per_mixed_unspec /// 
> si_recurrent si_rec_key_drugs si_rec_med_int_supplies si_rec_nonmed_int_supplies si_rec_building_space si_rec_mixed si_rec_other /// 
> si_capital si_cap_med_equip si_cap_nonmed_equip si_cap_build si_cap_vehic si_cap_mixed si_cap_other si_mixed si_unspecified /// 
> a_primary_sd  a_prisd_unspecified a_prisd_unspec_counseling a_prisd_post_test_counseling a_prisd_lab_services a_prisd_htc_service_delivery a_prisd_hiv_rapid_test a_prisd_arv_delivery /// 
> a_secondary_sd a_ancillary /// 
> a_anc_demand_generation a_anc_lab_services a_anc_adhreten a_anc_bldg_equip a_anc_unspecified /// 
> a_operational a_ope_bldg_equip a_ope_logistics a_ope_program_mgmt a_ope_supervision a_ope_training a_ope_transportation a_ope_massed a_ope_hmis a_ope_unspecified a_mixed a_mix_bldg_equip a_unspecified
> 
> 
> // only keep relevant variables 
> keep disease-a_unspecified
> 
> 
> // identify string variables in the dataset and make sure that missings are all formatted homogenously
> 
> ds, has(type string) 
> local strvars "`r(varlist)'"
> 
> foreach var of local strvars {c -(} 
>         replace `var' = "." if `var' == "NA" | `var' == "N/A" | `var' == "NR" | `var' == " " | `var' == ""
> {c )-}
> 
> 
> * Finally, export!
> **************************
> save pat_tracking_clean_wide_file_Mar2018.dta, replace
> 
> * Drew's Path
> //export excel using wide_files/UCSR_export_full.xlsx, first(varl) missing(".") replace
> 
> * Lily's Path
> * export excel using UCSR_exports/UCSR_export_full.xlsx, first(varl) missing(".") replace       
> 
> 
> 

{txt}end of do-file

{com}. br tech_flag*

. br id_tech tech_flag 

. br id_tech id_actvities tech_flag 
{err}variable {bf}id_actvities{sf} not found
{txt}{search r(111), local:r(111);}

{com}. br id_tech id_activities tech_flag 

. br id_tech id_actvities tech_flag 
{err}variable {bf}id_actvities{sf} not found
{txt}{search r(111), local:r(111);}

{com}. br id_tech id_actvities tech_flag 
{err}variable {bf}id_actvities{sf} not found
{txt}{search r(111), local:r(111);}

{com}. br id_tech id_activities tech_flag 

. br mean_cost

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. **************************************************************************
. **************************************************************************
. **************************************************************************
. ** Do file for export of VMMC studies to the UCSR, using select variables
. ** Lily Alexander
. ** University of Washington
. ** February 2018 
. ** lilyalexander18@gmail.com
. **************************************************************************
. **************************************************************************
. **************************************************************************
. 
. ** Data requirements
. **
. **  Must use data already formatted into wide file for GHCC analysis
. **              - These are available upon request
. **              - Procedure to be replicated for other intervention areas (ART, etc)
. **              - As well as other diseases (TB)
. **************************************************************************
. 
. set more off 
{txt}
{com}.         clear
{txt}
{com}.         *Drew's Path:
.         //cd "/Users/dcameron03/Documents/GitHub/Post-Extraction-Processing/VMMC/"
.         //use VMMC_wide_file.dta, replace       
.         *Lily's Path:
.         * cd "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/VMMC"
.         *       use VMMC_wide_file_Feb2018.dta
.         *Lily's temporary path: 
.         cd "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/Post-Extraction-Processing/Patient_tracking/wide_files
{txt}
{com}.         use pat_tracking_wide_file_Apr2018.dta, replace
{txt}
{com}. 
. 
. **********************************              
. ** Cross-validation of costs **
. **********************************
.         
.         * 1. Check that broad standard input categories sum to mean cost 
.         ****************************************************************
.         egen check = rowtotal(si_recurrent si_personnel)
{txt}
{com}.         replace check = si_combined if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1
  {res}0
{txt}
{com}.         di in red `r(N)'
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}. 
.         
.         * 2. Check that narrow standard input categories sum to broad categories
.         ************************************************************************
.         
.         local prefix "rec per" 
{txt}
{com}.                 
.         preserve 
{txt}
{com}.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(si_`var'_*)
{txt}  3{com}.                 drop si_`var'_*
{txt}  4{com}.                 gen diff_`var' = sum_`var' - si_`var'
{txt}  5{com}.                 gen flag_`var' = 1 if diff_`var' > 0.05 & diff_`var' !=. 
{txt}  6{com}.         
.         {c )-}
{txt}(2 missing values generated)
(2 missing values generated)

{com}.         restore
{txt}
{com}.         
.         * 3. Check that broad activity categories sum to mean cost 
.         **********************************************************
.         
.         egen check = rowtotal(a_primary_sd a_operational)
{txt}
{com}.         replace check = a_combo if check == 0
{txt}(0 real changes made)

{com}.         gen diff = check - mean_cost
{txt}
{com}.         gen flag = 1 if diff > 0.1
{txt}(2 missing values generated)

{com}.         
.         count if flag == 1 
  {res}0
{txt}
{com}.         di in red `r(N)' 
{res}{err}0
{txt}
{com}.         
.         drop diff check flag 
{txt}
{com}.         
.         * 4. Check that narrow activity categories sum to broad categories
.         ******************************************************************
.         
.         local prefix "prisd ope com" 
{txt}
{com}.         
.         //preserve 
.         
.         foreach var of local prefix {c -(} 
{txt}  2{com}.                 egen sum_`var' = rowtotal(a_`var'_*) 
{txt}  3{com}.                 
.         {c )-}
{txt}
{com}.         
.         gen diff_prisd = sum_prisd - a_primary_sd 
{txt}
{com}.         gen flag_prisd = 1 if diff_prisd > 0.05 & diff_prisd != . 
{txt}(2 missing values generated)

{com}. 
.         gen diff_ope = sum_ope - a_operational 
{txt}
{com}.         gen flag_ope = 1 if diff_ope > 0.05 & diff_ope != . 
{txt}(2 missing values generated)

{com}.         
.         gen diff_com = sum_com - a_combo
{txt}
{com}.         gen flag_com = 1 if diff_com > 0.05 & diff_com != . 
{txt}(2 missing values generated)

{com}. 
. 
. 
.         
. 
. **************************************************************************              
. ** First, export of whole raw data before compression / aggregation
. **************************************************************************
. ** Begin by selecting key variables for export
.                 
.                 label var disease "Disease" 
{txt}
{com}.                 label var output_unit2 "Output unit"
{txt}
{com}.                 
.                 * Identifiers
.                 **************
.                 label var id "ID Variable"
{txt}
{com}.                 label var unit_cost "Unit Cost ID"
{txt}
{com}.                 
.                 *Bibliographic variables
.                 ************************
.                 label var lead_author "Lead Author"
{txt}
{com}.                 label var ref_year "Reference Year"
{txt}
{com}.                 label var title "Title"
{txt}
{com}.                 label var journal_etc "Journal"
{txt}
{com}.                 label var url "URL"
{txt}
{com}. 
.                 * Geography
.                 ************
.                 label var iso_name "Country"
{txt}
{com}.                 label var pop_density "Urbanicity"
{txt}
{com}.                 label var location "Location"   
{txt}
{com}.                 label var no_sites "Sites"
{txt}
{com}.                 
.                 *Intervention variables
.                 ***********************
.                 label var ownership "Ownership"
{txt}
{com}.                 
.                 * Generate a higher-level platform variable
.                         gen platform=.
{txt}(2 missing values generated)

{com}.                                 replace platform=1 if id_facility=="HC01" | id_facility=="HC02" | id_facility=="HC03" | id_facility=="HC04" | id_facility=="HC05" |  id_facility=="HC06" |  id_facility=="HC07" | id_facility=="HC08" | id_facility=="HC09" | id_facility=="HC10" | id_facility=="HC11"
{txt}(2 real changes made)

{com}.                                 replace platform=2 if id_facility=="OR01" | id_facility=="OR02" |  id_facility=="OR03" |  id_facility=="OR04" |  id_facility=="OR05"
{txt}(0 real changes made)

{com}.                                 replace platform=3 if id_facility=="CB01" | id_facility=="CB02" | id_facility=="CB03" | id_facility=="CB04"
{txt}(0 real changes made)

{com}.                                 replace platform=4 if id_facility=="PW01"
{txt}(0 real changes made)

{com}.                                 replace platform=5 if id_facility=="OT01" |id_facility=="OT02"
{txt}(0 real changes made)

{com}.                         
.                         label variable platform "Platform"
{txt}
{com}.                         label define platform 1 "Fixed facility" 2 "Outreach" 3 "Community based" 4 "Population wide" 5 "Other"
{txt}
{com}.                         label values platform platform
{txt}
{com}.                         
.                 label var facility_cat "Platform specificity" 
{txt}
{com}.                 label var id_class "Intervention Category"
{txt}
{com}.                 label var id_int "Intervention"         
{txt}
{com}.                 label var int_description_long "Intervention Description (Long)"
{txt}
{com}.                 label var clinical_monitoring "Clinical monitoring" 
{txt}
{com}.                 label var demand_generation "Demand generation" 
{txt}
{com}.                 label var counseling_content "Counseling content"
{txt}
{com}.                 label var staff_type "Staff type & number"
{txt}
{com}.                 label var supportive_care "Supportive care"
{txt}
{com}.                 label var visits "Visit type & number"
{txt}
{com}.                 label var referrals "Referrals"
{txt}
{com}.                 label var method "Method"
{txt}
{com}.                 label var id_tech "Technology"
{txt}
{com}.                 label var treatment_phase "Treatment phase"
{txt}
{com}.                 label var arv_regimen "ARV Regimen" 
{txt}
{com}.                 label var treatment "Treatment" 
{txt}
{com}.                 label var screening_diagnoses "Screening and diagnosis"
{txt}
{com}.                 label var community_awareness "Community awareness"
{txt}
{com}.                 label var id_activities "Costed activities"
{txt}
{com}.                 
.                 label var start_month "Start Month"
{txt}
{com}.                 label var start_year "Start Year"
{txt}
{com}.                 label var end_month "End Month"
{txt}
{com}.                 label var end_year "End Year"
{txt}
{com}.                 label var period_portrayed "Total Months"
{txt}
{com}.                 label var year_intro "Year introduced at study site"
{txt}
{com}.                 label var coverage "Coverage"
{txt}
{com}.                 
. 
.                 *Population
.                 ************
.                 label var id_pop_dem_std "Target group (demographic)"
{txt}
{com}.                 label var id_pop_clin_std "Target group (clinical)"
{txt}
{com}.                 label var pop_age "Average Age"
{txt}
{com}.                 label var pop_sex "Gender"
{txt}
{com}.                 label var pop_ses "SES"
{txt}
{com}.                 label var pop_education "Education"
{txt}
{com}.                 label var hiv_prev "HIV Prevalence"
{txt}
{com}.                 label var tb_prev "TB Prevalence"
{txt}
{com}.                 label var tb_rx_resistance "TB Drug Resistance"
{txt}
{com}.                  
.                 replace pop_age = subinstr(pop_age, "years", "", .)
{txt}(0 real changes made)

{com}.                 
.                 * Study Design
.                 ***************
.                 label var costing_purpose "Costing Purpose"
{txt}
{com}.                 label var timing "Timing"
{txt}
{com}.                 label var country_sampling "Country Sampling"
{txt}
{com}.                 label var geo_sampling_incountry "Geographic Area In Country Sampling"
{txt}
{com}.                 label var site_sampling "Site Sampling"
{txt}
{com}.                 label var px_sampling "Patient Sampling"
{txt}
{com}.                 label var sample_size_derived "Sample size formally derived"
{txt}
{com}.                 label var controls "Controls"
{txt}
{com}.         
.         /*
>         *Need to replace all missing values in categoricals with 999 so we can label them "."
>         foreach i of varlist ownership platform id_class id_type id_modality disease id_tech id_phase int_services country region pop_density pop_sex costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_report econ_perspective_actual econ_costing real_world asd_costs research_costs unrelated_costs overhead volunteer_time family_time iso_code currency_x {c -(}
>                         replace `i'=999 if `i'==.
>                         label define `i' 999 ".", add
>                         {c )-}
>         
>         *Need to do same with string variables
>         foreach i of varlist id unit_cost lead_author ref_author title journal_etc url id_facility id_details int_description_long location ss_unique_trait id_pop_std pop_age pop_ses pop_education hiv_prev cd4_range tb_prev list_asd_costs overhead_costs uncertainty_rmk {c -(}
>                 replace `i'="." if `i'==""
>                 {c )-}
>         */
.         
.                 * Costing methods
.                 *******************
.                 label var econ_perspective_actual "Perspective"
{txt}
{com}.                 label var econ_costing "Economic / Financial"
{txt}
{com}.                 label var real_world "Real World / Per Protocol"
{txt}
{com}.                 label var asd_costs "Above Service Costs Included"
{txt}
{com}.                 label var list_asd_costs "Above Service Cost List"
{txt}
{com}.                 label var omitted_costs "Omitted Costs"
{txt}
{com}.                 label var sensitivity_analysis "Sensitivity Analysis"
{txt}
{com}.                 label var scale "Economies of scale"
{txt}
{com}.                 
.                 label var research_costs "Research Costs Included"
{txt}
{com}.                 label var unrelated_costs "Unrelated Costs Included"
{txt}
{com}.                 label var overhead "Overhead Costs Included"
{txt}
{com}.                 label var overhead_costs "Overhead Costs List"
{txt}
{com}.                 label var pot_distortions "Potential distortions"
{txt}
{com}.                 
.                 label var volunteer_time "Valuing Volunteer Time"
{txt}
{com}.                 label var family_time "Valuing Family Time"
{txt}
{com}.                 label var px_costs_measured "Patient-Incurred Costs Measured"
{txt}
{com}.                 label var cat_cost "Catastrophic Cost Calculated"
{txt}
{com}.                 
.                 label var currency_yr "Reported Currency Year"
{txt}
{com}.                 label var iso_code "Reported Currency"
{txt}
{com}.                 label var currency_iso "Currency of Data Collection"
{txt}
{com}.                 label var currency_x "Currency Exchange Method"
{txt}
{com}.                 label var current_x_rate "Currency Exchange Rate"
{txt}
{com}.                 label var discount_rate "Discount Rate"
{txt}
{com}.                 label var inflation "Inflation rate"
{txt}
{com}.                 
.                         
.                 * Finally, relabel the cost categories
.                 ***************************************
.                 
.                 * Label remaining confusing variables
.                 label var mean_cost     "Mean Unit Cost"
{txt}
{com}.                 
.                 // Personnel
.                 label var si_personnel "Personnel (SI)"
{txt}
{com}.                 label var si_per_service_delivery "Personnel: Direct Service Delivery (SI)"
{txt}
{com}. 
.                 // Recurrent
.                 label var si_recurrent "Recurrent Goods (SI)"
{txt}
{com}.                 label var si_rec_other "Recurring: Other (SI)"
{txt}
{com}.                 label var si_rec_nonmed_int_supplies "Recurring: Non-medical Supplies (SI)"
{txt}
{com}.         
.                 // Activities 
.                 label var a_primary_sd "Primary Service Delivery (A)"
{txt}
{com}.                 label var a_prisd_unspecified "Primary SD: Unspecified (A)"
{txt}
{com}. 
.                 label var a_operational "Operational (A)"
{txt}
{com}.                 label var a_ope_unspecified "Operational: Unspecified (A)"
{txt}
{com}.                 label var a_ope_transportation "Operational: Transportation (A)"
{txt}
{com}.                 
. 
.                 * Create the missing columns 
.                 ******************************
.         
.                 gen si_rec_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_mixed "Recurring: Mixed (SI)" 
{txt}
{com}.                 
.                 gen si_rec_med_int_supplies = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_med_int_supplies "Recurring: Medical Supplies (excluding drugs) (SI)"
{txt}
{com}.                 
.                 gen si_rec_key_drugs = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_key_drugs "Recurring: Supplies (key drugs) (SI)" 
{txt}
{com}.                 
.                 gen si_rec_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_rec_building_space "Recurring: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_per_support = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_support "Personnel: Support (SI)" 
{txt}
{com}.                 
.                 gen si_per_mixed_unspec = . 
{txt}(2 missing values generated)

{com}.                 label var si_per_mixed_unspec "Personnel: Mixed Unspecified (SI)"
{txt}
{com}. 
.                 gen si_capital = . 
{txt}(2 missing values generated)

{com}.                 label var si_capital "Capital (SI)"
{txt}
{com}.                 
.                 gen si_cap_other = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_other "Capital: Other (SI)"
{txt}
{com}.                 
.                 gen si_cap_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_mixed "Capital: Mixed (SI)"
{txt}
{com}.                 
.                 gen si_cap_med_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_med_equip "Capital: Equipment (medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_nonmed_equip = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_nonmed_equip "Capital: Equipment (non-medical) (SI)"
{txt}
{com}.                 
.                 gen si_cap_building_space = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_building_space "Capital: Building Space (SI)"
{txt}
{com}.                 
.                 gen si_cap_vehicles = . 
{txt}(2 missing values generated)

{com}.                 label var si_cap_vehicles "Capital: Vehicles (SI)"
{txt}
{com}.                 
.                 gen si_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var si_mixed "Mixed (SI)"
{txt}
{com}.                 
.                 gen si_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var si_unspecified "Unspecified (SI)"
{txt}
{com}.                 
.                 gen a_prisd_unspec_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_unspec_counseling "Primary SD: Counseling unspecified (A)"
{txt}
{com}.                 
.                 gen a_prisd_post_test_counseling = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_post_test_counseling "Primary SD: Post-test counseling (A)"
{txt}
{com}.                 
.                 gen a_prisd_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_lab_services "Primary SD: Lab services (A)"
{txt}
{com}.                 
.                 gen a_prisd_htc_service_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_htc_service_delivery "Primary SD: HTC service delivery (A)"
{txt}
{com}.                 
.                 gen a_prisd_hiv_rapid_test = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_hiv_rapid_test "Primary SD: HIV rapid testing (A)"
{txt}
{com}.                 
.                 gen a_prisd_arv_delivery = . 
{txt}(2 missing values generated)

{com}.                 label var a_prisd_arv_delivery "Primary SD: ARV delivery"
{txt}
{com}.                 
.                 gen a_anc_adhreten = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_adhreten "Ancillary: Adherence/Retention (A)" 
{txt}
{com}.                 
.                 gen a_anc_lab_services = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_lab_services "Ancillary: Lab Services (A)"
{txt}
{com}.                 
.                 gen a_ancillary = . 
{txt}(2 missing values generated)

{com}.                 label var a_ancillary "Ancillary (A)"
{txt}
{com}.                 
.                 gen a_anc_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_unspecified "Ancillary: Unspecified (A)"
{txt}
{com}.                 
.                 gen a_anc_demand_generation = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_demand_generation "Ancillary: Demand generation (A)"
{txt}
{com}.                 
.                 gen a_anc_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_anc_bldg_equip "Ancillary: Building equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_training = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_training "Operational: Training (A)"
{txt}
{com}.                 
.                 gen a_ope_program_mgmt = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_program_mgmt "Operational: Program Management (A)"
{txt}
{com}.                 
.                 gen a_ope_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_bldg_equip "Operational: Buildings and Equipment (A)"
{txt}
{com}.                 
.                 gen a_ope_logistics = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_logistics "Operational: Logistics (A)"
{txt}
{com}.                 
.                 gen a_ope_supervision = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_supervision "Operational: Supervision (A)"
{txt}
{com}.                 
.                 gen a_ope_massed = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_massed "Operational: Mass Education (A)" 
{txt}
{com}.                 
.                 gen a_ope_hmis = . 
{txt}(2 missing values generated)

{com}.                 label var a_ope_hmis "Operational: HMIS and Record-Keeping (A)"
{txt}
{com}.                 
.                 gen a_secondary_sd = . 
{txt}(2 missing values generated)

{com}.                 label var a_secondary_sd "Secondary Service Delivery (A)"
{txt}
{com}.                         
.                 gen a_mixed = . 
{txt}(2 missing values generated)

{com}.                 label var a_mixed "Mixed (A)"
{txt}
{com}.                 
.                 gen a_mix_bldg_equip = . 
{txt}(2 missing values generated)

{com}.                 label var a_mix_bldg_equip "Mixed: Building Equipment (A)"
{txt}
{com}.                 
.                 gen a_unspecified = . 
{txt}(2 missing values generated)

{com}.                 label var a_unspecified "Unspecified (A)" 
{txt}
{com}. 
. 
.                 
.         * And for the collapse: 
.                 *Generate a variable to tell collapsed costs from full costs
.                 gen collapsed=0
{txt}
{com}.                 * Need to create an id without (a) for grouping collapse
.                 gen study=substr(id, 1, length(id)-1)
{txt}
{com}.                 
.                                 label variable study "Study"
{txt}
{com}.                                 label variable collapsed "Collapsed"
{txt}
{com}.                                 
.                                 label define collapsed 0 "No" 1 "Yes"
{txt}
{com}.                                 label values collapsed collapsed
{txt}
{com}.                 
.                 *Create a caveats variable 
.                                         //gen flags="." 
.                                         
. 
. **************************************************************************              
. ** Replace N/A, NR and none with missing
. **************************************************************************      
. 
. local to_decode "disease collapsed output_unit2 pop_density ownership platform facility_cat id_class id_int method id_tech pop_sex tb_rx_resistance timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_actual econ_costing real_world asd_costs sensitivity_analysis scale research_costs unrelated_costs overhead volunteer_time family_time px_costs_measured cat_cost iso_code currency_iso currency_x inflation" 
{txt}
{com}. 
. foreach var of local to_decode {c -(} 
{txt}  2{com}.         decode `var', gen(`var'_new) 
{txt}  3{com}.         drop `var'
{txt}  4{com}.         rename `var'_new `var' 
{txt}  5{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  6{com}.         
.         replace `var' = strproper(`var')
{txt}  7{com}. {c )-}
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(2 real changes made)
{res}{txt}(2 real changes made)
(0 real changes made)

{com}. 
. foreach var of varlist clinical_monitoring demand_generation counseling_content staff_type supportive_care visits referrals id_activities list_asd_cost overhead_costs {c -(} 
{txt}  2{com}.         
.         replace `var' = "." if `var' == "N/A" | `var' == "NR" | `var' == "NA" | `var' == "" | `var' == " "
{txt}  3{com}.         
.         replace `var' = strproper(`var')
{txt}  4{com}. 
. {c )-}
{txt}(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)

{com}. 
.   
. replace disease = strupper(disease) 
{txt}(2 real changes made)

{com}. replace id_int = strupper(id_int) 
{txt}(2 real changes made)

{com}. replace iso_code = strupper(iso_code)
{txt}(2 real changes made)

{com}. replace currency_iso = strupper(currency_iso)
{txt}(2 real changes made)

{com}. replace pot_distortions = strupper(pot_distortions)
{txt}(0 real changes made)

{com}. 
. 
. 
. ****************************************************************************            
. ** Cross-validation of costed activities and intervention details columns **
. ****************************************************************************
. 
.         gen flag = 1 if regexm(id_activities, "HTC") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_1 = 1 if regexm(id_activities, "ARV") & arv_regimen == "."
{txt}(2 missing values generated)

{com}.         gen flag_2 = 1 if regexm(id_activities, "ARV") & treatment == "."
{txt}(2 missing values generated)

{com}.         gen flag_3 = 1 if regexm(id_activities, "counsel") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_4 = 1 if regexm(id_activities, "VCT") & counseling_content == "."
{txt}(2 missing values generated)

{com}.         gen flag_5 = 1 if regexm(id_activities, "CD4") & clinical_monitoring == "." 
{txt}(2 missing values generated)

{com}.         gen flag_6 = 1 if regexm(id_activities, "iagnosis") & clinical_monitoring == "."
{txt}(2 missing values generated)

{com}.         
.         
.         local varlist cost_activities "clinical_monitoring demand_generation counseling_content supportive_care referrals arv_regimen screening_diagnoses treatment community_awareness health_system id_tech" 
{txt}
{com}.         
.         gen supportive_care_flag = 1 if regexm(id_activities, "Supportive") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(2 missing values generated)

{com}.         replace supportive_care_flag = 1 if regexm(id_activities, "support") & (supportive_care == "." | supportive_care == "N/A" | supportive_care == "NR")
{txt}(0 real changes made)

{com}.         replace supportive_care_flag = 1 if supportive_care != "." & !(strmatch(id_activities, "*upport*"))
{txt}(0 real changes made)

{com}.         
.         gen clinical_mo_flag = 1 if regexm(id_activities, "CD4|iagnosis") & (clinical_monitoring == "." | clinical_monitoring == "N/A" | clinical_monitoring == "NR")
{txt}(2 missing values generated)

{com}.         replace clinical_mo_flag = 1 if clinical_monitoring != "." & (!(strmatch(id_activities, "*CD4*")) & !(strmatch(id_activities, "*iagnosis*")))
{txt}(0 real changes made)

{com}.         
.         gen counsel_flag = 1 if regexm(id_activities, "ounsel|VCT") & (counseling_content == "." | counseling_content == "N/A" | counseling_content == "NR")
{txt}(2 missing values generated)

{com}.         replace counsel_flag = 1 if counseling_content != "." & !(strmatch(id_activities, "*ounsel*"))
{txt}(0 real changes made)

{com}.         
.         gen demand_gen_flag = 1 if regexm(id_activities, "emand|generation") & (demand_generation == "." | demand_generation == "N/A" | demand_generation == "NR")
{txt}(2 missing values generated)

{com}.         replace demand_gen_flag = 1 if demand_generation != "." & demand_generation != "None" & !(strmatch(id_activities, "*eneration*"))
{txt}(0 real changes made)

{com}.         
.         gen referrals_flag = 1 if regexm(id_activities, "eferrals") & (referrals == "." | referrals == "N/A" | referrals == "NR")
{txt}(2 missing values generated)

{com}.         replace referrals_flag = 1 if referrals != "." & !(strmatch(id_activities, "*eferrals*"))
{txt}(0 real changes made)

{com}.         
.         gen arv_regimen_flag = 1 if regexm(id_activities, "ARV") & (arv_regimen == "." | arv_regimen == "N/A" | arv_regimen == "NR")
{txt}(2 missing values generated)

{com}.         replace arv_regimen_flag = 1 if arv_regimen != "." & arv_regimen != "N/A" & arv_regimen != "NR" & (!(strmatch(id_activities, "*ARV*")) & !(strmatch(id_activities, "*Arv*")))
{txt}(0 real changes made)

{com}.         
.         gen screen_diag_flag = 1 if regexm(id_activities, "iagnoses") & (screening_diagnoses == "." | screening_diagnoses == "N/A" | screening_diagnoses == "NR")
{txt}(2 missing values generated)

{com}.         
.         replace screen_diag_flag = 1 if screening_diagnoses != "." & screening_diagnoses != "NA" & screening_diagnoses != "NR" & !(strmatch(id_activities, "*iagno*"))
{txt}(0 real changes made)

{com}.         
.         gen treatment_flag = 1 if regexm(id_activities, "reatment") & (treatment == "." | treatment == "N/A" | treatment == "NR") 
{txt}(2 missing values generated)

{com}.         replace treatment_flag = 1 if treatment != "." & treatment != "N/A" & treatment != "NR" & !(strmatch(id_activities, "*reatment*"))
{txt}(0 real changes made)

{com}.         
.         gen comm_awareness_flag = 1 if regexm(id_activities, "wareness") & (community_awareness == "." | community_awareness == "N/A" | community_awareness == "NR") 
{txt}(2 missing values generated)

{com}.         replace comm_awareness_flag = 1 if community_awareness != "." & community_awareness != "N/A" & community_awareness != "NR" & community_awareness != "None" & !(strmatch(id_activities, "*wareness*"))
{txt}(0 real changes made)

{com}.         
.         gen health_system_flag = 1 if regexm(id_activities, "system") & (health_system == "." | health_system == "N/A" | health_system == "NR") 
{txt}(2 missing values generated)

{com}.         replace health_system_flag = 1 if health_system != "." & health_system != "N/A" & health_system != "NR" & !(strmatch(id_activities, "*ystem*"))
{txt}(0 real changes made)

{com}.         
.         gen tech_flag = 1 if regexm(id_activities, "echnology") & (id_tech == "." | id_tech == "N/A" | id_tech == "NR") 
{txt}(2 missing values generated)

{com}.         replace tech_flag = 1 if id_tech != "." & id_tech != "N/A" & id_tech != "NR" & !(strmatch(id_tech, "*ecnology*"))
{txt}(2 real changes made)

{com}. 
. 
. **************************************************************************              
. ** Order variables 
. **************************************************************************              
. 
. order disease collapsed lead_author ref_year output_unit2 ref_year title journal_etc url /// 
> iso_name location no_sites pop_density ownership platform facility_cat id_class id_int int_description_long /// 
> clinical_monitoring demand_generation counseling_content staff_type supportive_care visits referrals method id_tech /// 
> treatment_phase arv_regimen treatment screening_diagnoses community_awareness health_system id_activities /// 
> start_month start_year end_month end_year period_portrayed year_intro coverage /// 
> id_pop_dem_std id_pop_clin_std pop_age pop_sex pop_ses pop_education hiv_prev tb_prev tb_rx_resistance /// 
> costing_purpose timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls /// 
> econ_perspective_actual econ_costing real_world asd_costs list_asd_costs omitted_costs sensitivity_analysis scale /// 
> research_costs unrelated_costs overhead overhead_costs pot_distortions /// 
> volunteer_time family_time px_costs_measured cat_cost currency_yr iso_code currency_iso currency_x current_x_rate discount_rate inflation /// 
> mean_cost si_personnel si_per_service_delivery si_per_support si_per_mixed_unspec /// 
> si_recurrent si_rec_key_drugs si_rec_med_int_supplies si_rec_nonmed_int_supplies si_rec_building_space si_rec_mixed si_rec_other /// 
> si_capital si_cap_med_equip si_cap_nonmed_equip si_cap_build si_cap_vehic si_cap_mixed si_cap_other si_mixed si_unspecified /// 
> a_primary_sd  a_prisd_unspecified a_prisd_unspec_counseling a_prisd_post_test_counseling a_prisd_lab_services a_prisd_htc_service_delivery a_prisd_hiv_rapid_test a_prisd_arv_delivery /// 
> a_secondary_sd a_ancillary /// 
> a_anc_demand_generation a_anc_lab_services a_anc_adhreten a_anc_bldg_equip a_anc_unspecified /// 
> a_operational a_ope_bldg_equip a_ope_logistics a_ope_program_mgmt a_ope_supervision a_ope_training a_ope_transportation a_ope_massed a_ope_hmis a_ope_unspecified a_mixed a_mix_bldg_equip a_unspecified
{txt}
{com}. 
. 
. // only keep relevant variables 
. keep disease-a_unspecified
{txt}
{com}. 
. 
. // identify string variables in the dataset and make sure that missings are all formatted homogenously
. 
. ds, has(type string) 
{txt}{col 1}disease{col 15}id_int{col 29}screening_~s{col 43}country_sa~g{col 57}research_c~s
{col 1}collapsed{col 15}int_descri~g{col 29}community_~s{col 43}geo_sampli~y{col 57}unrelated_~s
{col 1}lead_author{col 15}clinical_m~g{col 29}health_sys~m{col 43}site_sampl~g{col 57}overhead
{col 1}output_unit2{col 15}demand_gen~n{col 29}id_activit~s{col 43}px_sampling{col 57}overhead_c~s
{col 1}title{col 15}counseling~t{col 29}id_pop_dem~d{col 43}sample_siz~d{col 57}pot_distor~s
{col 1}journal_etc{col 15}staff_type{col 29}id_pop_cli~d{col 43}controls{col 57}volunteer_~e
{col 1}url{col 15}supportive~e{col 29}pop_age{col 43}econ_persp~l{col 57}family_time
{col 1}iso_name{col 15}visits{col 29}pop_sex{col 43}econ_costing{col 57}px_costs_m~d
{col 1}location{col 15}referrals{col 29}pop_ses{col 43}real_world{col 57}cat_cost
{col 1}pop_density{col 15}method{col 29}pop_educat~n{col 43}asd_costs{col 57}iso_code
{col 1}ownership{col 15}id_tech{col 29}tb_prev{col 43}list_asd_c~s{col 57}currency_iso
{col 1}platform{col 15}treatment_~e{col 29}tb_rx_resi~e{col 43}omitted_co~s{col 57}currency_x
{col 1}facility_cat{col 15}arv_regimen{col 29}costing_pu~e{col 43}sensitivit~s{col 57}inflation
{col 1}id_class{col 15}treatment{col 29}timing{col 43}scale

{com}. local strvars "`r(varlist)'"
{txt}
{com}. 
. foreach var of local strvars {c -(} 
{txt}  2{com}.         replace `var' = "." if `var' == "NA" | `var' == "N/A" | `var' == "NR" | `var' == " " | `var' == ""
{txt}  3{com}. {c )-}
{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(2 real changes made)
(2 real changes made)
(2 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)

{com}. 
. 
. * Finally, export!
. **************************
. save pat_tracking_clean_wide_file_Mar2018.dta, replace
{txt}file pat_tracking_clean_wide_file_Mar2018.dta saved

{com}. 
. * Drew's Path
. //export excel using wide_files/UCSR_export_full.xlsx, first(varl) missing(".") replace
. 
. * Lily's Path
. * export excel using UCSR_exports/UCSR_export_full.xlsx, first(varl) missing(".") replace       
. 
. 
. 
. 
{txt}end of do-file

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2010/EGRESOS.csv", clear
{res}{err}file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2010/EGRESOS.csv not found
{txt}{search r(601), local:r(601);}

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2010/EGRESO.csv", clear
{res}{text}(46 vars, 2,634,339 obs)

{com}. count
  {res}2,634,339

{com}. duplicates tag id
{err}variable {bf}id{sf} not found
{txt}{search r(111), local:r(111);}

{com}. br

. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2012/EGRESOS.csv", clear
{res}{err}file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2012/EGRESOS.csv not found
{txt}{search r(601), local:r(601);}

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2010/EGRESO.csv", clear
{res}{err}{hline 2}Break{hline 2}
{txt}{search r(1), local:r(1);}

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2012/EGRESO.csv", clear
{res}{text}(50 vars, 2,880,606 obs)

{com}. import excel using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/SAEH_BD2009.xlsx", firstrow clear 
{res}{err}file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/SAEH_BD2009.xlsx too big
{txt}{search r(601), local:r(601);}

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/egresos1.csv", clear 
{res}{text}(120 vars, 1,000,000 obs)

{com}. 
. tempfile one 

. save `one', clear 
{err}option {bf:clear} not allowed
{txt}{search r(198), local:r(198);}

{com}. save `one', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000001 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000001 saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/egresos2.csv", clear 
{res}{text}(120 vars, 1,000,000 obs)

{com}. tempfile two 

. save `two', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000002 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000002 saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/egresos3.csv", clear 
{res}{text}(120 vars, 598,366 obs)

{com}. tempfile three 

. save `three', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000003 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000003 saved

{com}. use `one', clear 

. append using `two' 

. append using `three' 
{txt}{p 0 7 2}
(note: variable
diag_ini was 
str4, now str7 to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
afecprin was 
str4, now str7 to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
veces was 
byte, now int to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
navicune03 was 
byte, now int to accommodate using data's values)
{p_end}

{com}. export delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/EGRESOS.csv", replace
{res}{txt}(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/EGRESOS.csv not found)
{txt}file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2009/EGRESOS.csv saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/egresos1.csv", clear 
{res}{text}(134 vars, 1,000,000 obs)

{com}. tempfile one 

. save `one', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000004 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000004 saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/egresos2.csv", clear 
{res}{text}(134 vars, 1,000,000 obs)

{com}. tempfile two 

. save `two', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000005 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000005 saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/egresos3.csv", clear 
{res}{text}(134 vars, 463,847 obs)

{com}. tempfile three 

. save `three', replace
{txt}(note: file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000006 not found)
file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000006 saved

{com}. use `one', clear 

. append using `two' 
{err}{p 0 2 2}
variable
sa_interm is
str4 in master but
int in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
string/numeric mismatch.  The using variable
would then be treated as if it
contained "".
{p_end}
{txt}{search r(106), local:r(106);}

{com}. br sa_interm

. use `one', clear 

. br sa_interm

. append using `two'
{err}{p 0 2 2}
variable
sa_interm is
str4 in master but
int in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
string/numeric mismatch.  The using variable
would then be treated as if it
contained "".
{p_end}
{txt}{search r(106), local:r(106);}

{com}. br sa_interm

. use `two', clear

. br sa_interm

. tostring sa_interm
{err}{p}must specify either generate or replace option{p_end}
{txt}{search r(198), local:r(198);}

{com}. tostring sa_interm, replace
{txt}sa_interm was {res:int} now {res:str4}

{com}. save `two', replace
{txt}file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000005 saved

{com}. use `one', clear

. append using `two'
{err}{p 0 2 2}
variable
anest01 is
str1 in master but
byte in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
string/numeric mismatch.  The using variable
would then be treated as if it
contained "".
{p_end}
{txt}{search r(106), local:r(106);}

{com}. br anest01

. tab anest01

    {txt}ANEST01 {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          1 {c |}{res}    104,501       13.18       13.18
{txt}          2 {c |}{res}    196,492       24.79       37.97
{txt}          3 {c |}{res}     12,250        1.55       39.51
{txt}          4 {c |}{res}     78,832        9.94       49.46
{txt}          5 {c |}{res}      6,009        0.76       50.22
{txt}          6 {c |}{res}    390,847       49.30       99.52
{txt}          7 {c |}{res}      3,065        0.39       99.91
{txt}          8 {c |}{res}        730        0.09      100.00
{txt}          S {c |}{res}          1        0.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}    792,727      100.00

{com}. drop if anest01 == "S" 
{txt}(1 observation deleted)

{com}. destring anest01, replace
{txt}anest01: all characters numeric; {res}replaced {txt}as {res}byte
{txt}(207273 missing values generated)
{res}
{com}. br anest01

. save `one', replace
{txt}file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000004 saved

{com}. use `one', clear 

. append using `two' 
{txt}{p 0 7 2}
(note: variable
veces was 
byte, now int to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
navicune03 was 
byte, now int to accommodate using data's values)
{p_end}

{com}. append using `three'
{err}{p 0 2 2}
variable
sa_interm is
str4 in master but
int in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
string/numeric mismatch.  The using variable
would then be treated as if it
contained "".
{p_end}
{txt}{search r(106), local:r(106);}

{com}. use `three', clear

. br sa_interm

. tostring sa_interm, replace
{txt}sa_interm was {res:int} now {res:str4}

{com}. save `three', replace
{txt}file /var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//S_00256.000006 saved

{com}. use `one', clear

. append using `two'
{txt}{p 0 7 2}
(note: variable
veces was 
byte, now int to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
navicune03 was 
byte, now int to accommodate using data's values)
{p_end}

{com}. append using `three'

. export delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/EGRESOS.csv", replace
{res}{txt}(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/EGRESOS.csv not found)
{txt}file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2008/EGRESOS.csv saved

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2007/EGRESOS2007.csv", clear 
{res}{err}{hline 2}Break{hline 2}
{txt}{search r(1), local:r(1);}

{com}. import delimited using "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/SAEH_BD2007/EGRESOS2007.csv", clear 
{res}{text}(135 vars, 2,311,826 obs)

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
. 
. *****************************************************
. * First, merge different parts of SAEH sheet
. *****************************************************
. 
. // Bring in years SAEH 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
{res}{text}(43 vars, 1,416,807 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2000.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2000.dta saved
{res}{text}(43 vars, 1,526,021 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2001.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2001.dta saved
{res}{text}(43 vars, 1,639,154 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2002.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2002.dta saved
{res}{text}(58 vars, 1,707,909 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2003.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2003.dta saved
{res}{text}(43 vars, 1,795,795 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2004.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2004.dta saved
{res}{text}(87 vars, 1,980,961 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2005.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2005.dta saved
{res}{text}(108 vars, 2,099,946 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2006.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2006.dta saved
{res}{text}(135 vars, 2,311,826 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2007.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2007.dta saved
{res}{text}(135 vars, 2,463,846 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2008.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2008.dta saved
{res}{text}(120 vars, 2,598,366 obs)
(note: file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2009.dta not found)
file /Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets/saeh_2009.dta saved

{com}. 
{txt}end of do-file

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         append using saeh_`year'.dta
{txt}  4{com}.                 {c )-}
{txt}  5{com}.         {c )-}
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}{p 0 2 2}
variable
servicio02 is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         append using saeh_`year'.dta
{txt}  5{com}.                 {c )-}
{txt}  6{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{p 0 2 2}
variable
servicio02 is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br servicio02 

. tab servicio02

 {txt}SERVICIO02 {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          1 {c |}{res}          1        0.00        0.00
{txt}        100 {c |}{res}      2,926        8.35        8.35
{txt}        101 {c |}{res}        452        1.29        9.64
{txt}        102 {c |}{res}        325        0.93       10.57
{txt}        103 {c |}{res}        259        0.74       11.31
{txt}        104 {c |}{res}        223        0.64       11.95
{txt}        105 {c |}{res}         86        0.25       12.19
{txt}        108 {c |}{res}        978        2.79       14.98
{txt}        109 {c |}{res}         45        0.13       15.11
{txt}        110 {c |}{res}         19        0.05       15.17
{txt}        112 {c |}{res}         71        0.20       15.37
{txt}        113 {c |}{res}        325        0.93       16.30
{txt}        114 {c |}{res}        280        0.80       17.10
{txt}        115 {c |}{res}        247        0.70       17.80
{txt}        116 {c |}{res}         54        0.15       17.96
{txt}        200 {c |}{res}      1,916        5.47       23.42
{txt}        201 {c |}{res}        419        1.20       24.62
{txt}        202 {c |}{res}      2,744        7.83       32.45
{txt}        203 {c |}{res}        328        0.94       33.39
{txt}        204 {c |}{res}         13        0.04       33.43
{txt}        205 {c |}{res}        105        0.30       33.73
{txt}        206 {c |}{res}          4        0.01       33.74
{txt}        207 {c |}{res}      1,212        3.46       37.20
{txt}        208 {c |}{res}         23        0.07       37.26
{txt}        209 {c |}{res}        596        1.70       38.96
{txt}        210 {c |}{res}         18        0.05       39.01
{txt}        211 {c |}{res}        236        0.67       39.69
{txt}        212 {c |}{res}        605        1.73       41.41
{txt}        213 {c |}{res}        651        1.86       43.27
{txt}        214 {c |}{res}          3        0.01       43.28
{txt}        215 {c |}{res}         45        0.13       43.41
{txt}        216 {c |}{res}        337        0.96       44.37
{txt}        217 {c |}{res}          4        0.01       44.38
{txt}        300 {c |}{res}      3,045        8.69       53.07
{txt}        301 {c |}{res}         16        0.05       53.12
{txt}        302 {c |}{res}        477        1.36       54.48
{txt}        303 {c |}{res}      8,379       23.92       78.40
{txt}        304 {c |}{res}          1        0.00       78.40
{txt}        400 {c |}{res}      1,275        3.64       82.04
{txt}        401 {c |}{res}        170        0.49       82.52
{txt}        402 {c |}{res}        900        2.57       85.09
{txt}        403 {c |}{res}          5        0.01       85.11
{txt}        404 {c |}{res}         36        0.10       85.21
{txt}        407 {c |}{res}         45        0.13       85.34
{txt}        408 {c |}{res}         19        0.05       85.39
{txt}        409 {c |}{res}        128        0.37       85.76
{txt}        410 {c |}{res}         35        0.10       85.86
{txt}        411 {c |}{res}          2        0.01       85.86
{txt}        412 {c |}{res}        938        2.68       88.54
{txt}        413 {c |}{res}         15        0.04       88.58
{txt}        414 {c |}{res}          8        0.02       88.61
{txt}        415 {c |}{res}         45        0.13       88.73
{txt}        416 {c |}{res}         15        0.04       88.78
{txt}        418 {c |}{res}         15        0.04       88.82
{txt}        420 {c |}{res}        193        0.55       89.37
{txt}        424 {c |}{res}      1,763        5.03       94.40
{txt}        425 {c |}{res}        325        0.93       95.33
{txt}        500 {c |}{res}        117        0.33       95.66
{txt}        501 {c |}{res}          2        0.01       95.67
{txt}        502 {c |}{res}        304        0.87       96.54
{txt}        503 {c |}{res}      1,167        3.33       99.87
{txt}        505 {c |}{res}         46        0.13      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}     35,036      100.00

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 destring servicio02, replace 
{txt}  6{com}.                         {c )-}
{txt}  7{com}.                         
.                         append using saeh_`year'.dta
{txt}  8{com}.                 {c )-}
{txt}  9{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 already numeric; no {res}replace
{err}{p 0 2 2}
variable
servicio02 is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2007 {c -(} 
{txt}  5{com}.                                 destring servicio02, replace 
{txt}  6{com}.                         {c )-}
{txt}  7{com}.                         
.                         append using saeh_`year'.dta
{txt}  8{com}.                 {c )-}
{txt}  9{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{p 0 2 2}
variable
servicio02 is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                         {c )-}
{txt}  7{com}.                         
.                         append using saeh_`year'.dta
{txt}  8{com}.                 {c )-}
{txt}  9{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
{err}{p 0 2 2}
variable
servicio03 is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br servicio*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                         {c )-}
{txt}  8{com}.                         
.                         append using saeh_`year'.dta
{txt}  9{com}.                 {c )-}
{txt} 10{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
{err}{p 0 2 2}
variable
anest05 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                         {c )-}
{txt}  9{com}.                         
.                         append using saeh_`year'.dta
{txt} 10{com}.                 {c )-}
{txt} 11{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
quirof05 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                         {c )-}
{txt} 10{com}.                         
.                         append using saeh_`year'.dta
{txt} 11{com}.                 {c )-}
{txt} 12{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
anest06 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                         {c )-}
{txt} 11{com}.                         
.                         append using saeh_`year'.dta
{txt} 12{com}.                 {c )-}
{txt} 13{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
anest07 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br anest*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring anest08, replace
{txt} 12{com}.                         {c )-}
{txt} 13{com}.                         
.                         append using saeh_`year'.dta
{txt} 14{com}.                 {c )-}
{txt} 15{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
anest08 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
quirof07 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br quirof*

. br quirof*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring anest08, replace
{txt} 12{com}.                                 tostring quirof07, replace
{txt} 13{com}.                                 tostring quirof08, replace
{txt} 14{com}.                         {c )-}
{txt} 15{com}.                         
.                         append using saeh_`year'.dta
{txt} 16{com}.                 {c )-}
{txt} 17{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
anest08 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
anest08 is
str1 in master but
byte in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
string/numeric mismatch.  The using variable
would then be treated as if it
contained "".
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}. =                               tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                         {c )-}
{txt} 14{com}.                         
.                         append using saeh_`year'.dta
{txt} 15{com}.                 {c )-}
{txt} 16{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
{bf}{err}={sf} is not a valid command name
{txt}{search r(199), local:r(199);}

end of do-file

{search r(199), local:r(199);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                         {c )-}
{txt} 14{com}.                         
.                         append using saeh_`year'.dta
{txt} 15{com}.                 {c )-}
{txt} 16{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
cvetiemia is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 destring cvetiemia, replace
{txt} 14{com}.                         {c )-}
{txt} 15{com}.                         
.                         append using saeh_`year'.dta
{txt} 16{com}.                 {c )-}
{txt} 17{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia already numeric; no {res}replace
{err}{p 0 2 2}
variable
cvetiemia is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                         {c )-}
{txt} 15{com}.                         
.                         append using saeh_`year'.dta
{txt} 16{com}.                 {c )-}
{txt} 17{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
tiempoia is
int in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         append using saeh_`year'.dta
{txt} 17{com}.                 {c )-}
{txt} 18{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{p 0 2 2}
variable
derhab is
byte in master but
str2 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br derhab

. tab derhab

     {txt}DERHAB {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  7,716,836       63.43       63.43
{txt}          1 {c |}{res}    107,131        0.88       64.31
{txt}          2 {c |}{res}     59,119        0.49       64.79
{txt}          3 {c |}{res}     39,034        0.32       65.11
{txt}          4 {c |}{res}  1,517,458       12.47       77.59
{txt}          5 {c |}{res}      3,196        0.03       77.61
{txt}          6 {c |}{res}     75,665        0.62       78.23
{txt}          7 {c |}{res}      7,638        0.06       78.30
{txt}          8 {c |}{res}    772,812        6.35       84.65
{txt}          9 {c |}{res}  1,867,704       15.35      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res} 12,166,593      100.00

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                         {c )-}
{txt} 19{com}.                         
.                         append using saeh_`year'.dta
{txt} 20{com}.                 {c )-}
{txt} 21{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
traumat is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                         {c )-}
{txt} 20{com}.                         
.                         append using saeh_`year'.dta
{txt} 21{com}.                 {c )-}
{txt} 22{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
lugar is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                         {c )-}
{txt} 21{com}.                         
.                         append using saeh_`year'.dta
{txt} 22{com}.                 {c )-}
{txt} 23{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
sa_labor is
byte in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_labor, replace
{txt} 21{com}.                         {c )-}
{txt} 22{com}.                         
.                         append using saeh_`year'.dta
{txt} 23{com}.                 {c )-}
{txt} 24{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
{err}{p 0 2 2}
variable
sa_expul is
byte in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_labor, replace
{txt} 21{com}.                                 tostring sa_expul, replace
{txt} 22{com}.                         {c )-}
{txt} 23{com}.                         
.                         append using saeh_`year'.dta
{txt} 24{com}.                 {c )-}
{txt} 25{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
sa_expul was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
sa_recup is
byte in master but
str3 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br sa_*

. tostring sa_*, replace
{txt}sa_labor already string; no {res}replace
{txt}sa_expul already string; no {res}replace
{txt}sa_recup was {res:byte} now {res:str2}
sa_inten was {res:int} now {res:str4}
sa_interm was {res:int} now {res:str4}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_*, replace
{txt} 21{com}.                         {c )-}
{txt} 22{com}.                         
.                         append using saeh_`year'.dta
{txt} 23{com}.                 {c )-}
{txt} 24{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
sa_expul was {res:byte} now {res:str1}
sa_recup was {res:byte} now {res:str2}
sa_inten was {res:int} now {res:str4}
sa_interm was {res:int} now {res:str4}
{err}{p 0 2 2}
variable
anest01 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br anest*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_*, replace
{txt} 21{com}.                                 tostring anest*, replace 
{txt} 22{com}.                         {c )-}
{txt} 23{com}.                         
.                         append using saeh_`year'.dta
{txt} 24{com}.                 {c )-}
{txt} 25{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
sa_expul was {res:byte} now {res:str1}
sa_recup was {res:byte} now {res:str2}
sa_inten was {res:int} now {res:str4}
sa_interm was {res:int} now {res:str4}
anest01 was {res:byte} now {res:str1}
anest02 was {res:byte} now {res:str1}
anest05 already string; no {res}replace
{txt}anest06 already string; no {res}replace
{txt}anest07 already string; no {res}replace
{txt}anest08 was {res:byte} now {res:str1}
{err}{p 0 2 2}
variable
quirof01 is
byte in master but
str1 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br quirof*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_*, replace
{txt} 21{com}.                                 tostring anest*, replace 
{txt} 22{com}.                                 tostring quirof*, replace
{txt} 23{com}.                         {c )-}
{txt} 24{com}.                         
.                         append using saeh_`year'.dta
{txt} 25{com}.                 {c )-}
{txt} 26{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
sa_expul was {res:byte} now {res:str1}
sa_recup was {res:byte} now {res:str2}
sa_inten was {res:int} now {res:str4}
sa_interm was {res:int} now {res:str4}
anest01 was {res:byte} now {res:str1}
anest02 was {res:byte} now {res:str1}
anest05 already string; no {res}replace
{txt}anest06 already string; no {res}replace
{txt}anest07 already string; no {res}replace
{txt}anest08 was {res:byte} now {res:str1}
quirof01 was {res:byte} now {res:str1}
quirof02 was {res:byte} now {res:str1}
quirof05 already string; no {res}replace
{txt}quirof06 already string; no {res}replace
{txt}quirof07 already string; no {res}replace
{txt}quirof08 already string; no {res}replace
{err}{p 0 2 2}
variable
qh08 is
byte in master but
str2 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. br qh&
{bf}{err}qh{sf} ambiguous abbreviation
{txt}{search r(111), local:r(111);}

{com}. br qh*

. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         if `year' == 2006 {c -(} 
{txt}  5{com}.                                 tostring servicio02, replace 
{txt}  6{com}.                                 tostring servicio03, replace
{txt}  7{com}.                                 tostring anest05, replace
{txt}  8{com}.                                 tostring  quirof05, replace
{txt}  9{com}.                                 tostring anest06, replace
{txt} 10{com}.                                 tostring anest07, replace 
{txt} 11{com}.                                 tostring quirof07, replace
{txt} 12{com}.                                 tostring quirof08, replace
{txt} 13{com}.                                 tostring cvetiemia, replace
{txt} 14{com}.                                 tostring tiempoia, replace
{txt} 15{com}.                         {c )-}
{txt} 16{com}.                         
.                         if `year' == 2007 {c -(} 
{txt} 17{com}.                                 tostring  derhab, replace
{txt} 18{com}.                                 tostring traumat, replace
{txt} 19{com}.                                 tostring lugar, replace
{txt} 20{com}.                                 tostring sa_*, replace
{txt} 21{com}.                                 tostring anest*, replace 
{txt} 22{com}.                                 tostring quirof*, replace
{txt} 23{com}.                                 tostring qh08, replace
{txt} 24{com}.                         {c )-}
{txt} 25{com}.                         
.                         append using saeh_`year'.dta
{txt} 26{com}.                 {c )-}
{txt} 27{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}servicio02 was {res:int} now {res:str3}
servicio03 was {res:int} now {res:str3}
anest05 was {res:byte} now {res:str1}
quirof05 was {res:byte} now {res:str1}
anest06 was {res:byte} now {res:str1}
anest07 was {res:byte} now {res:str1}
quirof07 was {res:byte} now {res:str1}
quirof08 was {res:byte} now {res:str1}
cvetiemia was {res:byte} now {res:str1}
tiempoia was {res:int} now {res:str3}
{err}2007
{txt}derhab was {res:byte} now {res:str1}
traumat was {res:byte} now {res:str1}
lugar was {res:byte} now {res:str1}
sa_labor was {res:byte} now {res:str2}
sa_expul was {res:byte} now {res:str1}
sa_recup was {res:byte} now {res:str2}
sa_inten was {res:int} now {res:str4}
sa_interm was {res:int} now {res:str4}
anest01 was {res:byte} now {res:str1}
anest02 was {res:byte} now {res:str1}
anest05 already string; no {res}replace
{txt}anest06 already string; no {res}replace
{txt}anest07 already string; no {res}replace
{txt}anest08 was {res:byte} now {res:str1}
quirof01 was {res:byte} now {res:str1}
quirof02 was {res:byte} now {res:str1}
quirof05 already string; no {res}replace
{txt}quirof06 already string; no {res}replace
{txt}quirof07 already string; no {res}replace
{txt}quirof08 already string; no {res}replace
{txt}qh08 was {res:byte} now {res:str2}
{err}{p 0 2 2}
variable
qm08 is
byte in master but
str2 in using data
{p_end}
{p 4 4 2}
You could specify
{bf:append}'s
{bf:force} option to ignore this
numeric/string mismatch.  The using variable
would then be treated as if it
contained numeric missing value.
{p_end}
{txt}{search r(106), local:r(106);}

end of do-file

{search r(106), local:r(106);}

{com}. do "/var/folders/0y/5bmlgxmx39v_fqw0vs5vrp680000gn/T//SD00256.000000"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // March 7, 2018
. 
. // Purpose: Exploring second-trimester abortion in SAEH national-level data 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 100000m
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales"
{txt}
{com}.         
.         local years 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 
{txt}
{com}.         
.         local re_run 0 
{txt}
{com}.         
. *****************************************************
. * 1) Merge different parts of SAEH sheet
. *****************************************************
. 
. if `re_run' == 1 {c -(}
. 
. // Bring in SAEH data for years 2000-2009, for which all aspects of the hospitalization form are stored in one file (EGRESOS). 
. // Therefore, just need to bring in one dataset per year
.  
.         forvalues i=2000/2009 {c -(} 
{txt}  2{com}.         
.                 import delimited using "`data'/SAEH_BD`i'/EGRESOS`i'.csv", clear 
{txt}  3{com}.         
.                 save "`data'/final_datasets/saeh_`i'.dta", replace 
{txt}  4{com}.         
.         {c )-}
.         
.         
. // Bring in SAEH data for  years 2010-2015, for which each component of the hospitalization form (Obstet, productos, egresos, defunciones, procedimientos, and afecciones) are stored separately 
. 
.         forvalues i=2010/2015 {c -(} 
{txt}  2{com}.         
.         di in red `i'
{txt}  3{com}.         
.         // Bring in obstetric section
.         di in red "obstet"
{txt}  4{com}.         import delimited using "`data'/SAEH_BD`i'/OBSTET.csv", clear
{txt}  5{com}.         cap rename ãid id 
{txt}  6{com}.         cap rename id, lower
{txt}  7{com}.         duplicates drop id, force
{txt}  8{com}. 
.         
.         tempfile obstet 
{txt}  9{com}.         save `obstet', replace
{txt} 10{com}.         
.         // Bring in productos section 
.         di in red "productos"
{txt} 11{com}.         import delimited using "`data'/SAEH_BD`i'/PRODUCTOS.csv", clear
{txt} 12{com}.         
.                 // Reshape so that we have 1 observation per woman, with number of babies and their respective variables wide. 
.                 cap rename ãid id 
{txt} 13{com}.                 cap rename id, lower
{txt} 14{com}. 
.                 reshape wide pesoprod sexprod condnac condegre naviapag navirean navicune, i(id) j(numproducto)
{txt} 15{com}. 
.         tempfile productos 
{txt} 16{com}.         save `productos', replace
{txt} 17{com}.         
.         // Bring in defunc section 
.         di in red "defunciones"
{txt} 18{com}.         import delimited using "`data'/SAEH_BD`i'/DEFUNC.csv", clear
{txt} 19{com}.         cap rename ãid id 
{txt} 20{com}.         cap rename ïid id 
{txt} 21{com}.         cap rename id, lower
{txt} 22{com}.         duplicates drop id, force
{txt} 23{com}. 
. 
.         tempfile defunc 
{txt} 24{com}.         save `defunc', replace
{txt} 25{com}.         
.         // Bring in procedimientos section 
.         di in red "procedimientos"
{txt} 26{com}.         import delimited using "`data'/SAEH_BD`i'/PROCEDIMIENTOS.csv", clear
{txt} 27{com}.         cap rename ãid id 
{txt} 28{com}.         cap rename id, lower
{txt} 29{com}. 
. 
.                 sort id promed
{txt} 30{com}.                 drop if numpromed > 11 // keep just the first 10 procedures. 
{txt} 31{com}.                 
.                 // Reshape so that we have 1 observation per woman
.                 cap drop afecprin derhab
{txt} 32{com}.                 duplicates drop id numpromed, force
{txt} 33{com}.                 reshape wide tipo promed anest quirof qh qm, i(id) j(numpromed)
{txt} 34{com}.                 
.         tempfile proced
{txt} 35{com}.         save `proced', replace
{txt} 36{com}.         
.         
.         // Bring in afecciones section 
.         di in red "afecciones"
{txt} 37{com}.         import delimited using "`data'/SAEH_BD`i'/AFECCIONES.csv", clear
{txt} 38{com}.         cap rename ãid id 
{txt} 39{com}.         cap rename id, lower
{txt} 40{com}. 
.         duplicates drop id numafec, force  // COME BACK TO THIS!
{txt} 41{com}.         duplicates drop id numafec afec, force
{txt} 42{com}.         reshape wide afec, i(id) j(numafec)
{txt} 43{com}.         
.         tempfile afec
{txt} 44{com}.         save `afec', replace
{txt} 45{com}.         
.         // Bring in egresos section 
.         di in red "egresos"
{txt} 46{com}.         import delimited using "`data'/SAEH_BD`i'/EGRESO.csv", clear
{txt} 47{com}.         cap rename ãid id 
{txt} 48{com}.         cap rename id, lower
{txt} 49{com}. 
. 
.                 //split egreso, p(" ")
.                 //drop egreso egreso2 
.                 //rename egreso1 egreso 
.                 
.         
.         // Merge with other datasets 
.         merge 1:1 id using `obstet', nogen
{txt} 50{com}.         merge 1:1 id using `productos', nogen
{txt} 51{com}.         merge 1:1 id using `defunc', nogen
{txt} 52{com}.         merge 1:1 id using `proced', nogen
{txt} 53{com}.         merge 1:1 id using `afec', nogen
{txt} 54{com}.         
.         gen year = `i'
{txt} 55{com}. 
.                 
.         save "`data'/saeh_`i'.dta", replace
{txt} 56{com}.         
.         {c )-}
. 
. {c )-}
{txt}
{com}. 
.                                         
. *************************************************************
. * 2) Append all years together and save appended dataset
. *************************************************************
. 
.         cd "`data'/final_datasets" 
{res}/Users/lilyalexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Datos nacionales/final_datasets
{txt}
{com}.         
.         use saeh_2000.dta, clear
{txt}
{com}.         
.         foreach year of local years {c -(}
{txt}  2{com}.                 if `year' != 2000 {c -(}
{txt}  3{com}.                         di in red `year'
{txt}  4{com}.                         
.                         
.                         append using saeh_`year'.dta, force
{txt}  5{com}.                 {c )-}
{txt}  6{com}.         {c )-}
{err}2001
{txt}{p 0 7 2}
(note: variable
peso01 was 
int, now long to accommodate using data's values)
{p_end}
{err}2002
{txt}{p 0 7 2}
(note: variable
clues was 
str11, now str12 to accommodate using data's values)
{p_end}
{err}2003
2004
2005
2006
{txt}{p 0 7 2}
(note: variable
servicio02 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
servicio03 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
anest05 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof05 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest06 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest07 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof07 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof08 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemia was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tiempoia was str3 in the using data, but will be
int now)
{p_end}
{err}2007
{txt}{p 0 7 2}
(note: variable
derhab was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
servicio02 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
servicio03 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
traumat was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
lugar was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sa_labor was str3 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sa_expul was str3 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sa_recup was str3 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sa_inten was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
sa_interm was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
anest01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest05 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof05 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest06 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest07 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof07 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest08 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof08 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
qh08 was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
qm08 was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tipaten was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
producto was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tipnaci was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
planfam was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
gestac was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
peso01 was str4 in the using data, but will be
long now)
{p_end}
{p 0 7 2}
(note: variable
peso02 was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
sexprod01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sexprod02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condnac01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condnac02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condegre01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condegre02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
naviapag01 was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
naviapag02 was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
naviapag03 was str2 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
navicune01 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
navicune02 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
navicune03 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemia was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tiempoia was str3 in the using data, but will be
int now)
{p_end}
{err}2008
{txt}{p 0 7 2}
(note: variable
tuhpsiq was byte in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
derhab was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sa_interm was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
qh01 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm01 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qh02 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm02 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
anest03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
quirof03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
qh03 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm03 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
anest04 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
quirof04 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
qh04 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm04 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qh05 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm05 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
quirof06 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
qh06 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm06 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qh07 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm07 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
navirean01 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
navirean02 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
navirean03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemic was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoic was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemid was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoid was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiia was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiia was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
veces was 
byte, now int to accommodate using data's values)
{p_end}
{err}2009
{txt}{p 0 7 2}
(note: variable
tuhpsiq was byte in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
derhab was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
qh01 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm01 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qh02 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm02 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
anest03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
quirof03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
qh03 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm03 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
anest04 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
quirof04 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
qh04 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
qm04 was byte in the using data, but will be
str2 now)
{p_end}
{p 0 7 2}
(note: variable
navirean01 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
navirean02 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
navirean03 was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemic was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoic was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemid was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoid was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiia was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiia was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
diag_ini was 
str4, now str11 to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
afecprin was 
str4, now str11 to accommodate using data's values)
{p_end}
{err}2010
{txt}{p 0 7 2}
(note: variable
tuhpsiq was byte in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
derhab was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemic was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoic was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemid was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoid was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiia was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiia was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiib was int in the using data, but will be
str3 now)
{p_end}
{err}2011
{txt}{p 0 7 2}
(note: variable
cloccve was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
tuhpsiq was byte in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
derhab was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemib was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoib was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemic was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoic was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemid was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoid was int in the using data, but will be
str3 now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiia was byte in the using data, but will be
str1 now)
{p_end}
{p 0 7 2}
(note: variable
tiempoiia was int in the using data, but will be
str3 now)
