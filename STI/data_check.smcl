{smcl}
{com}{sf}{ul off}{txt}
{com}. 
. 
. * ----------------------------
. * load/install packages
. * ----------------------------
. 
. /* 
> If needed, install necessary packages to compile notebook document (e.g., html, docx, pdf)
> these packages include: markdoc, kethcup, weaver, synlight, and statax
> note: if get any error messages, follow on-screen instructions in Stata console to 
> complete correct installation
> 
> * once install following packages once, do not need to re-install; 
> * here, commented out
> */
. *packages for MarkDoc
. *ssc install Markdoc
. *ssc install weaver
. *ssc install synlight
. *ssc install statax
. *markdocpandoc // installs pandoc
. *packages for analysis and presentation of results
. *ssc install estout, replace
. *ssc install outreg
. *ssc install pandoc
. *ssc install coefplot 
. 
. *-----------------------
. *-----------------------
. 
. 
. /* Template: 
> MI 20170122: 
> comments from Stata do-file will not appear in final markdoc.
> The text included in this do-file will only appear if it
> is blocked between a forward slash '/' and 3 asterisks '***', as done below
> immediately before start of latex syntax.
> */
.         
. 
. /***
> 
> \documentclass{c -(}article{c )-}
> 
> \usepackage{c -(}graphicx{c )-}  % this is a package for inserting graphics
> \usepackage{c -(}hyperref{c )-}
> \hypersetup{c -(}
>     colorlinks=true,
>     linkcolor=blue,
>     filecolor=blue,      
>     urlcolor=blue
>         {c )-}
>         
> \usepackage{c -(}geometry{c )-}   % useful package for formatting document
> \geometry{c -(}
>         letterpaper,
>         total={c -(}6.5in, 9in{c )-},
>         left=1in,
>         right=1in,
>         top=1in,
>         bottom=1in
>         {c )-}
> 
> \begin{c -(}document{c )-}
> 
> \title{c -(}Data Validation Exercise before Entry into UCSR{c )-}
> \author{c -(}
>   Lily Alexander
>   {c )-}
> 
>  \date{c -(}
>   \bigskip
>   \today
>   {c )-}
> 
> \maketitle
>         
> \begin{c -(}abstract{c )-}
> \textbf{c -(}Summary{c )-}. This is a document to validate and check variables before they are integrated into the UCSR.
> \end{c -(}abstract{c )-}
> 
> \section{c -(}High-level codebook for all variables{c )-}
> 
> \begin{c -(}verbatim{c )-}
> ***/
. 
. /* ------------------------
> load dataset
> ---------------------------
> */
. 
. /**/ use STI_clean_wide_file.dta, clear 
{txt}
{com}. 
. 
. /* ------------------------
> codebook generation
> ---------------------------
> */
. /**/ codebook 

{txt}{hline}
{res}study{right:Study}
{txt}{hline}

{col 19}type:  string ({res}str6{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"hiv200"
{col 21}         2{col 33}"hiv201"
{col 21}        11{col 33}"hiv202"
{col 21}         3{col 33}"hiv203"
{col 21}        12{col 33}"hiv205"
{col 21}        16{col 33}"hiv206"

{txt}{hline}
{res}collapsed{right:Collapsed}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"No"

{txt}{hline}
{res}Flags{right:(unlabeled)}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}id{right:ID Variable}
{txt}{hline}

{col 19}type:  string ({res}str7{txt})

{col 10}unique values:  {res}29{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 15}examples:  {res}"hiv202b"
{col 26}"hiv203b"
{col 26}"hiv205i"
{col 26}"hiv206c"

{txt}{hline}
{res}unit_cost{right:Unit Cost ID}
{txt}{hline}

{col 19}type:  string ({res}str11{txt})

{col 10}unique values:  {res}47{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 15}examples:  {res}"hiv202b_i"
{col 26}"hiv203b_i"
{col 26}"hiv205i_i"
{col 26}"hiv206c_ii"

{txt}{hline}
{res}lead_author{right:Lead Author}
{txt}{hline}

{col 19}type:  string ({res}str9{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"Benzaken "
{col 21}        11{col 33}"Carrara"
{col 21}         3{col 33}"Dandona"
{col 21}         2{col 33}"Gilson"
{col 21}        12{col 33}"Parker"
{col 21}        16{col 33}"Shelley"

{txt}{col 16}warning:  variable has trailing blanks

{txt}{hline}
{res}ref_author{right:Reference Authors}
{txt}{hline}

{col 19}type:  string ({res}str114{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"Benzaken, A. S., Sabidó, M., Galban, E.
{col 33}G., Pedroza, V., Vasquez, F., Araújo,
{col 33}A., ... & Mayaud, P."
{col 21}        11{col 33}"Carrara, V., Terris-Prestholt, F.,
{col 33}Kumaranayake, L., & Mayaud, P."
{col 21}         3{col 33}"Dandona, L., Sisodia, P., Prasad, T. L.
{col 33}N., Marseille, E., Rao, M. C., Kumar, A.
{col 33}A., ... & Kahn, J. G. "
{col 21}         2{col 33}"Gilson, L., Mkanje, R., Grosskurth, H.,
{col 33}Mosha, F., Picard, J., Gavyole, A., ...
{col 33}& Mabey, D"
{col 21}        12{col 33}"Parker, K. A., Koumans, E. H., Hawkins,
{col 33}R. V., Massanga, M., Somse, P., Barker,
{col 33}K., & Moran, J."
{col 21}        16{col 33}"Shelley, K. D., Ansbro, É. M., Ncube,
{col 33}A. T., Sweeney, S., Fleischer, C.,
{col 33}Mumba, G. T., ... & Terris-Prestholt,
{col 33}F."

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}ref_year{right:Reference Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}1997{txt},{res}2015{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}6{col 51}{txt}missing .:  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}1997
{col 21}        12{col 33}1999
{col 21}        11{col 33}2004
{col 21}         3{col 33}2005
{col 21}         3{col 33}2008
{col 21}        16{col 33}2015

{txt}{hline}
{res}title{right:Title}
{txt}{hline}

{col 19}type:  string ({res}str199{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"Cost and efficiency of public sector
{col 33}sexually transmitted infection clinics
{col 33}in Andhra Pradesh, India"
{col 21}         2{col 33}"Cost-effectiveness of improved
{col 33}treatment services for sexually
{col 33}transmitted diseases in preventing HIV-1
{col 33}infection in Mwanza Region, Tanzania "
{col 21}         3{col 33}"Field evaluation of the performance and
{col 33}testing costs of a rapid point-of-care
{col 33}test for syphilis in a red-light
{col 33}district of Manaus, Brazil "
{col 21}        11{col 33}"Operational and economic evaluation of
{col 33}an NGO-led sexually transmitted
{col 33}infections intervention: north-Western
{col 33}Cambodia"
{col 21}        12{col 33}"Providing Low-Cost Sexually Transmitted
{col 33}Diseases Services in Two Semi-Urban
{col 33}Health Centers in Central African
{col 33}Republic (CAR): Characteristics of
{col 33}Patients and Patterns of Health
{col 33}Care-Seeking Behavior "
{col 21}        16{col 33}"Scaling Down to Scale Up: A Health
{col 33}Economic Analysis of Integrating
{col 33}Point-of-Care Syphilis Testing into
{col 33}Antenatal Care in Zambia during Pilot
{col 33}and National Rollout Implementation"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}journal_etc{right:Journal}
{txt}{hline}

{col 19}type:  string ({res}str41{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"BMC Health Services Research "
{col 21}        11{col 33}"Bulletin of the World Health
{col 33}Organization"
{col 21}        16{col 33}"Plos one"
{col 21}         3{col 33}"Sex Transm Infect "
{col 21}        12{col 33}"Sexually Transmitted Diseases "
{col 21}         2{col 33}"The lancet"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}url{right:URL}
{txt}{hline}

{col 19}type:  string ({res}str242{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Cost+and+efficiency+of+public+sector+
{col 33}sexually+transmitted+infection+clinics+i
{col 33}n+Andhra+Pradesh%2C+India"
{col 21}         2{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Cost-effectiveness+of+improved+treatm
{col 33}ent+services+for+sexually+transmitted+di
{col 33}seases+in+preventing+HIV-1+infection+in+
{col 33}Mwanza+Region%2C+Tanzania"
{col 21}         3{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Field+evaluation+of+the+performance+a
{col 33}nd+testing+costs+of+a+rapid+point-of-car
{col 33}e+test+for+syphilis+in+a+red-light+distr
{col 33}ict+of+Manaus%2C+Brazil"
{col 21}        11{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Operational+and+economic+evaluation+o
{col 33}f+an+NGO-led+sexually+transmitted+infect
{col 33}ions+intervention%3A+north-Western+Cambo
{col 33}dia"
{col 21}        12{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Providing+Low-Cost+Sexually+Transmitt
{col 33}ed+Diseases+Services+in+Two+Semi-Urban+H
{col 33}ealth+Centers+in+Central+African+Republi
{col 33}c+(CAR)%3A+Characteristics+of+Patients+a
{col 33}nd+Patterns+of+Health+Care-Seeking+Behav
{col 33}ior"
{col 21}        16{col 33}"https://www.ncbi.nlm.nih.gov/pubmed/?te
{col 33}rm=Scaling+Down+to+Scale+Up%3A+A+Health+
{col 33}Economic+Analysis+of+Integrating+Point-o
{col 33}f-Care+Syphilis+Testing+into+Antenatal+C
{col 33}are+in+Zambia+during+Pilot+and+National+
{col 33}Rollout+Implementation"

{txt}{hline}
{res}ownership{right:Ownership}
{txt}{hline}

{col 19}type:  string ({res}str17{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"."
{col 21}        11{col 33}"International NGO"
{col 21}        16{col 33}"Mixed"
{col 21}        17{col 33}"Public"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_facility{right:Facility Category}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        30{col 33}"HC02"
{col 21}         3{col 33}"HC04"
{col 21}         2{col 33}"HC10"
{col 21}        12{col 33}"HC11"

{txt}{hline}
{res}platform{right:Platform}
{txt}{hline}

{col 19}type:  string ({res}str15{txt}), but longest is str14

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"Fixed facility"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_class{right:Intervention Class}
{txt}{hline}

{col 19}type:  string ({res}str10{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"Prevention"

{txt}{hline}
{res}id_type{right:Intervention Type}
{txt}{hline}

{col 19}type:  string ({res}str42{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        19{col 33}"Sexually Transmitted Infections"
{col 21}        28{col 33}"Sexually Transmitted Infections
{col 33}management"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_modality{right:Delivery Modality}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}disease{right:Disease}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        44{col 33}"STDs"
{col 21}         3{col 33}"Syphilis"

{txt}{hline}
{res}id_tech{right:(unlabeled)}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}id_tech_diag{right:Technology for diagnosis}
{txt}{hline}

{col 19}type:  string ({res}str41{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        28{col 33}"."
{col 21}        16{col 33}"SD Bioline RST; confirmatory RPR test
{col 33}kit"
{col 21}         3{col 33}"VisiTect, FTA-Abs, VDRL"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_tech_treat{right:Technology for treatment}
{txt}{hline}

{col 19}type:  string ({res}str89{txt})

{col 10}unique values:  {res}13{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 15}examples:  {res}"."
{col 26}"Benzathine penicillin (2.5 MU 1 dose)"
{col 26}"Benzathine penicillin (2.5 MU 1 dose)"
{col 26}"benzathine penicillin"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}id_tech_prevention{right:Technology for prevention}
{txt}{hline}

{col 19}type:  string ({res}str7{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        35{col 33}"."
{col 21}         8{col 33}"Condoms"
{col 21}         4{col 33}"condoms"

{txt}{hline}
{res}id_phase{right:Phase}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}int_description_long{right:Intervention Description (Long)}
{txt}{hline}

{col 19}type:  string ({res}str1490{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"
We included STI clinics in the
{col 33}government-run public sec- tor hospitals
{col 33}for this study. These clinics provide
{col 33}services predominantly to the poor at no
{col 33}or minimal fee, and many persons
{col 33}receiving services here have relatively
{col 33}advanced STIs. At the time of starting
{col 33}data collection for this study in
{col 33}mid-2004, 85 public sector clinics were
{col 33}func- tioning. Of these, 28 STI clinics
{col 33}had been functioning since the 1960's in
{col 33}the state capital and the district head-
{col 33}quarters as part of the medical college
{col 33}hospitals and other major public
{col 33}hospitals of Andhra Pradesh. In
{col 33}addition, 57 STI clinics were formally
{col 33}designated in mid-2002 in pub- lic
{col 33}hospitals, in district headquarter
{col 33}hospitals and in area hospitals located
{col 33}in smaller jurisdictions. Generally, the
{col 33}STI care in medical college hospitals
{col 33}and district head- quarter hospitals is
{col 33}provided in distinct separate clinics,
{col 33}whereas in area hospitals it is provided
{col 33}as part of the gen- eral outpatient."
{col 21}         8{col 33}"A centralized two-day RST training
{col 33}workshop took place before RST was
{col 33}integrated within existing clinic
{col 33}staffing patterns, patient flow, and
{col 33}clinic processes alongside other routine
{col 33}antenatal POC tests (HIV, malaria, and
{col 33}haemoglobin). The pilot uti- lised SD
{col 33}BIOLINE Syphilis 3.0, a rapid POC
{col 33}syphilis antibody test produced by
{col 33}Standard Diagnostics (Yongin-Si, South
{col 33}Korea), with a manufacturer reported
{col 33}99.3% sensitivity and 99.5% specificity
{col 33}in serum versus the gold standard
{col 33}Treponema pallidum haemagglutination
{col 33}(TPHA) test ; of note, a recent
{col 33}meta-analysis of the diagnostic accuracy
{col 33}of SD Bioline 3.0 in field conditions
{col 33}reported a lower pooled sensitivity
{col 33}(87.9% serum; 83.8% whole blood) and
{col 33}specificity (96.0% serum; 98.4% whole
{col 33}blood). Pilot-specific QA and quality
{col 33}control (QC) measures were established
{col 33}to ensure high standards of quality
{col 33}management. The pilot results showed
{col 33}increased syphilis testing among ANC
{col 33}attendees (79.9% versus 95.6%, p<0.0001)
{col 33}and treatment of syphilis positive
{col 33}pregnant women (51.1% versus 95.2%,
{col 33}p<0.0001), and demon- strated the
{col 33}feasibility of integrating RST within
{col 33}busy urban and rural ANC settings in
{col 33}Zambia. Zambian syphilis treatment
{col 33}guideline pre-RST adoption was three
{col 33}weekly doses of Benzathine Penicillin
{col 33}(BP). During the pilot, patients were
{col 33}given one documented dose of BP
{col 33}following a positive RST test.
"
{col 21}         3{col 33}"Between May and October 2006,
{col 33}consecutive unselected patients with no
{col 33}age restriction presenting at the FUAM
{col 33}harbour clinic who showed interest in
{col 33}being screened with the rapid POC
{col 33}VisiTect Syphilis test (Omega
{col 33}Diagnostics, Alloa, Scotland) were
{col 33}invited to participate in the study. We
{col 33}included male and female sex workers,
{col 33}sex worker clients, and other patients
{col 33}living and working in the area who
{col 33}accessed the clinic. A sex worker client
{col 33}was defined as those men or women who
{col 33}reported having had sex with a male or
{col 33}female sex worker in the last 12 months.
{col 33}At the end of each clinic, venous blood
{col 33}samples were transferred to the FUAM
{col 33}laboratory. A laboratory technician,
{col 33}blind to the POC test results, tested
{col 33}sera using the FTA-Abs (WAMA
{col 33}Diagnostica, S ̃ao Paulo, Brazil) and
{col 33}VDRL (Winer Laboratorios, Rosario,
{col 33}Argentina), and VDRL titres were
{col 33}determined. The reference standard test
{col 33}for syphilis was FTA-Abs. This widely
{col 33}used test was considered the most
{col 33}appropriate comparator since the rapid
{col 33}POC test was also Treponema specific.
{col 33}Active syphilis was defined as sera
{col 33}reactive with both FTA-Abs and VDRL,
{col 33}with high and low titre active syphilis
{col 33}defined based on VDRL titres > or ,1:8,
{col 33}respectively. Participants with a
{col 33}positive POC test were treated
{col 33}immediately with one intramuscular
{col 33}injection of 2.4 MU benzathine
{col 33}penicillin."
{col 21}        12{col 33}"Paramedical health workers (medical
{col 33}assistants or nurses) were selected at
{col 33}each site to receive training in three
{col 33}programmatic areas: clinical management
{col 33}of STDs using simple algorithms adapted
{col 33}from those recommended by the World
{col 33}Health Organization, patient education
{col 33}and counseling. A complementary
{col 33}step-by-step job aid detailing the
{col 33}sequence and content of the clinical
{col 33}encounter was given to the providers and
{col 33}their supervisors. A minimum of two
{col 33}workers were trained at each site to
{col 33}prevent the interruption of services in
{col 33}the event of illness, vacation, and
{col 33}attrition. One trained worker at each
{col 33}site was then dedicated to the delivery
{col 33}of STD care using a private consultation
{col 33}room designated for that purpose in the
{col 33}OPD building.
Patients presented at the
{col 33}outpatient registration and triage; they
{col 33}could be self-referred (with symptoms or
{col 33}referral vouchers) or referred by the
{col 33}maternal and child health clinic or
{col 33}school health service. After history
{col 33}taking and a clinical examination, the
{col 33}provider explained the diagnosis and
{col 33}treatment to each patient. Single dose
{col 33}oral therapy and initial doses of
{col 33}multidose therapy (e.g., ciprofloxacin
{col 33}and doxycycline, respectively) were
{col 33}taken in the provider's presence.
{col 33}Providers then offered partner referral
{col 33}vouchers and explained the importance of
{col 33}partner treatment. The visit ended with
{col 33}a discussion and demonstration of condom
{col 33}use using a wooden model of a penis.
{col 33}Patients received drugs for a complete
{col 33}treatment and a packet of four condoms."
{col 21}        11{col 33}"The MSF project initially aimed to
{col 33}offer STI clinical services and outreach
{col 33}on HIV/AIDS prevention and condom
{col 33}distribution to these sex workers and
{col 33}their clients. Both clinics were located
{col 33}near red-light districts and
{col 33}marketplaces to facilitate access for
{col 33}clients. The clinics also accepted
{col 33}patients presenting with non-STI related
{col 33}complaints as well as members of the
{col 33}general population. STI case management
{col 33}at the MSF clinics included taking a
{col 33}detailed history and assessing the risk
{col 33}of being infected with an STI, clinical
{col 33}examination (including a speculum
{col 33}examination for women), health
{col 33}education, promotion of condom use, and
{col 33}treatment using the syndromic approach.
{col 33}STI index patients were provided with a
{col 33}contact slip to allow them to notify
{col 33}their sexual partners; these partners
{col 33}were treated in accordance with the
{col 33}patient’s syndrome, irrespective of the
{col 33}presence of symptoms. "
{col 21}         2{col 33}"The intervention was designed to be
{col 33}replicable and sustainable in the rural
{col 33}Tanzanian setting, and had five main
{col 33}elements. Primary-health-care workers
{col 33}from all health units in each community
{col 33}were trained to recognise and treat STDs
{col 33}by use of syndromic treatment
{col 33}algorithms. The primary-health-care
{col 33}workers were provided with simple
{col 33}equipment required for diagnosis of STDs
{col 33}, and a regular supply of appropriate
{col 33}drugs and consumables was assured.
{col 33}Supervisory visits were made roughly
{col 33}every 6 weeks to review the treatments
{col 33}prescribed by the primary-health-care
{col 33}workers and to provide further informal
{col 33}training. A health education team
{col 33}visited the villages served by each
{col 33}health unit every 6 months to encourage
{col 33}prompt attendance for STD treatment. A
{col 33}reference clinic was established in
{col 33}Mwanza town to act as a training centre
{col 33}for rural primary-health-care workers
{col 33}and to monitor the aetiology of STD
{col 33}syndromes and the effectiveness of the
{col 33}treatment algorithms."
{col 21}         8{col 33}"Treatment alogorithm: Treat with one
{col 33}dose of BP following positive RST
{col 33}result; run RPR confirmation and if
{col 33}active infection confirmed, treat with
{col 33}two additional doses of BP. If RPR
{col 33}confirmation unavailable, continue 2nd
{col 33}and 3rd weekly dose of BP.
"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}start_month{right:Start Month}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"1"
{col 21}        12{col 33}"10"
{col 21}        16{col 33}"3"
{col 21}         1{col 33}"4"
{col 21}         4{col 33}"5"
{col 21}         1{col 33}"6"
{col 21}        11{col 33}"7"

{txt}{hline}
{res}start_year{right:Start Year}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}9{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"1992"
{col 21}        12{col 33}"1993"
{col 21}        11{col 33}"1997"
{col 21}         1{col 33}"2003"
{col 21}         1{col 33}"2004"
{col 21}         1{col 33}"2005"
{col 21}         3{col 33}"2006"
{col 21}         8{col 33}"2010"
{col 21}         8{col 33}"2012"

{txt}{hline}
{res}end_month{right:End Month}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        12{col 33}"1"
{col 21}         3{col 33}"10"
{col 21}        13{col 33}"12"
{col 21}         1{col 33}"3"
{col 21}         1{col 33}"4"
{col 21}         1{col 33}"5"
{col 21}        16{col 33}"7"

{txt}{hline}
{res}end_year{right:End Year}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"1993"
{col 21}        12{col 33}"1996"
{col 21}        11{col 33}"1999"
{col 21}         3{col 33}"2004"
{col 21}         3{col 33}"2006"
{col 21}         8{col 33}"2010"
{col 21}         8{col 33}"2012"

{txt}{hline}
{res}period_portrayed{right:Total Months}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}5{txt},{res}30{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}6{col 51}{txt}missing .:  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        16{col 33}5
{col 21}         3{col 33}6
{col 21}         3{col 33}12
{col 21}         2{col 33}24
{col 21}        12{col 33}28
{col 21}        11{col 33}30

{txt}{hline}
{res}coverage{right:Coverage}
{txt}{hline}

{col 19}type:  numeric ({res}byte{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}int_services{right:Integrated Services}
{txt}{hline}

{col 19}type:  string ({res}str20{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        31{col 33}"Integrated"
{col 21}        16{col 33}"Partially integrated"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}country{right:Country}
{txt}{hline}

{col 19}type:  string ({res}str25{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"Brazil"
{col 21}        11{col 33}"Cambodia "
{col 21}        12{col 33}"Central African Republic "
{col 21}         3{col 33}"India"
{col 21}         2{col 33}"Tanzania"
{col 21}        16{col 33}"Zambia"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}region{right:Region}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        14{col 33}"Asia"
{col 21}         3{col 33}"LAC"
{col 21}        30{col 33}"SSA"

{txt}{hline}
{res}pop_density{right:Urbanicity}
{txt}{hline}

{col 19}type:  string ({res}str10{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        11{col 33}"Mixture"
{col 21}        12{col 33}"Peri-Urban"
{col 21}         6{col 33}"Rural"
{col 21}        18{col 33}"Urban"

{txt}{hline}
{res}neonates{right:Target group (demographic)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})
{ralign 22:label}:  {res:neonates}

{col 18}range:  [{res}0{txt},{res}0{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.   Numeric  Label
{col 21}{res}        47{col 33}       0{col 43}{txt}Adults and/or Adolescents

{txt}{hline}
{res}location{right:Location}
{txt}{hline}

{col 19}type:  string ({res}str97{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"Andhra Pradesh state"
{col 21}        12{col 33}"Bambari and  Bria"
{col 21}        11{col 33}"Banteay Meanchey province "
{col 21}         3{col 33}"Manaus "
{col 21}         8{col 33}"Mansa (Luapula Province), Kalomo
{col 33}(Southern Province), and Lundazi and
{col 33}Nyimba (Eastern Province). "
{col 21}         8{col 33}"Mongu and Lusaka"
{col 21}         2{col 33}"Mwanza"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}ss_unique_trait{right:Unique Trait}
{txt}{hline}

{col 19}type:  string ({res}str74{txt})

{col 10}unique values:  {res}29{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 15}examples:  {res}"Phase: Pilot. Setting: Urban"
{col 26}"Phase: Rollout. Setting: all"
{col 26}"Syndrome: pelvic Inflamatory Disease (PID).
{col 26}Population: non-pregnant women"
{col 26}"Year of program implementation: 1997"

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}id_pop_dem_std{right:Population served}
{txt}{hline}

{col 19}type:  string ({res}str30{txt}), but longest is str23

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"general population"
{col 21}         3{col 33}"FSWs; MSWs; SW clients"
{col 21}        11{col 33}"FSWs; MSWs; SW partners"
{col 21}         3{col 33}"FSWs; SW partners"
{col 21}        16{col 33}"Women on ANC"
{col 21}        12{col 33}"general population"

{txt}{col 16}warning:  variable has leading and embedded blanks

{txt}{hline}
{res}pop_age{right:Average Age}
{txt}{hline}

{col 19}type:  string ({res}str10{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        41{col 33}"."
{col 21}         3{col 33}"27.9"
{col 21}         2{col 33}"28"
{col 21}         1{col 33}"70-75% >19"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}pop_sex{right:Gender}
{txt}{hline}

{col 19}type:  string ({res}str11{txt})

{col 10}unique values:  {res}7{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        29{col 33}"."
{col 21}        11{col 33}"17% males"
{col 21}         1{col 33}"35.8% males"
{col 21}         1{col 33}"5.1% males"
{col 21}         1{col 33}"54-57% male"
{col 21}         3{col 33}"60% females"
{col 21}         1{col 33}"66.3% males"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}pop_ses{right:SES}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}pop_education{right:Education}
{txt}{hline}

{col 19}type:  string ({res}str37{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        44{col 33}"."
{col 21}         3{col 33}"52% didn't complete elementary school"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}pop_couples{right:Couples}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        36{col 33}"."
{col 21}        11{col 33}".13"

{txt}{hline}
{res}hiv_prev{right:HIV Prevalence}
{txt}{hline}

{col 19}type:  string ({res}str9{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        27{col 33}"."
{col 21}         3{col 33}".025"
{col 21}         2{col 33}".04"
{col 21}         1{col 33}".22"
{col 21}        11{col 33}".41"
{col 21}         3{col 33}"16–30% "

{txt}{col 16}warning:  variable has trailing blanks

{txt}{hline}
{res}cd4_med{right:Median CD4 Count}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}cd4_range{right:CD4 Range}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}tb_prev{right:TB Prevalence}
{txt}{hline}

{col 19}type:  string ({res}str2{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}tb_rx_resistance{right:TB Drug Resistance}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}costing_purpose_cat{right:Costing Purpose}
{txt}{hline}

{col 19}type:  string ({res}str26{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        12{col 33}"Tech efficiency analysis"
{col 21}         5{col 33}"econ eval/priority setting"
{col 21}        27{col 33}"mixed"
{col 21}         3{col 33}"tech efficiency analysis"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}timing{right:Timing}
{txt}{hline}

{col 19}type:  string ({res}str15{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"cross-sectional"

{txt}{hline}
{res}country_sampling{right:Country Sampling}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}geo_sampling_incountry{right:Geographic Area In Country Sampling}
{txt}{hline}

{col 19}type:  string ({res}str9{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        15{col 33}"."
{col 21}         2{col 33}"cluster"
{col 21}        30{col 33}"purposive"

{txt}{hline}
{res}site_sampling{right:Site Sampling}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}5{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        12{col 33}"."
{col 21}         3{col 33}"cluster"
{col 21}        11{col 33}"convenience"
{col 21}        11{col 33}"entire program"
{col 21}        10{col 33}"purposive"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}px_sampling{right:Patient Sampling}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}4{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        39{col 33}"."
{col 21}         3{col 33}"convenience"
{col 21}         3{col 33}"entire program"
{col 21}         2{col 33}"random"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}sample_size_derived{right:Sample size formally derived}
{txt}{hline}

{col 19}type:  string ({res}str2{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"no"

{txt}{hline}
{res}controls{right:Controls}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        45{col 33}"."
{col 21}         2{col 33}"yes"

{txt}{hline}
{res}econ_perspective_actual{right:Perspective}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"provider"

{txt}{hline}
{res}econ_costing{right:Economic / Financial}
{txt}{hline}

{col 19}type:  string ({res}str14{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        35{col 33}"economic"
{col 21}        12{col 33}"financial only"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}real_world{right:Real World / Per Protocol}
{txt}{hline}

{col 19}type:  string ({res}str10{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}"mix"
{col 21}        45{col 33}"real world"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}asd_costs{right:Above Service Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str19{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        12{col 33}"."
{col 21}         6{col 33}"no costs included"
{col 21}        29{col 33}"some costs included"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}list_asd_costs{right:Above Service Cost List}
{txt}{hline}

{col 19}type:  string ({res}str204{txt})

{col 10}unique values:  {res}6{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        15{col 33}"."
{col 21}         8{col 33}"Supervision; Central personnel; vehicle
{col 33}operation/maintenance; vehicle capital"
{col 21}         8{col 33}"Supervision; Central personnel; vehicle
{col 33}operation/maintenance; vehicle capital;
{col 33}quality assurance/control; incoming
{col 33}inspection; external quality control;
{col 33}external quality assurance; confirmatory
{col 33}retesting"
{col 21}         2{col 33}"Training manuals; training hall;
{col 33}training supervisors and central
{col 33}support"
{col 21}        11{col 33}"Traininig, Supervision and shared costs
{col 33}related to setting up buildings"
{col 21}         3{col 33}"none"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}research_costs{right:Research Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str8{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        26{col 33}"."
{col 21}        21{col 33}"excluded"

{txt}{hline}
{res}unrelated_costs{right:Unrelated Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}overhead{right:Overhead Costs Included}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        16{col 33}"Yes"
{col 21}        31{col 33}"no"

{txt}{hline}
{res}overhead_costs{right:Overhead Costs List}
{txt}{hline}

{col 19}type:  string ({res}str347{txt})

{col 10}unique values:  {res}5{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}"."
{col 21}         2{col 33}"Office equipment and furniture,
{col 33}vehicles, field equipment and equipment
{col 33}for PHCWs"
{col 21}        11{col 33}"buildings, capital equipment items and
{col 33}vehicles"
{col 21}        28{col 33}"none"
{col 21}         3{col 33}"outpatient and inpatient furniture,
{col 33}electrical fixtures, refrigerator,
{col 33}centrifuge, microscope, needle and
{col 33}syringe destroyer, water bath, slide
{col 33}rotator, water filter, sterilizer, and
{col 33}weighing machine. cleaning and building
{col 33}maintenance, electricity, water,
{col 33}telephone, gas/oil, waste disposal, the
{col 33}occasional training of staff during that
{col 33}fiscal year"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}omitted_costs{right:Author-reported Omitted Costs}
{txt}{hline}

{col 19}type:  string ({res}str147{txt}), but longest is str71

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}42{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        42{col 33}""
{col 21}         3{col 33}"Costs of infrastructure, training and
{col 33}supervision "
{col 21}         2{col 33}"health-unit staff, routine supervision,
{col 33}and general capital investment "

{txt}{col 16}warning:  variable has embedded and trailing blanks

{txt}{hline}
{res}volunteer_time{right:Valuing Volunteer Time}
{txt}{hline}

{col 19}type:  string ({res}str1{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}family_time{right:Valuing Family Time}
{txt}{hline}

{col 19}type:  string ({res}str3{txt}), but longest is str1

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"."

{txt}{hline}
{res}currency_yr{right:Reported Currency Year}
{txt}{hline}

{col 19}type:  numeric ({res}int{txt})

{col 18}range:  [{res}1993{txt},{res}2012{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}7{col 51}{txt}missing .:  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         2{col 33}1993
{col 21}        12{col 33}1994
{col 21}        11{col 33}2002
{col 21}         3{col 33}2004
{col 21}         3{col 33}2006
{col 21}         8{col 33}2010
{col 21}         8{col 33}2012

{txt}{hline}
{res}iso_code{right:Reported Currency}
{txt}{hline}

{col 19}type:  string ({res}str3{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"USD"

{txt}{hline}
{res}currency_x{right:Currency Exchange Method}
{txt}{hline}

{col 19}type:  string ({res}str11{txt})

{col 10}unique values:  {res}2{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        12{col 33}"."
{col 21}        35{col 33}"market only"

{txt}{col 16}warning:  variable has embedded blanks

{txt}{hline}
{res}current_x_rate{right:Currency Exchange Rate}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.14{txt},{res}5219.83{txt}]{col 55}units:  {res}.01
{col 10}{txt}unique values:  {res}6{col 51}{txt}missing .:  {res}12{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         3{col 33}2.14
{col 21}        11{col 33}36.5
{col 21}         3{col 33}45.95
{col 21}         2{col 33}479.87
{col 21}         8{col 33}4743.98
{col 21}         8{col 33}5219.83
{col 21}        12{col 33}.

{txt}{hline}
{res}discount_rate{right:Discount Rate}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.03{txt},{res}.03{txt}]{col 55}units:  {res}1
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}18{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        29{col 33}.03
{col 21}        18{col 33}.

{txt}{hline}
{res}sensitivity_analysis{right:Sensitivity Analysis}
{txt}{hline}

{col 19}type:  string ({res}str13{txt})

{col 10}unique values:  {res}3{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        21{col 33}"comprehensive"
{col 21}        11{col 33}"limited"
{col 21}        15{col 33}"none"

{txt}{hline}
{res}uncertainty_rmk{right:Uncertainty Remarks}
{txt}{hline}

{col 19}type:  string ({res}str4{txt})

{col 10}unique values:  {res}1{col 51}{txt}missing "":  {res}0{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}"none"

{txt}{hline}
{res}mean_cost{right:Mean Unit Cost}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.64795708{txt},{res}183.65781{txt}]{col 55}units:  {res}1.000e-08
{col 10}{txt}unique values:  {res}45{col 51}{txt}missing .:  {res}0{txt}/{res}47

{txt}{col 19}mean:{res}{col 26} 38.2974
{txt}{col 15}std. dev:{res}{col 26}  51.546

{txt}{col 12}percentiles:{col 32}10%{col 42}25%{col 52}50%{col 62}75%{col 72}90%
{res}{col 27} 2.80123{col 37} 5.63485{col 47} 13.5961{col 57} 57.0146{col 67} 122.996

{txt}{hline}
{res}si_capital{right:Capital (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}4.1332435{txt},{res}14.087191{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}4.1332435
{col 21}         1{col 33}14.087191
{col 21}        45{col 33}.

{txt}{hline}
{res}si_mixed{right:Mixed (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}si_personnel{right:Personnel (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}1.2816259{txt},{res}31.082287{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}5{col 51}{txt}missing .:  {res}42{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}1.2816259
{col 21}         1{col 33}9.4956684
{col 21}         1{col 33}9.9115562
{col 21}         1{col 33}18.660074
{col 21}         1{col 33}31.082287
{col 21}        42{col 33}.

{txt}{hline}
{res}si_recurrent{right:Recurrent Goods (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.8012304{txt},{res}17.899778{txt}]{col 55}units:  {res}1.000e-08
{col 10}{txt}unique values:  {res}17{col 51}{txt}missing .:  {res}30{txt}/{res}47

{txt}{col 19}mean:{res}{col 26} 7.54972
{txt}{col 15}std. dev:{res}{col 26} 4.20387

{txt}{col 12}percentiles:{col 32}10%{col 42}25%{col 52}50%{col 62}75%{col 72}90%
{res}{col 27} 3.68454{col 37} 5.27862{col 47} 5.71581{col 57} 8.29035{col 67} 14.3462

{txt}{hline}
{res}si_cap_medical_equip{right:Capital: Equipment (medical) (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.38786046{txt},{res}.38786046{txt}]{col 55}units:  {res}1.000e-08
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}.38786046
{col 21}        46{col 33}.

{txt}{hline}
{res}si_cap_nonmed_equip{right:Capital: Equipment (non-medical) (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.778666{txt},{res}2.778666{txt}]{col 55}units:  {res}1.000e-06
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}2.778666
{col 21}        46{col 33}.

{txt}{hline}
{res}si_cap_other{right:Capital: Other capital (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}1.6374457{txt},{res}3.2956271{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}1.6374457
{col 21}         1{col 33}3.2956271
{col 21}        45{col 33}.

{txt}{hline}
{res}si_mix_mixed{right:Mixed: Mixed (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}si_per_mixed_unspec{right:Personnel: Direct Service Delivery (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}9.495668{txt},{res}31.082287{txt}]{col 55}units:  {res}1.000e-06
{col 10}{txt}unique values:  {res}4{col 51}{txt}missing .:  {res}43{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}9.4956684
{col 21}         1{col 33}9.9115562
{col 21}         1{col 33}18.660074
{col 21}         1{col 33}31.082287
{col 21}        43{col 33}.

{txt}{hline}
{res}si_per_service_delivery{right:Personnel: Support (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}si_per_support{right:Personnel: Mixed Unspecified (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}1.2816259{txt},{res}1.2816259{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}1.2816259
{col 21}        46{col 33}.

{txt}{hline}
{res}si_rec_building_space{right:Recurring: Building Space (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}1.0061114{txt},{res}2.3054919{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}4{col 51}{txt}missing .:  {res}43{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}1.0061114
{col 21}         1{col 33}1.2924027
{col 21}         1{col 33}1.7105672
{col 21}         1{col 33}2.3054919
{col 21}        43{col 33}.

{txt}{hline}
{p 0 39}{res}si_rec_med_int_supplies{space 16}Recurring: Medical Supplies (excluding drugs) (SI){p_end}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}3.5076077{txt},{res}9.5637805{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}3.5076077
{col 21}         1{col 33}9.5637805
{col 21}        45{col 33}.

{txt}{hline}
{res}si_rec_nonmed_int_supplies{right:Recurring: Non-medical Supplies (SI)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.16863498{txt},{res}2.0678444{txt}]{col 55}units:  {res}1.000e-08
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}.16863498
{col 21}         1{col 33}2.0678444
{col 21}        45{col 33}.

{txt}{hline}
{res}a_ancillary{right:Ancillary (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_mixed{right:Mixed (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_operational{right:Operational (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.8012304{txt},{res}58.739707{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}17{col 51}{txt}missing .:  {res}30{txt}/{res}47

{txt}{col 19}mean:{res}{col 26} 11.1524
{txt}{col 15}std. dev:{res}{col 26} 12.8982

{txt}{col 12}percentiles:{col 32}10%{col 42}25%{col 52}50%{col 62}75%{col 72}90%
{res}{col 27} 4.82524{col 37} 5.63485{col 47} 6.93258{col 57} 9.91156{col 67} 18.6601

{txt}{hline}
{res}a_primary_sd{right:Primary Service Delivery (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}4.8229606{txt},{res}4.8229606{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}4.8229606
{col 21}        46{col 33}.

{txt}{hline}
{res}a_secondary_sd{right:Secondary Service Delivery (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_anc_demand_generation{right:Ancillary: Demand Generation (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_anc_lab_services{right:Anicllary: Lab Services (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_anc_unspecified{right:Ancillary: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_mix_mixed{right:Ancillary: Mixed (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_ope_bldg_equip{right:Operational: Buildings and Equipment (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.15177149{txt},{res}11.890106{txt}]{col 55}units:  {res}1.000e-12
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}.15177149
{col 21}         1{col 33}11.890106
{col 21}        45{col 33}.

{txt}{hline}
{res}a_ope_logistics{right:Operational: Logistics (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_ope_program_mgmt{right:Operational: Program Management (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_ope_supervision{right:Operational: Supervision (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}.8600384{txt},{res}.8600384{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}.8600384
{col 21}        46{col 33}.

{txt}{hline}
{res}a_ope_training{right:Operational: Training (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.5143476{txt},{res}2.5143476{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}1{col 51}{txt}missing .:  {res}46{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}2.5143476
{col 21}        46{col 33}.

{txt}{hline}
{res}a_ope_transportation{right:Operational: Transportation (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.4555653{txt},{res}3.4064267{txt}]{col 55}units:  {res}1.000e-10
{col 10}{txt}unique values:  {res}2{col 51}{txt}missing .:  {res}45{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}2.4555653
{col 21}         1{col 33}3.4064267
{col 21}        45{col 33}.

{txt}{hline}
{res}a_ope_unspecified{right:Operational: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}2.8012304{txt},{res}42.713912{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}16{col 51}{txt}missing .:  {res}31{txt}/{res}47

{txt}{col 19}mean:{res}{col 26} 10.4145
{txt}{col 15}std. dev:{res}{col 26} 9.54594

{txt}{col 12}percentiles:{col 32}10%{col 42}25%{col 52}50%{col 62}75%{col 72}90%
{res}{col 27} 4.82524{col 37} 5.56198{col 47} 6.91402{col 57} 11.6188{col 67} 18.6601

{txt}{hline}
{res}a_prisd_circumcision_proced{right:Primary SD: Circumcision Procedure (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.

{txt}{hline}
{res}a_prisd_unspecified{right:Primary SD: Unspecified (A)}
{txt}{hline}

{col 19}type:  numeric ({res}double{txt})

{col 18}range:  [{res}1.7375053{txt},{res}3.6762427{txt}]{col 55}units:  {res}1.000e-07
{col 10}{txt}unique values:  {res}4{col 51}{txt}missing .:  {res}43{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}         1{col 33}1.7375053
{col 21}         1{col 33}1.91705
{col 21}         1{col 33}2.1854141
{col 21}         1{col 33}3.6762427
{col 21}        43{col 33}.

{txt}{hline}
{res}a_secsd_hct{right:Secondary SD: HIV Counseling and Testing (A)}
{txt}{hline}

{col 19}type:  numeric ({res}float{txt})

{col 18}range:  [{res}.{txt},{res}.{txt}]{col 55}units:  {res}.
{col 10}{txt}unique values:  {res}0{col 51}{txt}missing .:  {res}47{txt}/{res}47

{txt}{col 13}tabulation:  Freq.  Value
{col 21}{res}        47{col 33}.
{txt}
{com}. /*
> 
> \end{c -(}verbatim{c )-}
> 
> 
> 
> \begin{c -(}verbatim{c )-}
> ***/
. 
. * can generate clean tables
. 
. /**/ quietly cd "C:\Users\Lily Alexander\Dropbox\ALL LIFE THINGS\INSP\Work with Sergio\GHCC\post_extraction_processing\STI\checks"
{txt}
{com}. /**/ quietly eststo sumstats: quietly estpost summarize
{txt}
{com}. 
. /**/ quietly esttab sumstats using sumstats, ///
>         cells("count mean sd min max") ///
>         title("Summary Statistics") tex  replace
{txt}
{com}. * note: do not use 'fragment' with esttab; doing so removes centering and 
. * tabular syntax
. 
. 
. * go back to main dir
. /**/ quietly cd "C:\Users\Lily Alexander\Dropbox\ALL LIFE THINGS\INSP\Work with Sergio\GHCC\post_extraction_processing\STI"
{txt}
{com}. 
. 
. /***
> \end{c -(}verbatim{c )-}
> 
> Here we import the table of summary statistics.\\
> 
> \input{c -(}./output/sumstats{c )-} 
> 
> Now lets generate and add a figure that visualizing one of these variables.\\
> 
> ----------------------
> export final tex document
> -----------------------------
> */
. 
. /* Exporting in several formats */
. *markdoc example1, replace              /* exporting a markdown file */
. *markdoc example1, replace export(html) 
. *markdoc example1, replace export(odt) 
. *markdoc example1, replace export(txt) 
. *markdoc example1, replace export(epub) 
. *markdoc mytemplatelatex, replace author() affiliation() export(docx) 
. /* could add date option (no parentheses) */
. *markdoc mytemplatelatex, replace author() affiliation() export(pdf)
. 
. * markdoc mytemplatelatex, replace author() affiliation() export(docx) markup()
. * markdoc mytemplatelatex, replace author() affiliation() export(html) markup()
. markdoc data_check, replace author() affiliation() export(tex) markup()
{txt}{p}(MarkDoc created {bf:{browse "data_check.tex"}})


{com}. 
. /*
> can also produce pdf slides:
> markdoc example1, replace author(Matthew C. Ingram) affiliation(University at Albany, SUNY) date export(slide)
> NOTE: this will replace any existing pdf file with same name, so be cautious
> */
. 
. * end
. 
. 
. 
{txt}end of do-file

{com}. br

. lookfor unit

              {txt}storage   display    value
variable name   type    format     label      variable label
{hline}
{p 0 48}{res}{bind:unit_cost      }{txt}{bind: str11   }{bind:{txt}%11s      }{space 1}{bind:         }{bind:  }{res}{res}Unit Cost ID{p_end}
{p 0 48}{bind:mean_cost      }{txt}{bind: double  }{bind:{txt}%10.0g    }{space 1}{bind:         }{bind:  }{res}{res}Mean Unit Cost{p_end}

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. **************************************************************************
. **************************************************************************
. ** Do file for export of VMMC studies to the UCSR, using select variables
. ** Lily Alexander
. ** Univ of Washington 
. ** January 2018 
. ** lilyalexander18@gmail.com; lalexan1@uw.edu
. **************************************************************************
. **************************************************************************
. **************************************************************************
. 
. ** Data requirements
. **
. **  Must use data already formatted into wide file for GHCC analysis
. **              - These are available upon request
. **              - Procedure to be replicated for other intervention areas (ART, etc)
. **              - As well as other diseases (TB)
. **************************************************************************
. 
. set more off 
{txt}
{com}.         clear
{txt}
{com}.         cd "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/post_extraction_processing/STI"
{res}C:\Users\Lily Alexander\Dropbox\ALL LIFE THINGS\INSP\Work with Sergio\GHCC\post_extraction_processing\STI
{txt}
{com}. 
.                 use final_dta/wide_file.dta
{txt}
{com}. 
{txt}end of do-file

{com}. lookfor vehic

              {txt}storage   display    value
variable name   type    format     label      variable label
{hline}
{p 0 48}{res}{bind:si_cap_vehicles}{txt}{bind: double  }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) si_cap_vehicles{p_end}
{p 0 48}{bind:ar_cap_vehicles}{txt}{bind: double  }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_cap_vehicles{p_end}
{p 0 48}{bind:ar_vehicles    }{txt}{bind: double  }{bind:{txt}%9.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_vehicles{p_end}

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. **************************************************************************
. **************************************************************************
. **************************************************************************
. ** Do file for export of VMMC studies to the UCSR, using select variables
. ** Lily Alexander
. ** Univ of Washington 
. ** January 2018 
. ** lilyalexander18@gmail.com; lalexan1@uw.edu
. **************************************************************************
. **************************************************************************
. **************************************************************************
. 
. ** Data requirements
. **
. **  Must use data already formatted into wide file for GHCC analysis
. **              - These are available upon request
. **              - Procedure to be replicated for other intervention areas (ART, etc)
. **              - As well as other diseases (TB)
. **************************************************************************
. 
. set more off 
{txt}
{com}.         clear
{txt}
{com}.         cd "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/INSP/Work with Sergio/GHCC/post_extraction_processing/STI"
{res}C:\Users\Lily Alexander\Dropbox\ALL LIFE THINGS\INSP\Work with Sergio\GHCC\post_extraction_processing\STI
{txt}
{com}. 
.                 use final_dta/wide_file.dta
{txt}
{com}. 
. **************************************************************************              
. ** First, export of whole raw data before compression / aggregation
. **************************************************************************
. ** Begin by selecting key variables for export
. 
.                 * Identifiers
.                 label var id "ID Variable"
{txt}
{com}.                 label var unit_cost "Unit Cost ID"
{txt}
{com}.                 
.                 *Bibliographic variables
.                 ************************
.                 label var lead_author "Lead Author"
{txt}
{com}.                 label var ref_author "Reference Authors"
{txt}
{com}.                 label var ref_year "Reference Year"
{txt}
{com}.                 label var title "Title"
{txt}
{com}.                 label var journal_etc "Journal"
{txt}
{com}.                 label var url "URL"
{txt}
{com}. 
.                 * Case issues - settled in excel, but could do something here too.
.                         *Sentence case
.                                 * Clean up title to sentence case
.                                 * foreach i of varlist  {c -(}
.                                 *       replace `i'=substr(`i', 1, 1)+ lower(substr(`i', 2, .))
.                                 *       {c )-}
.                                         
.                                 *Proper case
.                                 *foreach i of varlist id_tech id_modality int_services {c -(}
.                                 *       replace `i'=strproper(`i')
.                                 *       {c )-}
.                                 
.                                 *Upper case
.                                 *foreach i of varlist disease id_phase {c -(}
.                                 *       replace `i'=upper(`i')
.                                 *       {c )-}
.                                         
.                                         
.         ** Note for Willyanne, there is a character limit in Stata, so title and journal may need to be fixed manually
.                         *Reorder starting here
.                         order id unit_cost lead_author ref_author ref_year title journal_etc url
{txt}
{com}.                 
.                 *Intervention variables
.                 ***********************
.                 label var ownership "Ownership"
{txt}
{com}.                 label var id_facility "Facility Category" // Variable for Platform below
{txt}
{com}.                 label var id_class "Intervention Class"
{txt}
{com}.                 label var id_type "Intervention Type"
{txt}
{com}.                 label var id_tech_diag "Technology for diagnosis"
{txt}
{com}.                 label var id_tech_treat "Technology for treatment" 
{txt}
{com}.                 label var id_tech_prevention "Technology for prevention"
{txt}
{com}.                 label var id_phase "Phase"
{txt}
{com}.                 //label var id_details "Intervention Details"
.                 label var id_modality "Delivery Modality"
{txt}
{com}.                 label var int_description_long "Intervention Description (Long)"
{txt}
{com}.                 label var start_month "Start Month"
{txt}
{com}.                 label var start_year "Start Year"
{txt}
{com}.                 label var end_month "End Month"
{txt}
{com}.                 label var end_year "End Year"
{txt}
{com}.                 label var period_portrayed "Total Months"
{txt}
{com}.                 *label var year_intro "Year Introduced at Study Site"
.                 label var coverage "Coverage"
{txt}
{com}.                 label var int_services "Integrated Services"
{txt}
{com}.                 label var disease "Disease"
{txt}
{com}.                                         
.                         *Capitalize ownership 
.                         
.                         label define ownership_new 2 "International NGO" 3 "Mixed" 4 "Public" 999 "." 
{txt}
{com}.                         label values ownership ownership_new 
{txt}
{com}.                         
.                         label define integrated 1 "Integrated" 2 "Partially integrated"
{txt}
{com}.                         label values int_services integrated
{txt}
{com}.                         
.                         * Generate a higher-level platform variable
.                         gen platform=.
{txt}(47 missing values generated)

{com}.                                 replace platform=1 if id_facility=="HC01" | id_facility=="HC02" | id_facility=="HC03" | id_facility=="HC04" | id_facility=="HC05" |  id_facility=="HC06" |  id_facility=="HC07" | id_facility=="HC08" | id_facility=="HC09" | id_facility=="HC10" | id_facility=="HC11"
{txt}(47 real changes made)

{com}.                                 replace platform=2 if id_facility=="OR01" | id_facility=="OR02" |  id_facility=="OR03" |  id_facility=="OR04" |  id_facility=="OR05"
{txt}(0 real changes made)

{com}.                                 replace platform=3 if id_facility=="CB01" | id_facility=="CB02" | id_facility=="CB03" | id_facility=="CB04"
{txt}(0 real changes made)

{com}.                                 replace platform=4 if id_facility=="PW01"
{txt}(0 real changes made)

{com}.                                 replace platform=5 if id_facility=="OT01" |id_facility=="OT02"
{txt}(0 real changes made)

{com}.                         label variable platform "Platform"
{txt}
{com}.                         label define platform 1 "Fixed facility" 2 "Outreach" 3 "Community based" 4 "Population wide" 5 "Other"
{txt}
{com}.                         label values platform platform
{txt}
{com}. 
.         
.                         
.                         * Fix disease and capitalization
.                         label define disease1 1 "STDs" 2 "Syphilis" 
{txt}
{com}.                         label values disease disease1
{txt}
{com}.                 
.         ** Note to willyanne: Intervention details needs to be standardized and broken into categories
.                         ** Right now you'll lose all this info in the stata transfer.
.         ** We will also not be able to retain "intervention description long" in stata
.         ** Which field do you want in "health system level" comment? Long one wont copy over.
.         ** Also unclear whether you want integrated services variable or health system level remarks variable, or both.
.                 
.                         *Re-order starting here
.                         order ownership id_facility platform id_class id_type id_modality disease id_tech_diag id_tech_treat id_tech_prevention id_phase int_description_long start_month start_year end_month end_year period_portrayed coverage int_services 
{txt}
{com}.                                         order id unit_cost lead_author ref_author ref_year title journal_etc url
{txt}
{com}. 
.                 * Geography
.                 label var country "Country"
{txt}
{com}.                 label var pop_density "Urbanicity"
{txt}
{com}.                 label var location "Location"   
{txt}
{com}.                         * I dont know what variable you're talking about here. How do we want to deal with this? Its a free text field.
.                         
. ********************
. * Temporary fix for region variable
. gen region= . 
{txt}(47 missing values generated)

{com}. 
. decode country, gen(country_new)
{txt}
{com}. 
. replace region = 1 if country_new == "Brazil"
{txt}(3 real changes made)

{com}. replace region = 2 if country_new == "Tanzania" 
{txt}(2 real changes made)

{com}. replace region = 3 if country_new == "Cambodia " 
{txt}(11 real changes made)

{com}. replace region = 3 if country_new == "India"
{txt}(3 real changes made)

{com}. replace region = 2 if country_new == "Central African Republic " 
{txt}(12 real changes made)

{com}. replace region = 2 if country_new == "Zambia"
{txt}(16 real changes made)

{com}. 
. drop country_new
{txt}
{com}. 
. label variable region "Region"
{txt}
{com}. label define region 1 "LAC" 2 "SSA" 3 "Asia"
{txt}
{com}. label values region region
{txt}
{com}. ********************
. 
.                 * Pop-density 
.                 label define density 1 "Rural" 2 "Mixture" 3 "Peri-Urban" 4 "Rural" 5 "Urban"
{txt}
{com}.                 label values pop_density density 
{txt}
{com}.                         
.                         
.                         
.                         
.                         *Re-order starting here
.                         order country region pop_density location ss_unique_trait
{txt}
{com}.                                         order ownership id_facility platform id_class id_type id_modality disease id_tech_diag id_tech_treat id_tech_prevention id_phase int_description_long start_month start_year end_month end_year period_portrayed coverage int_services 
{txt}
{com}.                                         order id unit_cost lead_author ref_author ref_year title journal_etc url
{txt}
{com}. 
.                 *Population
.                 label var id_pop_dem "Population"
{txt}
{com}.                 label var pop_age "Average Age"
{txt}
{com}.                 label var pop_sex "Gender"
{txt}
{com}.                 label var pop_ses "SES"
{txt}
{com}.                 label var pop_education "Education"
{txt}
{com}.                 label var pop_couples "Couples"
{txt}
{com}.                 label var hiv_prev "HIV Prevalence"
{txt}
{com}.                 label var cd4_med "Median CD4 Count"
{txt}
{com}.                 label var cd4_range "CD4 Range"
{txt}
{com}.                 label var tb_prev "TB Prevalence"
{txt}
{com}.                 label var tb_rx_resistance "TB Drug Resistance"
{txt}
{com}.                  
.         
.                 foreach i of varlist id_pop_dem pop_age pop_ses pop_education hiv_prev cd4_range tb_prev {c -(}
{txt}  2{com}.                         replace `i'="." if `i'=="NR"
{txt}  3{com}.                         {c )-}
{txt}(0 real changes made)
(41 real changes made)
(47 real changes made)
(44 real changes made)
(27 real changes made)
(47 real changes made)
(47 real changes made)

{com}.                 
.                         * Re-order starting here
.                         order id_pop_dem_std pop_age pop_sex pop_ses pop_education pop_couples hiv_prev cd4_med cd4_range tb_prev tb_rx_resistance
{txt}
{com}.                                         order country region pop_density location ss_unique_trait
{txt}
{com}.                                         order ownership id_facility platform id_class id_type id_modality disease id_tech_diag id_tech_treat id_tech_prevention id_phase int_description_long start_month start_year end_month end_year period_portrayed coverage int_services 
{txt}
{com}.                                         order id unit_cost lead_author ref_author ref_year title journal_etc url
{txt}
{com}.                 
.                 * Study Design
.                 label var costing_purpose_cat "Costing Purpose"
{txt}
{com}.                 label var timing "Timing"
{txt}
{com}.                 *label var seasonality "Seasonality"
.                 label var country_sampling "Country Sampling"
{txt}
{com}.                 label var geo_sampling_incountry "Geographic Area In Country Sampling"
{txt}
{com}.                 label var site_sampling "Site Sampling"
{txt}
{com}.                 label var px_sampling "Patient Sampling"
{txt}
{com}.                 label var sample_size_derived "Sample size formally derived"
{txt}
{com}.                 label var controls "Controls"
{txt}
{com}.                 label var ss_unique_trait "Unique Trait"
{txt}
{com}.         
.         foreach var in start_month end_month start_year end_year{c -(} 
{txt}  2{com}.                 _strip_labels `var' 
{txt}  3{com}.                 tostring `var', replace
{txt}  4{com}.                 replace `var' = "Open" if `var' == "88" 
{txt}  5{com}.                 replace `var' = "Mixed" if `var' == "99"
{txt}  6{com}.         {c )-}
{txt}start_month was {res:byte} now {res:str2}
(0 real changes made)
(0 real changes made)
end_month was {res:byte} now {res:str2}
(0 real changes made)
(0 real changes made)
start_year was {res:int} now {res:str4}
(0 real changes made)
(0 real changes made)
end_year was {res:int} now {res:str4}
(0 real changes made)
(0 real changes made)

{com}.         
.         *Need to replace all missing values in categoricals with 999 so we can label them "."
.         foreach i of varlist ownership platform id_class id_type id_tech* id_modality disease id_phase int_services country region pop_density pop_sex costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls econ_perspective_report econ_perspective_actual econ_costing real_world asd_costs research_costs unrelated_costs overhead volunteer_time family_time iso_code currency_x pop_couples cd4_med tb_rx sensitivity_analysis {c -(}
{txt}  2{com}.                         
.                         decode `i', gen(`i'_new) 
{txt}  3{com}.                         drop `i' 
{txt}  4{com}.                         rename `i'_new `i'
{txt}  5{com}.                         
.                         replace `i' = "." if `i' == "999" 
{txt}  6{com}.                         replace `i' = "." if `i' == "N/A" 
{txt}  7{com}.                         replace `i' = "." if `i' == "NR"
{txt}  8{com}.                         replace `i' = "." if `i' == " "
{txt}  9{com}.                         replace `i' = "." if `i' == ""
{txt} 10{com}.                         {c )-}
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(26 real changes made)
(0 real changes made)
(0 real changes made)
(2 real changes made)
{res}{txt}(0 real changes made)
(12 real changes made)
(0 real changes made)
(0 real changes made)
(4 real changes made)
{res}{txt}(0 real changes made)
(15 real changes made)
(0 real changes made)
(0 real changes made)
(20 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(47 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(3 real changes made)
(0 real changes made)
(0 real changes made)
(44 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(15 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(12 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(39 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(45 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(12 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(26 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(47 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(47 real changes made)
{res}{txt}(0 real changes made)
(47 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(12 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(3 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
{res}{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)

{com}.         
.         *Need to do same with string variables
.         tostring ref_author, replace
{txt}ref_author already string; no {res}replace
{txt}
{com}.         tostring url, replace
{txt}url already string; no {res}replace
{txt}
{com}.         tostring id_pop_dem_std, replace
{txt}id_pop_dem_std already string; no {res}replace
{txt}
{com}.         foreach i of varlist id unit_cost lead_author ref_author title journal_etc url ownership id_facility platform id_class id_modality int_description_long location ss_unique_trait id_pop_dem_std pop_age pop_ses pop_education hiv_prev cd4_range tb_prev list_asd_costs overhead_costs uncertainty_rmk tb_prev {c -(}
{txt}  2{com}.                 replace `i'="." if `i'==""
{txt}  3{com}.                 replace `i'="." if `i'=="N/A"
{txt}  4{com}.                 {c )-}
{txt}(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(12 real changes made)
(3 real changes made)
(3 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)

{com}.                 
.         
.                         * re-order starting here
.                         order costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls
{txt}
{com}.                                         order id_pop_dem_std pop_age pop_sex pop_ses pop_education pop_couples hiv_prev cd4_med cd4_range tb_prev tb_rx_resistance
{txt}
{com}.                                         order country region pop_density location ss_unique_trait
{txt}
{com}.                                         order ownership id_facility platform id_class id_type id_modality disease id_tech_diag id_tech_treat id_tech_prevention id_phase int_description_long start_month start_year end_month end_year period_portrayed coverage int_services 
{txt}
{com}.                                         order id unit_cost lead_author ref_author ref_year title journal_etc url        
{txt}
{com}.                 
.                 * Include population (to dummy out infants)
.                 gen neonates=.
{txt}(47 missing values generated)

{com}.                 replace neonates=1 if id_pop_dem=="neonates" | id_pop_dem=="newborns" | id_pop_dem=="infant males at risk of HIV"
{txt}(0 real changes made)

{com}.                 replace neonates=0 if neonates==.
{txt}(47 real changes made)

{com}.                         * tab neonates
.                         * sum mean_cost if neonates==1,d
.                         * sum mean_cost if neonates==0,d
.                         label variable neonates "Target group (demographic)"
{txt}
{com}.                         label define neonates 0 "Adults and/or Adolescents" 1 "Neonates and/or Infants"
{txt}
{com}.                         label values neonates neonates
{txt}
{com}.                 
.                         label variable id_pop_dem_std "Population served"
{txt}
{com}.                         
.         
.                 
.                 * Costing methods
.                 label var econ_perspective_actual "Perspective"
{txt}
{com}.                 label var econ_costing "Economic / Financial"
{txt}
{com}.                 label var real_world "Real World / Per Protocol"
{txt}
{com}.                 *label var omitted_costs "Costing Frame"
.                 label var asd_costs "Above Service Costs Included"
{txt}
{com}.                 label var list_asd_costs "Above Service Cost List"
{txt}
{com}.                 label var research_costs "Research Costs Included"
{txt}
{com}.                 label var unrelated_costs "Unrelated Costs Included"
{txt}
{com}.                 label var overhead "Overhead Costs Included"
{txt}
{com}.                 label var overhead_costs "Overhead Costs List"
{txt}
{com}.                 label var omitted_costs "Author-reported Omitted Costs"
{txt}
{com}.                 label var volunteer_time "Valuing Volunteer Time"
{txt}
{com}.                 label var family_time "Valuing Family Time"
{txt}
{com}.                 label var currency_yr "Reported Currency Year"
{txt}
{com}.                 label var iso_code "Reported Currency"
{txt}
{com}.                 label var currency_x "Currency Exchange Method"
{txt}
{com}.                 label var current_x_rate "Currency Exchange Rate"
{txt}
{com}.                 label var discount_rate "Discount Rate"
{txt}
{com}.                 label var sensitivity_analysis "Sensitivity Analysis"
{txt}
{com}.                 label var uncertainty_rmk "Uncertainty Remarks"
{txt}
{com}.                         
.                 * not sure if the "costing Frame" variable you mention is omitted_costs
.                 * when you say you want "sensitivity remarks" do you mean uncertainty remarks?
.                                 * If so, a free text field of this size wont translate with Stata
.                 
.                 * Omitted costs variable in the extraction spreadsheet includes both explicitly and inferred omitted so for UCSR include just "author-reported" omissions 
.                 replace omitted_costs = "" if omitted_costs_rs != 1 // "1" is when the authors state the omissions explicitly
{txt}(28 real changes made)

{com}.         
.                 *Generate variables that are missing so that all columns are accounted for 
.                 gen si_per_service_delivery = . 
{txt}(47 missing values generated)

{com}.                 gen a_ancillary = . 
{txt}(47 missing values generated)

{com}.                 gen a_secondary_sd = . 
{txt}(47 missing values generated)

{com}.                 gen a_anc_demand_generation = . 
{txt}(47 missing values generated)

{com}.                 gen a_anc_lab_services = . 
{txt}(47 missing values generated)

{com}.                 gen a_anc_unspecified = . 
{txt}(47 missing values generated)

{com}.                 gen a_ope_logistics = . 
{txt}(47 missing values generated)

{com}.                 gen a_ope_program_mgmt = . 
{txt}(47 missing values generated)

{com}.                 gen a_prisd_circumcision_proced = . 
{txt}(47 missing values generated)

{com}.                 gen a_secsd_hct = . 
{txt}(47 missing values generated)

{com}.                 
.                 gen id_tech = "."
{txt}
{com}. 
.                 * Order variables thusly:
.                 order mean_cost si_capital si_mixed si_personnel si_recurrent si_cap_medical_equip si_cap_nonmed_equip si_cap_other si_mix_mixed si_per_mixed_unspec si_per_service_delivery si_per_support si_rec_building_space si_rec_med_int_supplies si_rec_nonmed_int_supplies a_ancillary a_mixed a_operational a_primary_sd a_secondary_sd a_anc_demand_generation a_anc_lab_services a_anc_unspecified a_mix_mixed a_ope_bldg_equip a_ope_logistics a_ope_program_mgmt a_ope_supervision a_ope_training a_ope_transportation a_ope_unspecified a_prisd_circumcision_proced a_prisd_unspecified a_secsd_hct
{txt}
{com}.                 order econ_perspective_actual econ_costing real_world asd_costs list_asd_costs research_costs unrelated_costs overhead overhead_costs omitted_costs volunteer_time family_time currency_yr iso_code currency_x current_x_rate discount_rate sensitivity_analysis uncertainty_rmk
{txt}
{com}.                                         order costing_purpose_cat timing country_sampling geo_sampling_incountry site_sampling px_sampling sample_size_derived controls
{txt}
{com}.                                         order id_pop_dem_std pop_age pop_sex pop_ses pop_education pop_couples hiv_prev cd4_med cd4_range tb_prev tb_rx_resistance
{txt}
{com}.                                         order country region pop_density neonates location ss_unique_trait
{txt}
{com}.                                         order ownership id_facility platform id_class id_type id_modality disease id_tech id_tech_diag id_tech_treat id_tech_prevention id_phase int_description_long start_month start_year end_month end_year period_portrayed coverage int_services 
{txt}
{com}.                                         order id unit_cost lead_author ref_author ref_year title journal_etc url
{txt}
{com}. 
{txt}end of do-file

{com}. tab iso_name

                      {txt}iso_name {c |}      Freq.     Percent        Cum.
{hline 31}{c +}{hline 35}
                        Brazil {c |}{res}          3        6.38        6.38
{txt}                     Cambodia  {c |}{res}         11       23.40       29.79
{txt}     Central African Republic  {c |}{res}         12       25.53       55.32
{txt}                         India {c |}{res}          3        6.38       61.70
{txt} Tanzania, United Republic of  {c |}{res}          2        4.26       65.96
{txt}                        Zambia {c |}{res}         16       34.04      100.00
{txt}{hline 31}{c +}{hline 35}
                         Total {c |}{res}         47      100.00

{com}. lookfor fac

              {txt}storage   display    value
variable name   type    format     label      variable label
{hline}
{p 0 48}{res}{bind:id_facility    }{txt}{bind: str4    }{bind:{txt}%9s       }{space 1}{bind:         }{bind:  }{res}{res}Facility Category{p_end}
{p 0 48}{bind:ar_fac_rental  }{txt}{bind: double  }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_fac_rental{p_end}
{p 0 48}{bind:ar_fac_mainte~e}{txt}{bind: double  }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_fac_maintenance{p_end}
{p 0 48}{bind:ar_fac_maint_~l}{txt}{bind: double  }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_fac_maint_and_util{p_end}
{p 0 48}{bind:ar_facility    }{txt}{bind: double  }{bind:{txt}%9.0g     }{space 1}{bind:         }{bind:  }{res}{res}(sum) ar_facility{p_end}
{p 0 48}{bind:facility_notes }{txt}{bind: str576  }{bind:{txt}%576s     }{space 1}{bind:         }{bind:  }{res}{res}facility_notes{p_end}
{p 0 48}{bind:meta_facility  }{txt}{bind: float   }{bind:{txt}%42.0g    }{space 1}{txt}meta_facility{p_end}
{p 0 48}{space 44}{bind:  }{res}{res}Broad Facility Category{p_end}
{p 0 48}{bind:facility_cat   }{txt}{bind: float   }{bind:{txt}%68.0g    }{space 1}{txt}facility_cat{p_end}
{p 0 48}{space 44}{bind:  }{res}{res}Narrow Facility Category{p_end}
{p 0 48}{bind:fac_type       }{txt}{bind: float   }{bind:{txt}%20.0g    }{space 1}{bind:fac_type }{bind:  }{res}{res}Facility Type for Analysis{p_end}
{p 0 48}{bind:ft_clinics     }{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}fac_type==Clinics{p_end}
{p 0 48}{bind:ft_intclinics  }{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}fac_type==Integrated clinics{p_end}
{p 0 48}{bind:ft_unspecifie~c}{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}fac_type==HC unspecified/other{p_end}
{p 0 48}{bind:health_center  }{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}facility_cat==Health Center (e.g. community health clinic - sometimes w/ 1-2 bed{p_end}
{p 0 48}{bind:hospital_clinic}{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}facility_cat==Clinic at hospital (intervention- or disease-specific){p_end}
{p 0 48}{bind:mixed_healthfac}{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}facility_cat==Mix of health care facility types{p_end}
{p 0 48}{bind:unspecified_h~c}{txt}{bind: byte    }{bind:{txt}%8.0g     }{space 1}{bind:         }{bind:  }{res}{res}facility_cat==Unspecified health care facility type{p_end}

{com}. tab fac_type

   {txt}Facility Type for {c |}
            Analysis {c |}      Freq.     Percent        Cum.
{hline 21}{c +}{hline 35}
             Clinics {c |}{res}         30       63.83       63.83
{txt}  Integrated clinics {c |}{res}          3        6.38       70.21
{txt}HC unspecified/other {c |}{res}         14       29.79      100.00
{txt}{hline 21}{c +}{hline 35}
               Total {c |}{res}         47      100.00

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 0 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
. 
. {c )-}
{txt}
{com}. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
{txt}
{com}. 
. use "`data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
{txt}end of do-file

{com}. br

. order prueba

. br

. sort folio prueba

. br

. br

. duplicates tag folio clues, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} folio clues{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}    163,757        8.43        8.43
{txt}          1 {c |}{res}    127,744        6.58       15.00
{txt}          2 {c |}{res}    111,609        5.74       20.75
{txt}          3 {c |}{res}    119,936        6.17       26.92
{txt}          4 {c |}{res}     94,235        4.85       31.77
{txt}          5 {c |}{res}    110,772        5.70       37.47
{txt}          6 {c |}{res}    110,677        5.70       43.17
{txt}          7 {c |}{res}     94,704        4.87       48.05
{txt}          8 {c |}{res}     78,075        4.02       52.07
{txt}          9 {c |}{res}     72,800        3.75       55.81
{txt}         10 {c |}{res}     75,262        3.87       59.69
{txt}         11 {c |}{res}     74,724        3.85       63.53
{txt}         12 {c |}{res}     82,784        4.26       67.79
{txt}         13 {c |}{res}     80,332        4.13       71.93
{txt}         14 {c |}{res}     78,900        4.06       75.99
{txt}         15 {c |}{res}     66,304        3.41       79.40
{txt}         16 {c |}{res}     61,982        3.19       82.59
{txt}         17 {c |}{res}     49,464        2.55       85.14
{txt}         18 {c |}{res}     40,451        2.08       87.22
{txt}         19 {c |}{res}     30,780        1.58       88.81
{txt}         20 {c |}{res}     25,305        1.30       90.11
{txt}         21 {c |}{res}     17,160        0.88       90.99
{txt}         22 {c |}{res}     12,788        0.66       91.65
{txt}         23 {c |}{res}      9,336        0.48       92.13
{txt}         24 {c |}{res}      7,225        0.37       92.50
{txt}         25 {c |}{res}      6,656        0.34       92.84
{txt}         26 {c |}{res}      5,832        0.30       93.14
{txt}         27 {c |}{res}      5,544        0.29       93.43
{txt}         28 {c |}{res}      5,278        0.27       93.70
{txt}         29 {c |}{res}      4,080        0.21       93.91
{txt}         30 {c |}{res}      4,061        0.21       94.12
{txt}         31 {c |}{res}      4,352        0.22       94.34
{txt}         32 {c |}{res}      3,135        0.16       94.51
{txt}         33 {c |}{res}      3,196        0.16       94.67
{txt}         34 {c |}{res}      2,450        0.13       94.80
{txt}         35 {c |}{res}      1,872        0.10       94.89
{txt}         36 {c |}{res}      1,813        0.09       94.99
{txt}         37 {c |}{res}      1,368        0.07       95.06
{txt}         38 {c |}{res}        780        0.04       95.10
{txt}         39 {c |}{res}        680        0.04       95.13
{txt}         40 {c |}{res}        943        0.05       95.18
{txt}         41 {c |}{res}        420        0.02       95.20
{txt}         42 {c |}{res}        473        0.02       95.23
{txt}         43 {c |}{res}        308        0.02       95.24
{txt}         44 {c |}{res}        315        0.02       95.26
{txt}         45 {c |}{res}        368        0.02       95.28
{txt}         46 {c |}{res}        423        0.02       95.30
{txt}         47 {c |}{res}        240        0.01       95.31
{txt}         48 {c |}{res}        539        0.03       95.34
{txt}         49 {c |}{res}        850        0.04       95.38
{txt}         50 {c |}{res}        408        0.02       95.40
{txt}         51 {c |}{res}        676        0.03       95.44
{txt}         52 {c |}{res}        636        0.03       95.47
{txt}         53 {c |}{res}        864        0.04       95.52
{txt}         54 {c |}{res}      1,320        0.07       95.58
{txt}         55 {c |}{res}        728        0.04       95.62
{txt}         56 {c |}{res}        969        0.05       95.67
{txt}         57 {c |}{res}      1,682        0.09       95.76
{txt}         58 {c |}{res}      2,006        0.10       95.86
{txt}         59 {c |}{res}      1,680        0.09       95.95
{txt}         60 {c |}{res}      1,830        0.09       96.04
{txt}         61 {c |}{res}      2,356        0.12       96.16
{txt}         62 {c |}{res}      2,772        0.14       96.31
{txt}         63 {c |}{res}      3,136        0.16       96.47
{txt}         64 {c |}{res}      3,445        0.18       96.64
{txt}         65 {c |}{res}      3,498        0.18       96.82
{txt}         66 {c |}{res}      3,149        0.16       96.99
{txt}         67 {c |}{res}      3,128        0.16       97.15
{txt}         68 {c |}{res}      3,312        0.17       97.32
{txt}         69 {c |}{res}      3,010        0.15       97.47
{txt}         70 {c |}{res}      3,195        0.16       97.64
{txt}         71 {c |}{res}      2,736        0.14       97.78
{txt}         72 {c |}{res}      3,504        0.18       97.96
{txt}         73 {c |}{res}      2,812        0.14       98.10
{txt}         74 {c |}{res}      3,150        0.16       98.27
{txt}         75 {c |}{res}      2,812        0.14       98.41
{txt}         76 {c |}{res}      1,925        0.10       98.51
{txt}         77 {c |}{res}      2,340        0.12       98.63
{txt}         78 {c |}{res}      3,239        0.17       98.80
{txt}         79 {c |}{res}      1,840        0.09       98.89
{txt}         80 {c |}{res}      2,025        0.10       99.00
{txt}         81 {c |}{res}      2,296        0.12       99.11
{txt}         82 {c |}{res}      1,328        0.07       99.18
{txt}         83 {c |}{res}      1,092        0.06       99.24
{txt}         84 {c |}{res}      1,530        0.08       99.32
{txt}         85 {c |}{res}      1,204        0.06       99.38
{txt}         86 {c |}{res}      1,392        0.07       99.45
{txt}         87 {c |}{res}        792        0.04       99.49
{txt}         88 {c |}{res}        979        0.05       99.54
{txt}         89 {c |}{res}      1,530        0.08       99.62
{txt}         90 {c |}{res}      1,001        0.05       99.67
{txt}         91 {c |}{res}        276        0.01       99.69
{txt}         92 {c |}{res}        465        0.02       99.71
{txt}         93 {c |}{res}        564        0.03       99.74
{txt}         94 {c |}{res}        665        0.03       99.77
{txt}         95 {c |}{res}        480        0.02       99.80
{txt}         96 {c |}{res}        582        0.03       99.83
{txt}         97 {c |}{res}        196        0.01       99.84
{txt}         98 {c |}{res}        198        0.01       99.85
{txt}         99 {c |}{res}        400        0.02       99.87
{txt}        100 {c |}{res}        404        0.02       99.89
{txt}        101 {c |}{res}        102        0.01       99.90
{txt}        102 {c |}{res}        103        0.01       99.90
{txt}        103 {c |}{res}        208        0.01       99.91
{txt}        104 {c |}{res}        105        0.01       99.92
{txt}        105 {c |}{res}        106        0.01       99.92
{txt}        107 {c |}{res}        108        0.01       99.93
{txt}        117 {c |}{res}        118        0.01       99.93
{txt}       1285 {c |}{res}      1,286        0.07      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,942,775      100.00

{com}. drop dup

. duplicates tag folio clues prueba, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} folio clues prueba{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}    439,323       22.61       22.61
{txt}          1 {c |}{res}    197,162       10.15       32.76
{txt}          2 {c |}{res}    173,241        8.92       41.68
{txt}          3 {c |}{res}    165,008        8.49       50.17
{txt}          4 {c |}{res}    164,360        8.46       58.63
{txt}          5 {c |}{res}    141,888        7.30       65.94
{txt}          6 {c |}{res}    126,581        6.52       72.45
{txt}          7 {c |}{res}    104,792        5.39       77.85
{txt}          8 {c |}{res}     92,574        4.77       82.61
{txt}          9 {c |}{res}     80,470        4.14       86.75
{txt}         10 {c |}{res}     63,690        3.28       90.03
{txt}         11 {c |}{res}     52,548        2.70       92.74
{txt}         12 {c |}{res}     32,773        1.69       94.42
{txt}         13 {c |}{res}     17,612        0.91       95.33
{txt}         14 {c |}{res}      8,070        0.42       95.74
{txt}         15 {c |}{res}      4,944        0.25       96.00
{txt}         16 {c |}{res}      3,672        0.19       96.19
{txt}         17 {c |}{res}      2,808        0.14       96.33
{txt}         18 {c |}{res}      2,698        0.14       96.47
{txt}         19 {c |}{res}      2,900        0.15       96.62
{txt}         20 {c |}{res}      2,289        0.12       96.74
{txt}         21 {c |}{res}      2,530        0.13       96.87
{txt}         22 {c |}{res}      2,967        0.15       97.02
{txt}         23 {c |}{res}      2,328        0.12       97.14
{txt}         24 {c |}{res}      4,100        0.21       97.35
{txt}         25 {c |}{res}      3,874        0.20       97.55
{txt}         26 {c |}{res}      3,753        0.19       97.74
{txt}         27 {c |}{res}      4,004        0.21       97.95
{txt}         28 {c |}{res}      3,857        0.20       98.15
{txt}         29 {c |}{res}      3,780        0.19       98.34
{txt}         30 {c |}{res}      3,999        0.21       98.55
{txt}         31 {c |}{res}      3,840        0.20       98.75
{txt}         32 {c |}{res}      3,168        0.16       98.91
{txt}         33 {c |}{res}      2,040        0.11       99.02
{txt}         34 {c |}{res}      1,470        0.08       99.09
{txt}         35 {c |}{res}      1,332        0.07       99.16
{txt}         36 {c |}{res}      1,110        0.06       99.22
{txt}         37 {c |}{res}        608        0.03       99.25
{txt}         38 {c |}{res}        585        0.03       99.28
{txt}         39 {c |}{res}        360        0.02       99.30
{txt}         40 {c |}{res}        574        0.03       99.33
{txt}         41 {c |}{res}        210        0.01       99.34
{txt}         42 {c |}{res}        645        0.03       99.37
{txt}         43 {c |}{res}        264        0.01       99.38
{txt}         44 {c |}{res}        675        0.03       99.42
{txt}         45 {c |}{res}        644        0.03       99.45
{txt}         46 {c |}{res}        940        0.05       99.50
{txt}         47 {c |}{res}      1,152        0.06       99.56
{txt}         48 {c |}{res}      1,078        0.06       99.61
{txt}         49 {c |}{res}      1,500        0.08       99.69
{txt}         50 {c |}{res}      1,479        0.08       99.77
{txt}         51 {c |}{res}      1,092        0.06       99.82
{txt}         52 {c |}{res}        689        0.04       99.86
{txt}         53 {c |}{res}        486        0.03       99.88
{txt}         54 {c |}{res}        440        0.02       99.91
{txt}         55 {c |}{res}        168        0.01       99.92
{txt}         56 {c |}{res}        171        0.01       99.92
{txt}         57 {c |}{res}        174        0.01       99.93
{txt}       1285 {c |}{res}      1,286        0.07      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,942,775      100.00

{com}. drop dup

. br

. drop dup
{err}variable {bf}dup{sf} not found
{txt}{search r(111), local:r(111);}

{com}. duplicates tag edad folio clues prueba, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} edad folio clues prueba{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,568,668       80.74       80.74
{txt}          1 {c |}{res}    284,382       14.64       95.38
{txt}          2 {c |}{res}     62,685        3.23       98.61
{txt}          3 {c |}{res}     16,300        0.84       99.45
{txt}          4 {c |}{res}      5,645        0.29       99.74
{txt}          5 {c |}{res}      2,316        0.12       99.86
{txt}          6 {c |}{res}        882        0.05       99.90
{txt}          7 {c |}{res}        480        0.02       99.93
{txt}          8 {c |}{res}         90        0.00       99.93
{txt}          9 {c |}{res}         30        0.00       99.93
{txt}         10 {c |}{res}         11        0.00       99.93
{txt}       1285 {c |}{res}      1,286        0.07      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,942,775      100.00

{com}. sort edad folio clues prueba dup

. br

. br edad folio clues prueba dup

. br

. tab cedo

 {txt}Entidad de {c |}
   atencin {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          9 {c |}{res}    934,718       66.34       66.34
{txt}         33 {c |}{res}    440,519       31.27       97.61
{txt}         34 {c |}{res}     33,659        2.39      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,408,896      100.00

{com}. tab cenjur
{err}variable {bf}cenjur{sf} not found
{txt}{search r(111), local:r(111);}

{com}. tab cjurcve

{txt}Jurisdicci {c |}
       n de {c |}
   atencin {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          1 {c |}{res}    216,951       15.40       15.40
{txt}          2 {c |}{res}     34,327        2.44       17.84
{txt}          3 {c |}{res}          2        0.00       17.84
{txt}          5 {c |}{res}      8,876        0.63       18.47
{txt}          6 {c |}{res}     35,651        2.53       21.00
{txt}          7 {c |}{res}     35,691        2.53       23.53
{txt}          8 {c |}{res}    134,550        9.55       33.08
{txt}          9 {c |}{res}    129,073        9.16       42.24
{txt}         10 {c |}{res}     26,450        1.88       44.12
{txt}         11 {c |}{res}     80,899        5.74       49.86
{txt}         12 {c |}{res}     67,757        4.81       54.67
{txt}         13 {c |}{res}    261,635       18.57       73.24
{txt}         14 {c |}{res}     26,021        1.85       75.09
{txt}         15 {c |}{res}    180,262       12.79       87.88
{txt}         16 {c |}{res}    170,751       12.12      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,408,896      100.00

{com}. tab cmpocve

  {txt}Municipio {c |}
de atencin {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          2 {c |}{res}     34,327        2.44        2.44
{txt}          4 {c |}{res}     35,691        2.53        4.97
{txt}          5 {c |}{res}    216,951       15.40       20.37
{txt}          6 {c |}{res}          2        0.00       20.37
{txt}          7 {c |}{res}    129,073        9.16       29.53
{txt}          8 {c |}{res}     35,651        2.53       32.06
{txt}          9 {c |}{res}     80,899        5.74       37.80
{txt}         10 {c |}{res}      8,876        0.63       38.43
{txt}         11 {c |}{res}     67,757        4.81       43.24
{txt}         12 {c |}{res}    134,550        9.55       52.79
{txt}         13 {c |}{res}     26,450        1.88       54.67
{txt}         14 {c |}{res}     26,021        1.85       56.52
{txt}         15 {c |}{res}    180,262       12.79       69.31
{txt}         16 {c |}{res}    261,635       18.57       87.88
{txt}         17 {c |}{res}    170,751       12.12      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,408,896      100.00

{com}. tab cloccve

  {txt}Localidad {c |}
de atencin {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          1 {c |}{res}  1,408,896      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,408,896      100.00

{com}. tab cvercve

     {txt}Dgito {c |}
verificador {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}    672,368       47.72       47.72
{txt}          1 {c |}{res}    229,509       16.29       64.01
{txt}          2 {c |}{res}    286,696       20.35       84.36
{txt}          3 {c |}{res}     27,297        1.94       86.30
{txt}          6 {c |}{res}     94,389        6.70       93.00
{txt}          8 {c |}{res}     82,030        5.82       98.82
{txt}         12 {c |}{res}     12,090        0.86       99.68
{txt}         42 {c |}{res}      4,517        0.32      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,408,896      100.00

{com}. br

. sort edad folio clues prueba dup

. drop dup

. duplicates tag id folio clues prueba, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} id folio clues prueba{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,051,587       54.13       54.13
{txt}          1 {c |}{res}    197,724       10.18       64.31
{txt}          2 {c |}{res}    165,183        8.50       72.81
{txt}          3 {c |}{res}    127,708        6.57       79.38
{txt}          4 {c |}{res}    120,690        6.21       85.59
{txt}          5 {c |}{res}     81,108        4.17       89.77
{txt}          6 {c |}{res}     47,733        2.46       92.23
{txt}          7 {c |}{res}     24,608        1.27       93.49
{txt}          8 {c |}{res}     16,281        0.84       94.33
{txt}          9 {c |}{res}     13,630        0.70       95.03
{txt}         10 {c |}{res}     12,562        0.65       95.68
{txt}         11 {c |}{res}      9,564        0.49       96.17
{txt}         12 {c |}{res}      7,956        0.41       96.58
{txt}         13 {c |}{res}      4,634        0.24       96.82
{txt}         14 {c |}{res}      3,495        0.18       97.00
{txt}         15 {c |}{res}      3,216        0.17       97.16
{txt}         16 {c |}{res}      2,210        0.11       97.28
{txt}         17 {c |}{res}      2,466        0.13       97.40
{txt}         18 {c |}{res}      3,097        0.16       97.56
{txt}         19 {c |}{res}      4,140        0.21       97.78
{txt}         20 {c |}{res}      3,402        0.18       97.95
{txt}         21 {c |}{res}      3,762        0.19       98.15
{txt}         22 {c |}{res}      4,094        0.21       98.36
{txt}         23 {c |}{res}      3,096        0.16       98.52
{txt}         24 {c |}{res}      4,175        0.21       98.73
{txt}         25 {c |}{res}      3,640        0.19       98.92
{txt}         26 {c |}{res}      3,186        0.16       99.08
{txt}         27 {c |}{res}      3,024        0.16       99.24
{txt}         28 {c |}{res}      2,726        0.14       99.38
{txt}         29 {c |}{res}      2,340        0.12       99.50
{txt}         30 {c |}{res}      2,232        0.11       99.61
{txt}         31 {c |}{res}      1,920        0.10       99.71
{txt}         32 {c |}{res}      1,584        0.08       99.79
{txt}         33 {c |}{res}        884        0.05       99.84
{txt}         34 {c |}{res}        560        0.03       99.87
{txt}         35 {c |}{res}        360        0.02       99.89
{txt}         36 {c |}{res}        518        0.03       99.91
{txt}         37 {c |}{res}        152        0.01       99.92
{txt}         38 {c |}{res}        156        0.01       99.93
{txt}         42 {c |}{res}         86        0.00       99.93
{txt}       1285 {c |}{res}      1,286        0.07      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,942,775      100.00

{com}. tab year

       {txt}year {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
       2000 {c |}{res}    134,989        6.95        6.95
{txt}       2001 {c |}{res}    133,445        6.87       13.83
{txt}       2002 {c |}{res}    160,173        8.25       22.08
{txt}       2003 {c |}{res}    179,659        9.25       31.33
{txt}       2004 {c |}{res}    193,935        9.99       41.32
{txt}       2005 {c |}{res}    213,820       11.01       52.33
{txt}       2006 {c |}{res}    201,614       10.38       62.72
{txt}       2007 {c |}{res}     95,948        4.94       67.66
{txt}       2008 {c |}{res}     95,313        4.91       72.57
{txt}       2009 {c |}{res}     92,102        4.74       77.31
{txt}       2010 {c |}{res}     89,470        4.61       81.92
{txt}       2011 {c |}{res}     89,737        4.62       86.54
{txt}       2012 {c |}{res}     90,730        4.67       91.22
{txt}       2013 {c |}{res}     86,046        4.43       95.65
{txt}       2014 {c |}{res}     84,508        4.35      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00

{com}. duplicates tag id folio clues prueba if year >= 2007, gen(dup)
{err}generate() must specify new variable
{txt}{search r(110), local:r(110);}

{com}. drop dup

. duplicates tag id folio clues prueba if year >= 2007, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} id folio clues prueba{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}    723,850       99.82       99.82
{txt}          1 {c |}{res}          4        0.00       99.82
{txt}       1285 {c |}{res}      1,286        0.18      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}    725,140      100.00

{com}. br if dup == 1285

. drop dup

. duplicates tag id if year >= 2007, gen(dup)

{p 0 4}{txt}Duplicates in terms of {res} id{p_end}

{com}. tab dup

        {txt}dup {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}    412,662       56.91       56.91
{txt}          1 {c |}{res}    167,834       23.15       80.05
{txt}          2 {c |}{res}     89,517       12.34       92.40
{txt}          3 {c |}{res}     44,188        6.09       98.49
{txt}          4 {c |}{res}      9,310        1.28       99.78
{txt}          5 {c |}{res}        336        0.05       99.82
{txt}          6 {c |}{res}          7        0.00       99.82
{txt}       1285 {c |}{res}      1,286        0.18      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}    725,140      100.00

{com}. drop dup

. br id folio clues prueba

. br id folio clues prueba ingreso egreso

. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 0 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
. 
. {c )-}
{txt}
{com}. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
{txt}
{com}. 
. use "`data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. * Eliminating registers to keep only women (check with Evelyn what this means) 
. gen prueb=prueba
{txt}(1,286 missing values generated)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101       64.70       64.70
{txt}          1 {c |}{res}    520,197       26.79       91.49
{txt}          2 {c |}{res}    138,489        7.13       98.62
{txt}          3 {c |}{res}     26,702        1.38      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00
{txt}
{com}. drop if prueb!=0
{txt}(686,674 observations deleted)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{txt}
{com}. drop _m
{txt}
{com}. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace  
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved

{com}. 
. * Replace AFEC01-AFEC06 with values from datasets sent by Dr. Lozano 
. 
. clear 
{txt}
{com}. use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. merge m:1 id year using "`data'/AFECCIONES2010.dta", update 
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,661,484
{txt}{col 9}from master{col 30}{res}       1,178,256{txt}  (_merge==1)
{col 9}from using{col 30}{res}       1,483,228{txt}  (_merge==2)

{col 5}matched{col 30}{res}          77,845
{txt}{col 9}not updated{col 30}{res}               0{txt}  (_merge==3)
{col 9}missing updated{col 30}{res}          77,845{txt}  (_merge==4)
{col 9}nonmissing conflict{col 30}{res}               0{txt}  (_merge==5)
{col 5}{hline 41}

{com}. 
{txt}end of do-file

{com}. tab year if _m == 3
{txt}no observations

{com}. lookfor year

              {txt}storage   display    value
variable name   type    format     label      variable label
{hline}
{p 0 48}{res}{bind:year           }{txt}{bind: float   }{bind:{txt}%9.0g     }{space 1}{bind:         }{bind:  }{res}{res}{p_end}

{com}. tab year

       {txt}year {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
       2000 {c |}{res}     55,453        2.02        2.02
{txt}       2001 {c |}{res}     57,178        2.09        4.11
{txt}       2002 {c |}{res}     70,198        2.56        6.67
{txt}       2003 {c |}{res}     79,131        2.89        9.56
{txt}       2004 {c |}{res}     89,825        3.28       12.84
{txt}       2005 {c |}{res}     94,730        3.46       16.30
{txt}       2006 {c |}{res}     85,732        3.13       19.43
{txt}       2007 {c |}{res}     95,948        3.50       22.93
{txt}       2008 {c |}{res}     95,313        3.48       26.41
{txt}       2009 {c |}{res}     92,102        3.36       29.77
{txt}       2010 {c |}{res}  1,572,698       57.41       87.19
{txt}       2011 {c |}{res}     89,737        3.28       90.46
{txt}       2012 {c |}{res}     90,730        3.31       93.77
{txt}       2013 {c |}{res}     86,046        3.14       96.92
{txt}       2014 {c |}{res}     84,508        3.08      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  2,739,329      100.00

{com}. tab year if _m == 3
{txt}no observations

{com}. tab year if _m == 2

       {txt}year {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
       2010 {c |}{res}  1,483,228      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,483,228      100.00

{com}. tab year if _m == 1

       {txt}year {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
       2000 {c |}{res}     55,453        4.71        4.71
{txt}       2001 {c |}{res}     57,178        4.85        9.56
{txt}       2002 {c |}{res}     70,198        5.96       15.52
{txt}       2003 {c |}{res}     79,131        6.72       22.23
{txt}       2004 {c |}{res}     89,825        7.62       29.86
{txt}       2005 {c |}{res}     94,730        8.04       37.90
{txt}       2006 {c |}{res}     85,732        7.28       45.17
{txt}       2007 {c |}{res}     95,948        8.14       53.32
{txt}       2008 {c |}{res}     95,313        8.09       61.40
{txt}       2009 {c |}{res}     92,102        7.82       69.22
{txt}       2010 {c |}{res}     11,625        0.99       70.21
{txt}       2011 {c |}{res}     89,737        7.62       77.82
{txt}       2012 {c |}{res}     90,730        7.70       85.52
{txt}       2013 {c |}{res}     86,046        7.30       92.83
{txt}       2014 {c |}{res}     84,508        7.17      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,178,256      100.00

{com}. br if _m == 3

. tab _m

                 {txt}_merge {c |}      Freq.     Percent        Cum.
{hline 24}{c +}{hline 35}
        master only (1) {c |}{res}  1,178,256       43.01       43.01
{txt}         using only (2) {c |}{res}  1,483,228       54.15       97.16
{txt}    missing updated (4) {c |}{res}     77,845        2.84      100.00
{txt}{hline 24}{c +}{hline 35}
                  Total {c |}{res}  2,739,329      100.00

{com}. br if _m == 4

. tab year if _m ==4

       {txt}year {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
       2010 {c |}{res}     77,845      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}     77,845      100.00

{com}. count
  {res}2,739,329

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 0 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
. 
. {c )-}
{txt}
{com}. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
{txt}
{com}. 
. use "`data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. * Eliminating registers to keep only women (check with Evelyn what this means) 
. gen prueb=prueba
{txt}(1,286 missing values generated)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101       64.70       64.70
{txt}          1 {c |}{res}    520,197       26.79       91.49
{txt}          2 {c |}{res}    138,489        7.13       98.62
{txt}          3 {c |}{res}     26,702        1.38      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00
{txt}
{com}. drop if prueb!=0
{txt}(686,674 observations deleted)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{txt}
{com}. drop _m
{txt}
{com}. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace  
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved

{com}. 
. * Replace AFEC01-AFEC06 with values from datasets sent by Dr. Lozano 
. 
. clear 
{txt}
{com}. use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
{txt}end of do-file

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. 
. merge m:1 id year using "`data'/AFECCIONES2010.dta", update 
{res}{err}{p 0 4 2}
file /AFECCIONES2010.dta
not found
{p_end}
{txt}{search r(601), local:r(601);}

end of do-file

{search r(601), local:r(601);}

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 0 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
. 
. {c )-}
{txt}
{com}. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
{txt}
{com}. 
. use "`data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. * Eliminating registers to keep only women (check with Evelyn what this means) 
. gen prueb=prueba
{txt}(1,286 missing values generated)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101       64.70       64.70
{txt}          1 {c |}{res}    520,197       26.79       91.49
{txt}          2 {c |}{res}    138,489        7.13       98.62
{txt}          3 {c |}{res}     26,702        1.38      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00
{txt}
{com}. drop if prueb!=0
{txt}(686,674 observations deleted)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{txt}
{com}. drop _m
{txt}
{com}. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace  
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved

{com}. 
. * Replace AFEC01-AFEC06 with values from datasets sent by Dr. Lozano 
. 
. clear 
{txt}
{com}. use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. merge m:1 id year using "`data'/AFECCIONES2010.dta", update 
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,661,484
{txt}{col 9}from master{col 30}{res}       1,178,256{txt}  (_merge==1)
{col 9}from using{col 30}{res}       1,483,228{txt}  (_merge==2)

{col 5}matched{col 30}{res}          77,845
{txt}{col 9}not updated{col 30}{res}               0{txt}  (_merge==3)
{col 9}missing updated{col 30}{res}          77,845{txt}  (_merge==4)
{col 9}nonmissing conflict{col 30}{res}               0{txt}  (_merge==5)
{col 5}{hline 41}

{com}. 
{txt}end of do-file

{com}. count
  {res}2,739,329

{com}. drop if prueba != 0
{txt}(1,483,228 observations deleted)

{com}. count
  {res}1,256,101

{com}. br if _m == 4

. count if _m == 4
  {res}77,845

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 0 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
. 
. {c )-}
{txt}
{com}. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
{txt}
{com}. 
. use "`data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. * Eliminating registers to keep only women (check with Evelyn what this means) 
. gen prueb=prueba
{txt}(1,286 missing values generated)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101       64.70       64.70
{txt}          1 {c |}{res}    520,197       26.79       91.49
{txt}          2 {c |}{res}    138,489        7.13       98.62
{txt}          3 {c |}{res}     26,702        1.38      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00
{txt}
{com}. drop if prueb!=0
{txt}(686,674 observations deleted)

{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{txt}
{com}. drop _m
{txt}
{com}. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace  
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved

{com}. 
. * Replace AFEC01-AFEC06 with values from datasets sent by Dr. Lozano 
. 
. clear 
{txt}
{com}. use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. merge m:1 id year using "`data'/AFECCIONES2010.dta", update 
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,661,484
{txt}{col 9}from master{col 30}{res}       1,178,256{txt}  (_merge==1)
{col 9}from using{col 30}{res}       1,483,228{txt}  (_merge==2)

{col 5}matched{col 30}{res}          77,845
{txt}{col 9}not updated{col 30}{res}               0{txt}  (_merge==3)
{col 9}missing updated{col 30}{res}          77,845{txt}  (_merge==4)
{col 9}nonmissing conflict{col 30}{res}               0{txt}  (_merge==5)
{col 5}{hline 41}

{com}. drop if prueb != 0 
{txt}(1,483,228 observations deleted)

{com}. drop _m 
{txt}
{com}. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved

{com}.         
.         
. forvalues i=2011(1)2014 {c -(} 
{txt}  2{com}.         
.         clear 
{txt}  3{com}.         use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}  4{com}.         
.         merge m:1 id year using "`data'/AFECCIONES`i'.dta", update keepusing (AFEC01 AFEC02 AFEC03 AFEC04 AFEC05 AFEC06 id year) nogen 
{txt}  5{com}. 
.         drop if prueb!=0
{txt}  6{com}. 
.         save "`lily_data'/Aborto en 2trimestre.dta", replace
{txt}  7{com}. 
. 
. **********************************************************************
. *Step 4: Replace values of "egresos 2007-2009" that Dr. Lozano sent 
. **********************************************************************
. 
. clear 
{txt}  8{com}. 
. forvalues i=2007(1)2009 {c -(} 
{txt}  9{com}.         use "`data'/EGRESOS`i'.dta", clear 
{txt} 10{com}.         
.         if `i' == 2009 {c -(}
{txt} 11{com}.                 rename egreso egreso_string
{txt} 12{com}.                 gen long egreso = date(egreso_string, "DMY")
{txt} 13{com}.                 format egreso %td       
{txt} 14{com}.                 gen year = 2009
{txt} 15{com}.         {c )-}
{txt} 16{com}.         
.         if `i' == 2007 | `i' == 2008 {c -(} 
{txt} 17{com}.         
.                 rename egreso egreso_string
{txt} 18{com}.                 gen egreso_string2 = substr(egreso_string,1,10)
{txt} 19{com}.                 replace egreso_string2 = subinstr(egreso_string2," ","",.)
{txt} 20{com}.                 gen long egreso = date(egreso_string2,"MDY")
{txt} 21{com}.                 replace egreso_string2 = substr(egreso_string2,1,8) if egreso==. 
{txt} 22{com}.                 drop egreso
{txt} 23{com}.                 gen long egreso = date(egreso_string2,"MDY")
{txt} 24{com}.                 //mdesc egreso
.                 format egreso %td       
{txt} 25{com}.                 gen year = `i' 
{txt} 26{com}.         {c )-}
{txt} 27{com}.         
.         save "`data'/EGRESOS`i'.dta", replace 
{txt} 28{com}. {c )-}
{txt} 29{com}. 
. // Append datasets 
.         
.         use "`data'/EGRESOS2009.dta", clear 
{txt} 30{com}.         append using "`data'/EGRESOS2008.dta", force 
{txt} 31{com}.         append using "`data'/EGRESOS2007.dta", force 
{txt} 32{com}.         
. // Clean up dataset
.         * Modify dates 
.         rename ingre ingre_string
{txt} 33{com}.         replace ingre_string = subinstr(ingre_string," ","",.)
{txt} 34{com}.         gen long ingre = date(ingre_string, "DMY")
{txt} 35{com}.         replace ingre_string=substr(ingre_string,1,6)+"2007" if ingre==. & substr(ingre_string,7,2)=="07" 
{txt} 36{com}.         replace ingre_string=substr(ingre_string,1,6)+"2006" if ingre==. & substr(ingre_string,7,2)=="06" 
{txt} 37{com}.         format ingre %td        
{txt} 38{com}. 
.         * Rename variables for "afecciones 01-06"
.         forvalue i = 1(1)6{c -(}
{txt} 39{com}.                 rename afec0`i' AFEC0`i'
{txt} 40{com}.         {c )-}
{txt} 41{com}. 
.         * Eliminate variables that we don't need 
.         drop cjurcve cmpocve cloccve ctuncve tuhpsiq servhc servhp cveedad sexo derhab considera_indigena habla_esp habla_lengua lengua_indigena dias_esta tipserv servicioingre servicio02 servicio03 servicioegre proced cluesproced motegre diag_ini 
{txt} 42{com}.         drop causaext traumat lugar vez veces infec cie_infec sa_labor sa_expul sa_recup sa_inten sa_interm promed01 anest01 quirof01 qh01 qm01 promed02 anest02 quirof02 qh02 qm02 promed03 anest03 
{txt} 43{com}.         drop quirof03 qh03 qm03 promed04 anest04 quirof04 qh04 qm04 gestas partos abortos hayprod tipaten producto tipnaci planfam gestac peso01 peso02 peso03 sexprod01 sexprod02 sexprod03 condnac01 condnac02 
{txt} 44{com}.         drop condnac03 condegre01 condegre02 condegre03 naviapag01 naviapag02 naviapag03 navirean01 navirean02 navirean03 navicune01 navicune02 navicune03 causaia cvetiemia tiempoia causaib cvetiemib tiempoib 
{txt} 45{com}.         drop causaic cvetiemic tiempoic causaid cvetiemid tiempoid causaiia cvetiemiia tiempoiia causaiib cvetiemiib tiempoiib causabas 
{txt} 46{com}.         drop promed05 anest05 quirof05 qh05 qm05 promed06 anest06 quirof06 qh06 qm06 promed07 anest07 quirof07 qh07 qm07 promed08 anest08 quirof08 qh08 qm08 
{txt} 47{com}.         drop cedocve entidad munic loc ingre_string egreso_string  egreso_string2 
{txt} 48{com}. 
.         * Eliminate duplicates. In these datasets, each row represents a different women by date of discharge from the hospital 
.         duplicates drop clues edad afecprin egreso ingre year,force
{txt} 49{com}.         
.         * Save dataset 
.         save "`lily_data'/EGRESOS2007-09_short.dta", replace
{txt} 50{com}. 
. {c )-}
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,748,954
{txt}{col 9}from master{col 30}{res}       1,180,271{txt}  
{col 9}from using{col 30}{res}       1,568,683{txt}  

{col 5}matched{col 30}{res}          75,830
{txt}{col 9}not updated{col 30}{res}               0{txt}  
{col 9}missing updated{col 30}{res}          75,830{txt}  
{col 9}nonmissing conflict{col 30}{res}               0{txt}  
{col 5}{hline 41}
(1,568,683 observations deleted)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{res}{err}variable {bf}egreso_string{sf} already defined
{txt}{search r(110), local:r(110);}

end of do-file

{search r(110), local:r(110);}

{com}.  do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. // Lily Alexander 
. // MPH Student, University of Washington 
. // January 18, 2018 
. 
. // Purpose: Cleaning SAEH data for master's thesis and Aim 1 of SFP grant 
. 
. 
. *****************************************************
. * Set Stata preferences and local directories
. *****************************************************
. 
.         clear all
{res}{txt}
{com}.         set more off
{txt}
{com}.         set mem 2g
{txt}{bf:set memory} ignored.
{p 4 4 2}
Memory no longer
needs to be set in modern Statas;
memory adjustments are performed on the fly
automatically.
{p_end}

{com}.         
.         local data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación" 
{txt}
{com}.         local lily_data "C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data"
{txt}
{com}.         
. *****************************************************
. *Step 1: Convert exits ("egresos") for years 2007-2009 from CSV to stata
. *****************************************************
. 
. // Only run if needed. Since files are already created, don't re-run. 
. 
. local re_run = 1
{txt}
{com}. 
. if `re_run' == 1 {c -(}
. 
.         forvalues i=2007/2009 {c -(} 
{txt}  2{com}.                 insheet using "`data'/EGRESOS`i'.csv", clear
{txt}  3{com}.                 save "`data'/EGRESOS`i'.dta", replace
{txt}  4{com}.         {c )-}
{txt}(135 vars, 2,311,826 obs)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2007.dta saved
(134 vars, 2,463,847 obs)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2008.dta saved
(120 vars, 1,299,184 obs)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2009.dta saved
{com}. 
. 
. *****************************************************
. *Step 2: Convert 2010-2014 to Stata     
. *****************************************************
. 
. 
. forvalues i=2010(1)2014 {c -(} 
{txt}  2{com}.         
.         di in red "`i'"
{txt}  3{com}.         insheet using "`data'/AFECCIONES`i'.csv", clear 
{txt}  4{com}.         duplicates drop id numafec, force
{txt}  5{com}.         
.         reshape wide afec, i(id) j(numafec)
{txt}  6{com}.         gen year = `i'
{txt}  7{com}.         
.         if `i' == 2010 | `i' == 2013 {c -(} 
{txt}  8{com}.                 drop afec7 afec8
{txt}  9{com}. 
.         {c )-} 
{txt} 10{com}.         
.         if `i' == 2011 | `i' == 2012 {c -(} 
{txt} 11{com}.                 drop afec7
{txt} 12{com}. 
.         {c )-}
{txt} 13{com}.         
.         if `i' == 2014 {c -(} 
{txt} 14{com}.                 drop afec7-afec15
{txt} 15{com}. 
.         {c )-}
{txt} 16{com}.         
.         forvalues b=1(1)6 {c -(} 
{txt} 17{com}.                 rename afec`b' AFEC0`b'
{txt} 18{com}.         {c )-}
{txt} 19{com}.         
.         save "`data'/AFECCIONES`i'.dta", replace
{txt} 20{com}. 
.         {c )-}
{err}2010
{txt}(3 vars, 2,250,484 obs)

{p 0 4}{txt}Duplicates in terms of {res} id numafec{p_end}

{txt}(0 observations are duplicates)
(note: j = 1 2 3 4 5 6 7 8)

Data{col 36}long{col 43}->{col 48}wide
{hline 77}
Number of obs.                 {res} 2.3e+06   {txt}->{res} 1.6e+06
{txt}Number of variables            {res}       3   {txt}->{res}       9
{txt}j variable (8 values)           {res}numafec   {txt}->   (dropped)
xij variables:
                                   {res}afec   {txt}->   {res}afec1 afec2 ... afec8
{txt}{hline 77}
{res}{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/AFECCIONES2010.dta saved
{err}2011
{txt}(6 vars, 2,373,293 obs)

{p 0 4}{txt}Duplicates in terms of {res} id numafec{p_end}

{txt}(0 observations are duplicates)
(note: j = 1 2 3 4 5 6 7)

Data{col 36}long{col 43}->{col 48}wide
{hline 77}
Number of obs.                 {res} 2.4e+06   {txt}->{res} 1.6e+06
{txt}Number of variables            {res}       6   {txt}->{res}      11
{txt}j variable (7 values)           {res}numafec   {txt}->   (dropped)
xij variables:
                                   {res}afec   {txt}->   {res}afec1 afec2 ... afec7
{txt}{hline 77}
{res}{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/AFECCIONES2011.dta saved
{err}2012
{txt}(6 vars, 2,538,926 obs)

{p 0 4}{txt}Duplicates in terms of {res} id numafec{p_end}

{txt}(10 observations deleted)
(note: j = 1 2 3 4 5 6 7)

Data{col 36}long{col 43}->{col 48}wide
{hline 77}
Number of obs.                 {res} 2.5e+06   {txt}->{res} 1.8e+06
{txt}Number of variables            {res}       6   {txt}->{res}      11
{txt}j variable (7 values)           {res}numafec   {txt}->   (dropped)
xij variables:
                                   {res}afec   {txt}->   {res}afec1 afec2 ... afec7
{txt}{hline 77}
{res}{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/AFECCIONES2012.dta saved
{err}2013
{txt}(3 vars, 2,622,080 obs)

{p 0 4}{txt}Duplicates in terms of {res} id numafec{p_end}

{txt}(37 observations deleted)
(note: j = 1 2 3 4 5 6 7 8)

Data{col 36}long{col 43}->{col 48}wide
{hline 77}
Number of obs.                 {res} 2.6e+06   {txt}->{res} 1.8e+06
{txt}Number of variables            {res}       3   {txt}->{res}       9
{txt}j variable (8 values)           {res}numafec   {txt}->   (dropped)
xij variables:
                                   {res}afec   {txt}->   {res}afec1 afec2 ... afec8
{txt}{hline 77}
{res}{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/AFECCIONES2013.dta saved
{err}2014
{txt}(3 vars, 2,767,444 obs)

{p 0 4}{txt}Duplicates in terms of {res} id numafec{p_end}

{txt}(620 observations deleted)
(note: j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15)

Data{col 36}long{col 43}->{col 48}wide
{hline 77}
Number of obs.                 {res} 2.8e+06   {txt}->{res} 1.9e+06
{txt}Number of variables            {res}       3   {txt}->{res}      16
{txt}j variable (15 values)          {res}numafec   {txt}->   (dropped)
xij variables:
                                   {res}afec   {txt}->   {res}afec1 afec2 ... afec15
{txt}{hline 77}
{res}{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/AFECCIONES2014.dta saved
{com}. 
. 
. *****************************************************************************************
. *Step 3: Replace values of "afecciones 01-06" for 2010-2014 with new data from Dr. Lozano
. *****************************************************************************************
. 
. clear 
. 
. use "`data'/Aborto en 2trimestre.dta", clear 
. 
. * Eliminating registers to keep only women (check with Evelyn what this means) 
. gen prueb=prueba
{txt}(1,286 missing values generated)
{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101       64.70       64.70
{txt}          1 {c |}{res}    520,197       26.79       91.49
{txt}          2 {c |}{res}    138,489        7.13       98.62
{txt}          3 {c |}{res}     26,702        1.38      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,941,489      100.00
{com}. drop if prueb!=0
{txt}(686,674 observations deleted)
{com}. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{com}. drop _m
. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace  
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{com}. 
. * Replace AFEC01-AFEC06 with values from datasets sent by Dr. Lozano 
. 
. clear 
. use "`lily_data'/Aborto en 2trimestre.dta", clear 
. 
. merge m:1 id year using "`data'/AFECCIONES2010.dta", update 
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,661,484
{txt}{col 9}from master{col 30}{res}       1,178,256{txt}  (_merge==1)
{col 9}from using{col 30}{res}       1,483,228{txt}  (_merge==2)

{col 5}matched{col 30}{res}          77,845
{txt}{col 9}not updated{col 30}{res}               0{txt}  (_merge==3)
{col 9}missing updated{col 30}{res}          77,845{txt}  (_merge==4)
{col 9}nonmissing conflict{col 30}{res}               0{txt}  (_merge==5)
{col 5}{hline 41}
{com}. drop if prueb != 0 
{txt}(1,483,228 observations deleted)
{com}. drop _m 
. 
. save "`lily_data'/Aborto en 2trimestre.dta", replace
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{com}.         
.         
. forvalues i=2011(1)2014 {c -(} 
{txt}  2{com}.         
.         clear 
{txt}  3{com}.         use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}  4{com}.         
.         merge m:1 id year using "`data'/AFECCIONES`i'.dta", update keepusing (AFEC01 AFEC02 AFEC03 AFEC04 AFEC05 AFEC06 id year) nogen 
{txt}  5{com}. 
.         drop if prueb!=0
{txt}  6{com}. 
.         save "`lily_data'/Aborto en 2trimestre.dta", replace
{txt}  7{com}. 
. {c )-}
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,748,954
{txt}{col 9}from master{col 30}{res}       1,180,271{txt}  
{col 9}from using{col 30}{res}       1,568,683{txt}  

{col 5}matched{col 30}{res}          75,830
{txt}{col 9}not updated{col 30}{res}               0{txt}  
{col 9}missing updated{col 30}{res}          75,830{txt}  
{col 9}nonmissing conflict{col 30}{res}               0{txt}  
{col 5}{hline 41}
(1,568,683 observations deleted)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,849,020
{txt}{col 9}from master{col 30}{res}       1,176,079{txt}  
{col 9}from using{col 30}{res}       1,672,941{txt}  

{col 5}matched{col 30}{res}          80,022
{txt}{col 9}not updated{col 30}{res}               0{txt}  
{col 9}missing updated{col 30}{res}          80,022{txt}  
{col 9}nonmissing conflict{col 30}{res}               0{txt}  
{col 5}{hline 41}
(1,672,941 observations deleted)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,899,605
{txt}{col 9}from master{col 30}{res}       1,180,845{txt}  
{col 9}from using{col 30}{res}       1,718,760{txt}  

{col 5}matched{col 30}{res}          75,256
{txt}{col 9}not updated{col 30}{res}               0{txt}  
{col 9}missing updated{col 30}{res}          75,256{txt}  
{col 9}nonmissing conflict{col 30}{res}               0{txt}  
{col 5}{hline 41}
(1,718,760 observations deleted)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       2,988,787
{txt}{col 9}from master{col 30}{res}       1,181,391{txt}  
{col 9}from using{col 30}{res}       1,807,396{txt}  

{col 5}matched{col 30}{res}          74,710
{txt}{col 9}not updated{col 30}{res}               0{txt}  
{col 9}missing updated{col 30}{res}          74,710{txt}  
{col 9}nonmissing conflict{col 30}{res}               0{txt}  
{col 5}{hline 41}
(1,807,396 observations deleted)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/Aborto en 2trimestre.dta saved
{com}. **********************************************************************
. *Step 4: Replace values of "egresos 2007-2009" that Dr. Lozano sent 
. **********************************************************************
. 
. clear 
. 
. forvalues i=2007(1)2009 {c -(} 
{txt}  2{com}.         use "`data'/EGRESOS`i'.dta", clear 
{txt}  3{com}.         
.         if `i' == 2009 {c -(}
{txt}  4{com}.                 rename egreso egreso_string
{txt}  5{com}.                 gen long egreso = date(egreso_string, "DMY")
{txt}  6{com}.                 format egreso %td       
{txt}  7{com}.                 gen year = 2009
{txt}  8{com}.         {c )-}
{txt}  9{com}.         
.         if `i' == 2007 | `i' == 2008 {c -(} 
{txt} 10{com}.         
.                 rename egreso egreso_string
{txt} 11{com}.                 gen egreso_string2 = substr(egreso_string,1,10)
{txt} 12{com}.                 replace egreso_string2 = subinstr(egreso_string2," ","",.)
{txt} 13{com}.                 gen long egreso = date(egreso_string2,"MDY")
{txt} 14{com}.                 replace egreso_string2 = substr(egreso_string2,1,8) if egreso==. 
{txt} 15{com}.                 drop egreso
{txt} 16{com}.                 gen long egreso = date(egreso_string2,"MDY")
{txt} 17{com}.                 //mdesc egreso
.                 format egreso %td       
{txt} 18{com}.                 gen year = `i' 
{txt} 19{com}.         {c )-}
{txt} 20{com}.         
.         save "`data'/EGRESOS`i'.dta", replace 
{txt} 21{com}. {c )-}
{res}{txt}(0 real changes made)
(2,311,826 missing values generated)
(2,311,826 real changes made)
(2,311,826 missing values generated)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2007.dta saved
{res}{txt}(1 missing value generated)
(0 real changes made)
(2,463,847 missing values generated)
(2,463,846 real changes made)
(2,463,847 missing values generated)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2008.dta saved
{res}{txt}(6 missing values generated)
file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Segunda formación/EGRESOS2009.dta saved
{com}. 
. // Append datasets 
.         
.         use "`data'/EGRESOS2009.dta", clear 
.         append using "`data'/EGRESOS2008.dta", force 
{txt}{p 0 7 2}
(note: variable
cedocve was byte in the using data, but will be
str82 now)
{p_end}
{p 0 7 2}
(note: variable
anest01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
egreso_string was 
str10, now str19 to accommodate using data's values)
{p_end}
{p 0 7 2}
(note: variable
veces was 
byte, now int to accommodate using data's values)
{p_end}
{com}.         append using "`data'/EGRESOS2007.dta", force 
{txt}{p 0 7 2}
(note: variable
cedocve was byte in the using data, but will be
str82 now)
{p_end}
{p 0 7 2}
(note: variable
servicio02 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
servicio03 was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
servicioegre was str3 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
traumat was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
lugar was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
anest01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
quirof01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tipaten was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
producto was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
tipnaci was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
planfam was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
peso01 was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
peso02 was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
peso03 was str4 in the using data, but will be
int now)
{p_end}
{p 0 7 2}
(note: variable
sexprod01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
sexprod02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condnac01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condnac02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condegre01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
condegre02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
navirean01 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
navirean02 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
navirean03 was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemia was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemib was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemic was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemid was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiia was str1 in the using data, but will be
byte now)
{p_end}
{p 0 7 2}
(note: variable
cvetiemiib was str1 in the using data, but will be
byte now)
{p_end}
{com}.         
. // Clean up dataset
.         * Modify dates 
.         rename ingre ingre_string
{res}{com}.         replace ingre_string = subinstr(ingre_string," ","",.)
{txt}(5,908 real changes made)
{com}.         gen long ingre = date(ingre_string, "DMY")
{txt}(8,086 missing values generated)
{com}.         replace ingre_string=substr(ingre_string,1,6)+"2007" if ingre==. & substr(ingre_string,7,2)=="07" 
{txt}(5,742 real changes made)
{com}.         replace ingre_string=substr(ingre_string,1,6)+"2006" if ingre==. & substr(ingre_string,7,2)=="06" 
{txt}(56 real changes made)
{com}.         format ingre %td        
. 
.         * Rename variables for "afecciones 01-06"
.         forvalue i = 1(1)6{c -(}
{txt}  2{com}.                 rename afec0`i' AFEC0`i'
{txt}  3{com}.         {c )-}
{res}{com}. 
.         * Eliminate variables that we don't need 
.         drop cjurcve cmpocve cloccve ctuncve tuhpsiq servhc servhp cveedad sexo derhab considera_indigena habla_esp habla_lengua lengua_indigena dias_esta tipserv servicioingre servicio02 servicio03 servicioegre proced cluesproced motegre diag_ini 
.         drop causaext traumat lugar vez veces infec cie_infec sa_labor sa_expul sa_recup sa_inten sa_interm promed01 anest01 quirof01 qh01 qm01 promed02 anest02 quirof02 qh02 qm02 promed03 anest03 
.         drop quirof03 qh03 qm03 promed04 anest04 quirof04 qh04 qm04 gestas partos abortos hayprod tipaten producto tipnaci planfam gestac peso01 peso02 peso03 sexprod01 sexprod02 sexprod03 condnac01 condnac02 
.         drop condnac03 condegre01 condegre02 condegre03 naviapag01 naviapag02 naviapag03 navirean01 navirean02 navirean03 navicune01 navicune02 navicune03 causaia cvetiemia tiempoia causaib cvetiemib tiempoib 
.         drop causaic cvetiemic tiempoic causaid cvetiemid tiempoid causaiia cvetiemiia tiempoiia causaiib cvetiemiib tiempoiib causabas 
.         drop promed05 anest05 quirof05 qh05 qm05 promed06 anest06 quirof06 qh06 qm06 promed07 anest07 quirof07 qh07 qm07 promed08 anest08 quirof08 qh08 qm08 
.         drop cedocve entidad munic loc ingre_string egreso_string  egreso_string2 
. 
.         * Eliminate duplicates. In these datasets, each row represents a different women by date of discharge from the hospital 
.         duplicates drop clues edad afecprin egreso ingre year,force

{p 0 4}{txt}Duplicates in terms of {res} clues edad afecprin egreso ingre year{p_end}

{txt}(274,753 observations deleted)
{com}.         
.         * Save dataset 
.         save "`lily_data'/EGRESOS2007-09_short.dta", replace
{txt}file C:/Users/Lily Alexander/Dropbox/ALL LIFE THINGS/SFP_2017-2019/04 Aim 1a - SAEH/01 Datos/Bases/Lily_data/EGRESOS2007-09_short.dta saved
{com}. 
. {c )-}
{txt}
{com}. 
. **********************************************************************
. *Step 5: Combine datasets
. **********************************************************************
. 
. use "`lily_data'/Aborto en 2trimestre.dta", clear 
{txt}
{com}. 
. // Second check to make sure we just have women in the dataset 
. tab prueb

      {txt}prueb {c |}      Freq.     Percent        Cum.
{hline 12}{c +}{hline 35}
          0 {c |}{res}  1,256,101      100.00      100.00
{txt}{hline 12}{c +}{hline 35}
      Total {c |}{res}  1,256,101      100.00
{txt}
{com}. drop if prueb != 0 
{txt}(0 observations deleted)

{com}. 
. // Merge this dataset with the "egresos 2007-2009" dataset that was created above 
. merge m:m clues edad afecprin egreso ingre year using "`lily_data'/EGRESOS2007-09_short.dta", update 
{res}
{txt}{col 5}Result{col 38}# of obs.
{col 5}{hline 41}
{col 5}not matched{col 30}{res}       7,018,630
{txt}{col 9}from master{col 30}{res}       1,236,789{txt}  (_merge==1)
{col 9}from using{col 30}{res}       5,781,841{txt}  (_merge==2)

{col 5}matched{col 30}{res}          19,312
{txt}{col 9}not updated{col 30}{res}               0{txt}  (_merge==3)
{col 9}missing updated{col 30}{res}          19,312{txt}  (_merge==4)
{col 9}nonmissing conflict{col 30}{res}               0{txt}  (_merge==5)
{col 5}{hline 41}

{com}. 
. /*
> drop if prueb!=0
> drop _merge 
> 
> save "`lily_data'/Aborto en 2trimestre dataset.dta", replace
> 
> **********************************************************************
> *Step 6: Create variables for the analysis
> **********************************************************************
> 
> use "`lily_data'/Aborto en 2trimestre dataset.dta", clear 
> 
> 

{txt}end of do-file

{com}. count
  {res}7,037,942

{com}. do "C:\Users\LILYAL~1\AppData\Local\Temp\STD3498_000000.tmp"
{txt}
{com}. 
. 
. 